% Encoding: UTF-8

@Article{Lin2019197,
  author                  = {Lin, Y. and Wang, H. and Li, J. and Gao, H.},
  title                   = {Data source selection for information integration in big data era},
  journal                 = {Information Sciences},
  year                    = {2019},
  volume                  = {479},
  pages                   = {197-213},
  issn                    = {00200255},
  note                    = {cited By 0},
  abbrev_source_title     = {Inf Sci},
  abstract                = {In big data era, information integration often requires abundant data extracted from massive data sources. Due to a large number of data sources, data source selection plays a crucial role in information integration, since it is costly and even impossible to access all data sources. Data Source selection should consider both efficiency and effectiveness issues. For efficiency, the approach should scale to large data source amount. From effectiveness aspect, data quality and overlapping of sources are to be considered. In this paper, we study source selection problem in Big Data and propose methods which can scale to datasets with up to millions of data sources and guarantee the quality of results. Motivated by this, we propose a new metric taking the expected number of true values a source can provide as a criteria to evaluate the contribution of a data source. Based on our proposed index, we present a scalable algorithm and two pruning strategies to improve the efficiency without sacrificing precision. Experimental results on both real world and synthetic data sets show that our methods can select sources providing a large proportion of true values efficiently and can scale to massive data sources. © 2018 Elsevier Inc.},
  affiliation             = {Harbin Institute of Technology, Harbin, China},
  author_keywords         = {Data cleaning; Data integration; Source selection},
  coden                   = {ISIJB},
  correspondence_address1 = {Wang, H.; Harbin Institute of TechnologyChina; email: wangzh@hit.edu.cn},
  document_type           = {Article},
  doi                     = {10.1016/j.ins.2018.11.029},
  keywords                = {Data integration; Data mining; Efficiency; Information retrieval; Metadata, Data cleaning; Data source selection; Information integration; Pruning strategy; Quality of results; Scalable algorithms; Source selection; Synthetic datasets, Big data},
  language                = {English},
  publisher               = {Elsevier Inc.},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057622803&doi=10.1016%2fj.ins.2018.11.029&partnerID=40&md5=67c4375a75813b192a3d19b53c3a88e4},
}

@Article{Somani2019561,
  author                  = {Somani, G. and Zhao, X. and Srirama, S.N. and Buyya, R.},
  title                   = {Integration of Cloud, Internet of Things, and Big Data Analytics},
  journal                 = {Software - Practice and Experience},
  year                    = {2019},
  volume                  = {49},
  number                  = {4},
  pages                   = {561-564},
  issn                    = {00380644},
  note                    = {cited By 0},
  abbrev_source_title     = {Software Pract Exper},
  affiliation             = {Department of Computer Science and Engineering, Central University of Rajasthan, Ajmer, India; School of Engineering and Computer Science, Washington State University Vancouver, Vancouver, WA, United States; Mobile & Cloud Computing Laboratory, Institute of Computer Science, Faculty of Science and Technology, University of Tartu, Tartu, Estonia; Cloud Computing and Distributed Systems (CLOUDS) Laboratory, School of Computing and Information Systems, The University of Melbourne, Melbourne, Australia},
  coden                   = {SPEXB},
  correspondence_address1 = {Somani, G.; Department of Computer Science and Engineering, Central University of RajasthanIndia; email: gaurav@curaj.ac.in},
  document_type           = {Editorial},
  doi                     = {10.1002/spe.2664},
  language                = {English},
  publisher               = {John Wiley and Sons Ltd},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056270964&doi=10.1002%2fspe.2664&partnerID=40&md5=83bdbb13e57deeeab8f20265b838ae66},
}

@Article{Song2019279,
  author                  = {Song, S. and Zhang, Z.},
  title                   = {Database Resources in BIG Data Center: Submission, Archiving, and Integration of Big Data in Plant Science},
  journal                 = {Molecular Plant},
  year                    = {2019},
  volume                  = {12},
  number                  = {3},
  pages                   = {279-281},
  issn                    = {16742052},
  note                    = {cited By 0},
  abbrev_source_title     = {Mol. Plant},
  affiliation             = {BIG Data Center, Beijing Institute of Genomics, Chinese Academy of Sciences, Beijing, 100101, China; CAS Key Laboratory of Genome Sciences and Information, Beijing Institute of Genomics, Chinese Academy of Sciences, Beijing, 100101, China; University of Chinese Academy of Sciences, Beijing, 100049, China},
  correspondence_address1 = {Song, S.; BIG Data Center, Beijing Institute of Genomics, Chinese Academy of SciencesChina; email: songshh@big.ac.cn},
  document_type           = {Note},
  doi                     = {10.1016/j.molp.2019.01.020},
  language                = {English},
  publisher               = {Cell Press},
  pubmed_id               = {30716410},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061976400&doi=10.1016%2fj.molp.2019.01.020&partnerID=40&md5=8c7b243412b1be04dab834bf3b0d4556},
}

@Article{Çalı2019315,
  author                  = {Çalı, S. and Balaman, Ş.Y.},
  title                   = {Improved decisions for marketing, supply and purchasing: Mining big data through an integration of sentiment analysis and intuitionistic fuzzy multi criteria assessment},
  journal                 = {Computers and Industrial Engineering},
  year                    = {2019},
  volume                  = {129},
  pages                   = {315-332},
  issn                    = {03608352},
  note                    = {cited By 0},
  abbrev_source_title     = {Comput Ind Eng},
  abstract                = {This study proposes a novel decision support system for product ranking problems which integrates multi criteria decision making (MCDM) and aspect level sentiment analysis techniques. The main purpose of the developed methodology is to rank the alternative products taking into account a set of product criteria and the customer comments related to these criteria posted on websites to recommend the most appropriate alternative to potential customers. The decision support system comprises two stages, in the first stage, the online customer reviews are transformed into customer satisfaction scores through aspect level sentiment analysis to obtain performance scores corresponding to alternative products, whereas the second stage deals with ranking the alternative products via a novel MCDM methodology, namely “IF-ELECTRE integrated with VIKOR” according to the performance scores obtained in the first level. Intuitionistic fuzzy sets (IFSs) are utilized to effectively represent the customer reviews including hesitant expressions in decision matrix. The weights of criteria (the product aspects of significant importance for customers) are determined using entropy method. The applicability of the developed approach is explored by a case study, in which customer reviews about hotel experiences are evaluated using lexicon based sentiment analysis and alternative hotels are ranked according to the findings from the sentiment analysis by the Intuitionistic fuzzy (IF)-ELECTRE integrated with VIKOR methodology. © 2019 Elsevier Ltd},
  affiliation             = {The Graduate School of Natural and Applied Sciences, Department of Industrial Engineering, Dokuz Eylul University, Tinaztepe Yerleskesi, Buca, Izmir 35397, Turkey; Department of Industrial Engineering, Dokuz Eylul University, Tinaztepe Yerleşkesi, Buca, Izmir 35397, Turkey},
  author_keywords         = {Data mining; Intuitionistic fuzzy sets; Multi criteria decision making; Product and service ranking},
  coden                   = {CINDD},
  correspondence_address1 = {Balaman, Ş.Y.; Department of Industrial Engineering, Dokuz Eylul University, Tinaztepe YerleşkesiTurkey; email: s.yilmaz@deu.edu.tr},
  document_type           = {Article},
  doi                     = {10.1016/j.cie.2019.01.051},
  keywords                = {Artificial intelligence; Big data; Customer satisfaction; Decision making; Decision support systems; Fuzzy sets; Sales; Sentiment analysis, Analysis techniques; Intuitionistic fuzzy; Intuitionistic fuzzy sets; Multi criteria decision making; Multi-criteria assessment; Online customer reviews; Potential customers; Product and services, Data mining},
  language                = {English},
  publisher               = {Elsevier Ltd},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060921795&doi=10.1016%2fj.cie.2019.01.051&partnerID=40&md5=91dc33e9e18d11a026ff4df22561d9e1},
}

@Conference{Kaur2019200,
  author              = {Kaur, H. and Kushwaha, A.S.},
  title               = {A Review on Integration of Big Data and IoT},
  year                = {2019},
  pages               = {200-203},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Proc. - Int. Conf. Comput. Sci., ICCS},
  abstract            = {Communication plays a vital role whether we talk about formal or informal but when it comes to device communication or objects communication. IoT plays very important role to understand real world objects after transforming into virtual objects and generate huge amount of data which is in structured as well as unstructured form. In this paper author is focusing on various attributes which may provide feasible and optimal solutions for effective integration of IoT with Big Data to solve critical data analysis. Author would also highlights various challenges faced in IoT and Big Data integration by providing reviews of various authors. © 2018 IEEE.},
  affiliation         = {School of Computer Applications, Lovely Professional University, Jalandhar, India},
  art_number          = {8611058},
  author_keywords     = {Big Data Analytics; Big Data Lambda Architecture(BDLA); Big Data Learning(BDL); IoT; Map-Reduce; NoSQL databases; PIG; SkyTree},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICCS.2018.00040},
  isbn                = {9781538680254},
  journal             = {Proceedings - 4th International Conference on Computing Sciences, ICCS 2018},
  keywords            = {Big data; Data Analytics; Data integration; Mammals; Metadata, Critical data; Map-reduce; Nosql database; Optimal solutions; Real-world objects; SkyTree; Virtual objects, Internet of things},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062073518&doi=10.1109%2fICCS.2018.00040&partnerID=40&md5=c4133c43bd181f951766a96a8e8989ec},
}

@Article{Yousfi2019207,
  author                  = {Yousfi, S. and Rhanoui, M. and Chiadmi, D.},
  title                   = {Towards a generic multimodal architecture for batch and streaming Big Data integration},
  journal                 = {Journal of Computer Science},
  year                    = {2019},
  volume                  = {15},
  number                  = {1},
  pages                   = {207-220},
  issn                    = {15493636},
  note                    = {cited By 0},
  abbrev_source_title     = {J. Comput. Sci.},
  abstract                = {Big Data are rapidly produced from various heterogeneous data sources. They are of different types (text, image, video or audio) and have different levels of reliability and completeness. One of the most interesting architectures that deal with the large amount of emerging data at high velocity is called the lambda architecture. In fact, it combines two different processing layers namely batch and speed layers, each providing specific views of data while ensuring robustness, fast and scalable data processing. However, most papers dealing with the lambda architecture are focusing one single type of data generally produced by a single data source. Besides, the layers of the architecture are implemented independently, or, at best, are combined to perform basic processing without assessing either the data reliability or completeness. Therefore, inspired by the lambda architecture, we propose in this paper a generic multimodal architecture that combines both batch and streaming processing in order to build a complete, global and accurate insight in near-real-time based on the knowledge extracted from multiple heterogeneous Big Data sources. Our architecture uses batch processing to analyze the data structures and contents, build the learning models and calculate the reliability index of the involved sources, while the streaming processing uses the built-in models of the batch layer to immediately process incoming data and rapidly provide results. We validate our architecture in the context of urban traffic management systems in order to detect congestions. © 2019 Siham Yousfi, Maryem Rhanoui and Dalila Chiadmi.},
  affiliation             = {SIP Research Team, Rabat IT Center, EMI, Mohammed V University in Rabat, Morocco; IMS Team, ADMIR Laboratory, Rabat IT Center, ENSIAS, Mohammed V University in Rabat, Morocco; Meridian Team, LYRICA Laboratory, School of Information Sciences, Rabat, Morocco},
  author_keywords         = {Big Data integration; Heterogeneous data; Lambda architecture; Urban traffic management systems},
  correspondence_address1 = {Yousfi, S.; SIP Research Team, Rabat IT Center, EMI, Mohammed V University in RabatMorocco; email: sihamyousfi@research.emi.ac.ma},
  document_type           = {Article},
  doi                     = {10.3844/jcssp.2019.207.220},
  language                = {English},
  publisher               = {Science Publications},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061562274&doi=10.3844%2fjcssp.2019.207.220&partnerID=40&md5=5e332b31353f824de4847e4a59a0d84a},
}

@Article{Kaloyanova2019114,
  author                  = {Kaloyanova, K.},
  title                   = {Towards integrations of big data technology components},
  journal                 = {Lecture Notes in Business Information Processing},
  year                    = {2019},
  volume                  = {341},
  pages                   = {114-120},
  issn                    = {18651348},
  note                    = {cited By 0},
  abbrev_source_title     = {Lect. Notes Bus. Inf. Process.},
  abstract                = {Addressing the increasing volumes of data requires specific technologies, sophisticated methods and tools. Recently, the Big data processing’ challenge gave a strong impulse to the development of new data technologies. Considering that organizations still use their traditional database applications, reconciliation of both cases will be a more effective way to manage data functions in the organizations. In this paper we propose a framework for processing Big data based on technologies provided by Oracle. We also discuss some performance aspects of the proposed framework. © 2019, Springer Nature Switzerland AG.},
  affiliation             = {Faculty of Mathematics and Informatics, Sofia University, Sofia, Bulgaria},
  author_keywords         = {Big data; Database (DB); Hadoop; MapReduce; NoSQL; Oracle},
  correspondence_address1 = {Kaloyanova, K.; Faculty of Mathematics and Informatics, Sofia UniversityBulgaria; email: kkaloyanova@fmi.uni-sofia.bg},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-030-11395-7_11},
  editor                  = {Themistocleous M., Themistocleous M., da Cunha P.R.},
  isbn                    = {9783030113940},
  keywords                = {Big data; Information systems; Information use, Data functions; Data technologies; Database applications; Hadoop; Map-reduce; NoSQL; Oracle; Performance aspects, Data handling},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060787136&doi=10.1007%2f978-3-030-11395-7_11&partnerID=40&md5=9c47f39a327a9348211c46a9d983b1ad},
}

@Article{Talha201943,
  author                  = {Talha, M. and Ali, S. and Shah, S. and Khan, F.G. and Iqbal, J.},
  title                   = {Integration of Big Data and Deep Learning},
  journal                 = {SpringerBriefs in Computer Science},
  year                    = {2019},
  pages                   = {43-52},
  issn                    = {21915768},
  note                    = {cited By 0},
  abbrev_source_title     = {SpringerBriefs Comp. Sci.},
  abstract                = {The traditional algorithms of artificial intelligence and neural networks have many limitations to process big data in real time. Therefore, the researchers introduce the concept of deep learning to address the aforementioned challenge. However, big data analytics required a process consists of various steps where in each step an algorithm or a bunch of algorithm can be used. This chapter explains the role of machine learning in processing big data to meet various applications and users’ demands in real time. Similarly, various techniques of deep learning are studied to show how they can be used to address various challenges and issues of big data. Similarly, other similar techniques such as transfer learning are also discussed to support the study of deep learning. © 2019, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
  affiliation             = {Deanship of Scientific Research, King Saud University, Riyadh, Saudi Arabia; Islamia College University, Peshawar, Pakistan; Comsats University, Islamabad, Pakistan; Department of Electrical Engineering, Sarhad University of Science and Information Technology, Peshawar, Pakistan},
  correspondence_address1 = {Talha, M.; Deanship of Scientific Research, King Saud UniversitySaudi Arabia; email: talhauppal@gmail.com},
  document_type           = {Book Chapter},
  doi                     = {10.1007/978-981-13-3459-7_4},
  language                = {English},
  publisher               = {Springer},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060144026&doi=10.1007%2f978-981-13-3459-7_4&partnerID=40&md5=1c3340bada74e3c28855d1272739766d},
}

@Article{Zeiler2019,
  author                  = {Zeiler, W. and Labeodan, T.},
  title                   = {Human-in-the-loop energy flexibility integration on a neighbourhood level: Small and Big Data management},
  journal                 = {Building Services Engineering Research and Technology},
  year                    = {2019},
  issn                    = {01436244},
  note                    = {cited By 0; Article in Press},
  abbrev_source_title     = {Build Serv Eng Res Technol},
  abstract                = {Modern buildings provide an enormous amount of data available from various sources ranging from modular wireless sensors to smart meters. As well as enhancing energy management and building performance, the analysis of these datasets can enhance the management of decentralized energy systems (electrical storage, PV generation, heat storage, etc.). To optimize the interaction between the building and the grid, it is essential to determine the total energy flexibility of the user and the building. A building has different possibilities for demand side management, energy storage and energy exchange for which a functional-layered approach is proposed from the user up to building and its interaction with the energy infrastructure. Central is the principle of the human-in-the-loop, where a bottom-up approach places the human needs as a central starting point for the energy interaction optimisation. The combination of Big Data with deep learning techniques offers new possibilities in the prediction of energy use and decentralized renewable energy production (e.g. from local weather data taking into account local phenomena such as urban heat islands). This combined with a more bottom-up approach of multi-agent systems with a gossip-based cooperative approach using Small Data offers decentralized control and monitoring autonomy to reduce the complexity of the energy system integration and transition. This makes it possible to relate the outcomes of the urban energy system integration on a neighbourhood level. The approach is being applied to a typically medium-sized office building. A first application of the human-in-the-loop controlling the lighting systems in the open-plan workplace of the test-bed office building showed some estimated annual energy saving of around 24%. Practical application : Analysis of a large database containing so called Big Data of clusters of buildings seems promising. Therefor there is the need to study the potential impact of utilization of big building operational data in building services industry. Besides this there is also a need for a data mining-based method for analyzing massive building operational data of a specific building, Small Data. This work sets out a general framework and method for doing both and to combine the strength of both approaches. The presented combined approach and results will be of interest to engineers and facility managers wondering what the key constraints to optimal use data to optimize low energy/carbon control strategies might have within their work. © The Chartered Institution of Building Services Engineers 2019.},
  affiliation             = {Department of Built Environment, University of Technology Eindhoven, Netherlands},
  author_keywords         = {BEMS; Big Data; energy flexibility; neighbourhood energy management; Small Data; smart grid},
  coden                   = {BSETD},
  correspondence_address1 = {Zeiler, W.; Department of Built Environment, University of Technology EindhovenNetherlands; email: w.zeiler@bwk.tue.nl},
  document_type           = {Article in Press},
  doi                     = {10.1177/0143624418823190},
  keywords                = {Big data; Data integration; Data mining; Deep learning; Digital storage; Energy conservation; Energy management; Energy utilization; Heat storage; Information management; Multi agent systems; Office buildings; Photovoltaic cells; Smart power grids; Storage management, BEMS; Energy flexibility; Neighbourhood; Small data; Smart grid, Energy management systems},
  language                = {English},
  publisher               = {SAGE Publications Ltd},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059909978&doi=10.1177%2f0143624418823190&partnerID=40&md5=4409f50f061d3ee4002cbae017c463db},
}

@Article{Singh2019405,
  author                  = {Singh, P.K. and Verma, R.K. and Sarkar, J.L.},
  title                   = {MCC and big data integration for various technological frameworks},
  journal                 = {Advances in Intelligent Systems and Computing},
  year                    = {2019},
  volume                  = {714},
  pages                   = {405-414},
  issn                    = {21945357},
  note                    = {cited By 0},
  abbrev_source_title     = {Adv. Intell. Sys. Comput.},
  abstract                = {In the world of big data and Internet of things (IoT), data grows exponentially in terms of petabytes, and subsequent processing in large scale needs commodity-based clusters to run these applications. Mobile users cannot get the commodity cluster to run parallel, complex, and scientific applications. The portable devices can form a cloudlet and use the cloud based on available resources and required resources which can be taken care by our proposed scheduler engine. We are aware that the mobile devices have resource limitations, however the combinations of several component such as portable devices and cloud computing will help to fulfill the limitation in terms of resources. To encounter the problem of performing data intensive jobs using the mobile devices and also achieve interoperability with the cloudlet and different vendors of the cloud, we have proposed various architectures to integrate IoT and big data along with MCC. The proposed architectures use middleware for the integration of MCC and big data for various technological frameworks; in our approach, we use various appliances, sensors, and portable devices having efficient utilization of the resources on the cloud and cloudlets. © 2019, Springer Nature Singapore Pte Ltd.},
  affiliation             = {Tata Consultancy Services Research, Mumbai, India; Biju Patnaik University of Technology, Rourkela, Odisha, India; Central University of Rajasthan, Ajmer, India},
  author_keywords         = {Big data; Cloud computing; Computation offloading; Hadoop; Internet of things; Iterative MapReduce; Middleware; Mobile cloud computing; Spark; Twister},
  correspondence_address1 = {Singh, P.K.; Tata Consultancy Services ResearchIndia; email: praveenhelp78@gmail.com},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-981-13-0224-4_36},
  editor                  = {Pujari A.K., Misra S., Panigrahi C.R., Pati B., Li K.},
  isbn                    = {9789811302237},
  keywords                = {Cloud computing; Computer architecture; Data integration; Electric sparks; Intelligent computing; Internet of things; Middleware; Mobile cloud computing; Mobile telecommunication systems; Portable equipment, Computation offloading; Hadoop; Internet of Things (IOT); Iterative mapreduce; Proposed architectures; Scientific applications; Technological framework; Twister, Big data},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050389988&doi=10.1007%2f978-981-13-0224-4_36&partnerID=40&md5=d5859635e68c2b47b3d3c0011cb7e38c},
}

@Article{Nadal20193,
  author                  = {Nadal, S. and Romero, O. and Abelló, A. and Vassiliadis, P. and Vansummeren, S.},
  title                   = {An integration-oriented ontology to govern evolution in Big Data ecosystems},
  journal                 = {Information Systems},
  year                    = {2019},
  volume                  = {79},
  pages                   = {3-19},
  issn                    = {03064379},
  note                    = {cited By 2},
  abbrev_source_title     = {Inf. Syst.},
  abstract                = {Big Data architectures allow to flexibly store and process heterogeneous data, from multiple sources, in their original format. The structure of those data, commonly supplied by means of REST APIs, is continuously evolving. Thus data analysts need to adapt their analytical processes after each API release. This gets more challenging when performing an integrated or historical analysis. To cope with such complexity, in this paper, we present the Big Data Integration ontology, the core construct to govern the data integration process under schema evolution by systematically annotating it with information regarding the schema of the sources. We present a query rewriting algorithm that, using the annotated ontology, converts queries posed over the ontology to queries over the sources. To cope with syntactic evolution in the sources, we present an algorithm that semi-automatically adapts the ontology upon new releases. This guarantees ontology-mediated queries to correctly retrieve data from the most recent schema version as well as correctness in historical queries. A functional and performance evaluation on real-world APIs is performed to validate our approach. © 2018 Elsevier Ltd},
  affiliation             = {Universitat Politècnica de Catalunya - BarcelonaTech, Spain; University of Ioannina, Greece; Université Libre de Bruxelles, Belgium},
  author_keywords         = {Data integration; Evolution; Semantic web},
  coden                   = {INSYD},
  correspondence_address1 = {Nadal, S.; Universitat Politècnica de Catalunya - BarcelonaTechSpain; email: snadal@essi.upc.edu},
  document_type           = {Article},
  doi                     = {10.1016/j.is.2018.01.006},
  keywords                = {Data integration; Ontology; Semantic Web, Analytical process; Evolution; Heterogeneous data; Historical analysis; Historical queries; Integration process; Performance evaluations; Schema evolution, Big data},
  language                = {English},
  publisher               = {Elsevier Ltd},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042165289&doi=10.1016%2fj.is.2018.01.006&partnerID=40&md5=039d9b1ce51336bfce1aa122930d264b},
}

@Conference{Cadersaib2018146,
  author              = {Cadersaib, B.Z. and Ben Sta, H. and Gobin Rahimbux, B.A.},
  title               = {Making an interoperability approach between ERP and big data context},
  year                = {2018},
  pages               = {146-153},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Proc. - Int. Conf. Enterp. Syst., ES},
  abstract            = {Enterprise Resource Planning (ERP) systems are deeply rooted as part of organisations' IT systems. These systems have attracted different types of research including project management, technological implications as well as educational research. With the new data era, it is key that studies complementing ERP and Big Data integration are well established. During the initial stage of literature analysis, it was found that interoperability was an important aspect in ERP and Big Data integration. However, there were limited studies linking ERP, Big Data and Interoperability. A thorough background analysis was therefore performed to understand state-of-the-art linking these three domains and the results are presented in this paper. First, the link between ERP, Big Data and Interoperability is discussed. Second, the main findings from the articles linking ERP, Big Data and Interoperability are highlighted. Finally, the research areas linking these three domains are derived. © 2018 IEEE.},
  affiliation         = {Department of Software and Information Systems, University of Mauritius, Reduit, Mauritius; University of Tunis El Manar, Higher Institute of Computer Science, 2, Rue Abou Raihane Bayrouni Ariana, Tunis, 2080, Tunisia; University of Tunis, Higher Institute of Management, SMART Lab, 41, Avenue de la Liberte, Cite Bouchoucha Le Bardo, Tunis, 2000, Tunisia},
  art_number          = {8588272},
  author_keywords     = {Big data; Enterprise architecture; ERP; Interoperability},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ES.2018.00030},
  isbn                = {9781538683880},
  journal             = {Proceedings - 2018 6th International Conference on Enterprise Systems, ES 2018},
  keywords            = {Big data; Data integration; Interoperability; Project management, Background analysis; Data contexts; Educational research; Enterprise Architecture; Enterprise resource planning systems; Interoperability approaches; Literature analysis; State of the art, Enterprise resource planning},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061314949&doi=10.1109%2fES.2018.00030&partnerID=40&md5=6f3e21b95b22e6d53c5a6b63cd510a2c},
}

@Conference{Deshpande2018195,
  author              = {Deshpande, P. and Rasin, A. and Brown, E. and Furst, J. and Raicu, D.S. and Montner, S.M. and Armato, S.G.},
  title               = {Big data integration case study for radiology data sources},
  year                = {2018},
  pages               = {195-198},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {IEEE Life Sci. Conf., LSC},
  abstract            = {Today's digitized world urgently needs Big Data integration and analysis. Healthcare records are responsible for generating petabytes of data in a single day. Such data is heterogeneous in nature, captured in different files and formats, and varies from hospital to hospital. By integrating data from different sources and extracting meaningful information for the medical community, we can improve the overall quality of patient care. Our research targets the problem of integration for health records. To start, we already developed the Integrated Radiology Image search (IRIS) engine, which could represent a data integration framework for the healthcare domain. IRIS provided support for multiple public data sources and incorporated medical ontologies which would help radiologists and improve search interpretation by considering the meaning of the search query terms. In this paper, we describe a case study of data integration for radiology data sources. While the need for data integration is self-evident, we learned that rather than being a single step, data integration is an iterative process that requires continuous integration of metadata and additional supporting data sources. Our results show that an each step of data integration further improved IRIS engine results. © 2018 IEEE.},
  affiliation         = {DePaul University, Chicago, United States; Department of Radiology, University of Chicago, Chicago, United States},
  art_number          = {8572185},
  document_type       = {Conference Paper},
  doi                 = {10.1109/LSC.2018.8572185},
  isbn                = {9781538667095},
  journal             = {2018 IEEE Life Sciences Conference, LSC 2018},
  keywords            = {Big data; Engines; Health care; Hospitals; Radiation; Radiology; Search engines, Continuous integrations; Healthcare domains; Healthcare record; Integration frameworks; Iterative process; Medical community; Medical ontology; Public data source, Data integration},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060205722&doi=10.1109%2fLSC.2018.8572185&partnerID=40&md5=8b5486e3dc0c039b509ba041d6058c5f},
}

@Conference{Samoylov2018131,
  author              = {Samoylov, A. and Sergeev, N. and Kucherova, M. and Denisov, B.},
  title               = {Methodology of big data integration from a priori unknown heterogeneous data sources},
  year                = {2018},
  pages               = {131-135},
  publisher           = {Association for Computing Machinery},
  note                = {cited By 0},
  abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
  abstract            = {The success of data preparation for Big Data analytics directly depends on the quality of data integration from heterogeneous data sources. Extract, Transform and Load (ETL) systems have proved to be an efficient solution for this task. But to the moment, in the stages of data selection, definition of extraction rules and transformation, the decision is usually made exclusively by a data specialist. This, in turn, causes such problems as redundancy and inconsistency of imported data, narrow specialization of rules (up to uniqueness) with a limited number of analytical models and known requirements for the data mart. This paper presents the concept of solving the problem by providing methodological support for Big Data preparation procedure to efficiently collect data from a priory unknown heterogeneous data sources. © 2018 Association for Computing Machinery.},
  affiliation         = {Southern Federal University, Chekhova Street, 2, Taganrog, Russian Federation; Green Oasis School Tianmian, No 4030, Shennan Middle Road, Futian District, Shenzhen, Guangdong, 518026, China},
  author_keywords     = {Big Data; Data integration; ETL; Heterogeneous data sources; Knowledge extraction; Modeling; Semantics},
  document_type       = {Conference Paper},
  doi                 = {10.1145/3297156.3297249},
  isbn                = {9781450366069},
  journal             = {ACM International Conference Proceeding Series},
  keywords            = {Artificial intelligence; Big data; Data Analytics; Data integration; Extraction; Metadata; Models; Multimedia systems; Semantics, Data mart; Data preparation; Data Selection; Extract , transform and loads; Extraction rule; Heterogeneous data sources; Knowledge extraction, Data mining},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062797062&doi=10.1145%2f3297156.3297249&partnerID=40&md5=bc199da1789e0e3f779e922dcde616c5},
}

@Article{Li20181761,
  author                  = {Li, D.},
  title                   = {Brain Cognition and Spatial Cognition: On Integration of Geo-spatial Big Data and Artificial Intelligence [脑认知与空间认知-论空间大数据与人工智能的集成]},
  journal                 = {Wuhan Daxue Xuebao (Xinxi Kexue Ban)/Geomatics and Information Science of Wuhan University},
  year                    = {2018},
  volume                  = {43},
  number                  = {12},
  pages                   = {1761-1767},
  issn                    = {16718860},
  note                    = {cited By 0},
  abbrev_source_title     = {Wuhan Daxue Xuebao Xinxi Kexue Ban},
  abstract                = {21st century is the age of data explosion growth. In the era of big data, it is urgent to enhance the timeliness and intelligence level of the geo-spatial information science.Artificial intelligence is applied to geo-spatial information science, enhancing the perception and cognition ability of geospatial information processing, and realizing the three processes of perception, cognition and action of geo-spatial information science.Through the integration of geo-spatial big data and AI (artificial intelligence), the macro, meso and micro scale of the earth space, earth observation brain(EOB), smart city brain(SCB) and smart phone brain(SPB) are proposed. EOB, SCB and SPB are highly intelligent systems in the geo-spatial information science. The concept model and the key technologies needed to be solved of EOB, SCB and SPB are introduced in detail, and an example is given to illustrate the process of perception, cognition and active in the primary stage of the EOB,SCB and SPB. In future,EOB,SCB and SPB can observe when, where, what object, what change to push these right information to right person at the right time and right place. © 2018, Research and Development Office of Wuhan University. All right reserved.},
  affiliation             = {State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, 430079, China; Collaborative Innovation Center of Geospatial Technology, Wuhan, 430079, China},
  author_keywords         = {Artificial intelligence; Earth observation brain; Geo-spatial big data; Geospatial information intelligent service; Smart city brain; Smart phone brain},
  coden                   = {WDXKA},
  correspondence_address1 = {Li, D.; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan UniversityChina; email: drli@whu.edu.cn},
  document_type           = {Article},
  doi                     = {10.13203/j.whugis20180411},
  keywords                = {Artificial intelligence; Big data; Earth (planet); Intelligent systems; Observatories; Smart city; Smartphones, Brain cognition; Earth observations; Geo-spatial; Geo-spatial informations; Intelligent Services; Key technologies; Perception and cognition; Spatial cognition, Data integration},
  language                = {Chinese},
  publisher               = {Wuhan University},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061864025&doi=10.13203%2fj.whugis20180411&partnerID=40&md5=9a439f9692b7e097082378e779f7c181},
}

@Article{DallaValle201876,
  author                  = {Dalla Valle, L. and Kenett, R.},
  title                   = {Social media big data integration: A new approach based on calibration},
  journal                 = {Expert Systems with Applications},
  year                    = {2018},
  volume                  = {111},
  pages                   = {76-90},
  issn                    = {09574174},
  note                    = {cited By 2},
  abbrev_source_title     = {Expert Sys Appl},
  abstract                = {In recent years, the growing availability of huge amounts of information, generated in every sector at high speed and in a wide variety of forms and formats, is unprecedented. The ability to harness big data is an opportunity to obtain more accurate analyses and to improve decision-making in industry, government and many other organizations. However, handling big data may be challenging and proper data integration is a key dimension in achieving high information quality. In this paper, we propose a novel approach to data integration that calibrates online generated big data with interview based customer survey data. A common issue of customer surveys is that responses are often overly positive, making it difficult to identify areas of weaknesses in organizations. On the other hand, online reviews are often overly negative, hampering an accurate evaluation of areas of excellence. The proposed methodology calibrates the levels of unbalanced responses in different data sources via resampling and performs data integration using Bayesian Networks to propagate the new re-balanced information. In this paper we show, with a case study example, how the novel data integration approach allows businesses and organizations to get a bias corrected appraisal of the level of satisfaction of their customers. The application is based on the integration of online data of review blogs and customer satisfaction surveys from the San Francisco airport. We illustrate how this integration enhances the information quality of the data analytic work in four of InfoQ dimensions, namely, Data Structure, Data Integration, Temporal Relevance and Chronology of Data and Goal. © 2017},
  affiliation             = {School of Computing, Electronics and Mathematics, University of Plymouth, Drake Circus, PL4 8AA, Plymouth, Devon, United Kingdom; KPA Ltd, Neaman Institute, Technion and University of Turin, Italy},
  author_keywords         = {Bayesian networks; Calibration; Data integration; Information quality (InfoQ); Resampling techniques; Social media},
  coden                   = {ESAPE},
  correspondence_address1 = {Dalla Valle, L.; School of Computing, Electronics and Mathematics, University of Plymouth, Drake Circus, PL4 8AA, Plymouth, Devon, United Kingdom; email: luciana.dallavalle@plymouth.ac.uk},
  document_type           = {Article},
  doi                     = {10.1016/j.eswa.2017.12.044},
  keywords                = {Bayesian networks; Big data; Calibration; Customer satisfaction; Decision making; Information analysis; Sales; Social networking (online); Surveys, Customer satisfaction survey; Information quality; Integration approach; Level of satisfaction; Resampling technique; Social media; Temporal relevance; Unbalanced response, Data integration},
  language                = {English},
  publisher               = {Elsevier Ltd},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039774393&doi=10.1016%2fj.eswa.2017.12.044&partnerID=40&md5=335f4ad1f5e687bf63f87a8fa031f3aa},
}

@Book{Leung2018141,
  title                   = {The integration of big data analytics, data mining and artificial intelligence solutions for strategic e-commerce retail and logistics business-it alignment: A case study},
  publisher               = {Nova Science Publishers, Inc.},
  year                    = {2018},
  author                  = {Leung, K.H. and Luk, C.C. and Choy, K.L. and Lam, H.Y.},
  volume                  = {41},
  isbn                    = {9781536144611; 9781536144604},
  note                    = {cited By 0},
  abbrev_source_title     = {Prog. in Econ. Res.},
  abstract                = {The advancement of information technology, in conjunction with the popularity of the use of mobile apps and mobile payment, has facilitated a drastic growth of e-commerce retail business around the globe in the past decade. In order to focus on core business processes, such as product development and promotion, e-retailers commonly outsource the logistics and distribution aspects of e-commerce business to third-party logistics service providers (3PLs). In attempting to grasp a share of the market pie of e-commerce logistics business, 3PLs, on the other hand, need to rise to the challenge of providing timely and efficient logistics service for ecommerce orders to satisfy both the e-retailers and the consumers. In view of the essential need of 3PLs to continuously improve their core capability in e-commerce order handling, which may in turn facilitate ecommerce supply chain excellence as a whole, this article describes the current bottlenecks in the e-commerce supply chain, reviews both the state-of-the-art and common logistics management systems in the market for e-commerce order management, thereby providing a critical review of the feasibility of integrating various popular artificial intelligence (AI) techniques in the development of logistics management systems. A case example is provided to demonstrate the potential of cost-effective, lightweight artificial intelligence-based e-commerce order handling systems for effective management of e-commerce logistics orders by the 3PLs. © 2018 Nova Science Publishers, Inc.},
  affiliation             = {Department of Industrial and Systems Engineering, The Hong Kong Polytechnic University, Hong Kong},
  author_keywords         = {Artificial intelligence; Big data analytics; Data mining; E-commerce},
  correspondence_address1 = {Choy, K.L.; Department of Industrial and Systems Engineering, The Hong Kong Polytechnic UniversityHong Kong; email: kl.choy@polyu.edu.hk},
  document_type           = {Book Chapter},
  journal                 = {Progress in Economics Research},
  language                = {English},
  pages                   = {141-165},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061139890&partnerID=40&md5=45cd8afa1fbdc2fd18b16449b9a0fb1d},
}

@Article{Shi2018141,
  author                  = {Shi, Z. and Wang, G.},
  title                   = {Integration of big-data ERP and business analytics (BA)},
  journal                 = {Journal of High Technology Management Research},
  year                    = {2018},
  volume                  = {29},
  number                  = {2},
  pages                   = {141-150},
  issn                    = {10478310},
  note                    = {cited By 0},
  abbrev_source_title     = {J. High Technol. Manage. Res.},
  abstract                = {Technology advancements in cloud computing, big data systems, No-SQL database, cognitive systems, deep learning, and other artificial intelligence techniques make the integration of traditional ERP transaction data and big data streaming from various social media platforms and Internet of Things (IOTs) into a unified analytics system not only feasible but also inevitable. Two steps are prominent for this integration. The first, coined as forming the big-data ERP, is the integration of traditional ERP transaction data and the big data and the second is to integrate the big-data ERP with business analytics (BA). As ERP implementers and BA users are facing various challenges, managers responsible for this big-data ERP-BA integration are also seriously challenged. To help them deal with these challenges, we develop the SIST model (including Strategic alignment, Intellectual and Social capital integration, and Technology integration) and propose that this integration is an evolving portfolio with various maturity levels for different business functions, likely leading to sustainable competitive advantages. © 2018},
  affiliation             = {Decision & Information Sciences, Charlton College of Business 209, The University of Massachusetts at Dartmouth, United States; Decision & Information Sciences, Charlton College of Business 214, The University of Massachusetts at Dartmouth, United States},
  author_keywords         = {Big data; Business analytics; ERP; Maturity model; Portfolio perspective; Sustainable competitive advantages},
  coden                   = {JTMRE},
  correspondence_address1 = {Shi, Z.; Decision & Information Sciences, Charlton College of Business 209, The University of Massachusetts at DartmouthUnited States; email: zshi@umassd.edu},
  document_type           = {Article},
  doi                     = {10.1016/j.hitech.2018.09.004},
  keywords                = {Cognitive systems; Competition; Data integration; Deep learning; Distributed computer systems; Enterprise resource planning; Integration; Media streaming; Sustainable development, Artificial intelligence techniques; Business analytics; Internet of thing (IoTs); Maturity model; Portfolio perspective; Social media platforms; Sustainable competitive advantages; Technology Integration, Big data},
  language                = {English},
  publisher               = {Elsevier Ltd},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054417186&doi=10.1016%2fj.hitech.2018.09.004&partnerID=40&md5=ee0514f182f60cdab42c9dc189549f65},
}

@Conference{Stamelos2018539,
  author              = {Stamelos, I. and Koromilas, E. and Kachris, C. and Soudris, D.},
  title               = {A novel framework for the seamless integration of FPGA accelerators with big data analytics frameworks in heterogeneous data centers},
  year                = {2018},
  editor              = {Zine-Dine K., Smari W.W.},
  pages               = {539-545},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Proc. - Int. Conf. High Perform. Comput. Simul., HPCS},
  abstract            = {To face the increased network traffic in the cloud, data center operators have started adopting an heterogeneous approach in their infrastructures. Heterogeneous infrastructures, e.g. based on FPGAS, can provide higher performance and better energy-efficiency compared to the contemporary processors. However, FPGAS lack of an easy-To-use framework for the efficient deployment from high-level programming frameworks. In this paper, we present a novel framework that allows the seamless integration of FPGAS from high-level programming languages, like Java and Scala. The proposed approach provides all the required APIs for the utilization of FPGAS from these languages. The proposed scheme has been mapped on Amazon AWS f1 infrastructure and a performance evaluation is presented for two widely used machine learning algorithms. © 2018 IEEE.},
  affiliation         = {Institute of Communication and Computer Systems (ICCS), National Technical University of Athens, Athens, Greece},
  art_number          = {8514395},
  author_keywords     = {Accelerator; Data center; FPGA; heterogeneous computing; Machine learning; Reconfigurable computing},
  document_type       = {Conference Paper},
  doi                 = {10.1109/HPCS.2018.00090},
  isbn                = {9781538678787},
  journal             = {Proceedings - 2018 International Conference on High Performance Computing and Simulation, HPCS 2018},
  keywords            = {Artificial intelligence; Energy efficiency; Field programmable gate arrays (FPGA); High level languages; Learning algorithms; Learning systems; Object oriented programming; Particle accelerators; Reconfigurable architectures, Data centers; Heterogeneous computing; Heterogeneous data centers; High-level programming frameworks; High-level programming language; Performance evaluations; Reconfigurable computing; Seamless integration, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057431298&doi=10.1109%2fHPCS.2018.00090&partnerID=40&md5=7ef3d1db536a18bfb13f7aff9bb439f8},
}

@Article{Janković20181180,
  author                  = {Janković, S. and Mladenović, S. and Mladenović, D. and Vesković, S. and Glavić, D.},
  title                   = {Schema on read modeling approach as a basis of big data analytics integration in EIS},
  journal                 = {Enterprise Information Systems},
  year                    = {2018},
  volume                  = {12},
  number                  = {8-9},
  pages                   = {1180-1201},
  issn                    = {17517575},
  note                    = {cited By 1},
  abbrev_source_title     = {Enterp. Inf. Syst.},
  abstract                = {Big Data analysis is the process that can help organizations to make better business decisions. Organizations use data warehouses and business intelligence systems, i.e. enterprise information systems (EISs), to support and improve their decision-making processes. Since the ultimate goal of using EISs and Big Data analytics is the same, a logical task is to enable these systems to work together. In this paper we propose a framework of cooperation of these systems, based on the schema on read modeling approach and data virtualization. The goal of data virtualization process is to hide technical details related to data storage from applications and to display heterogeneous data sources as one integrated data source. We have tested the proposed model in a case study in the transportation domain. The study has shown that the proposed integration model responds flexibly and efficiently to the requirements related to adding new data sources, new data models and new data storage technologies. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.},
  affiliation             = {Faculty of Transport and Traffic Engineering, University of Belgrade, Belgrade, Serbia},
  author_keywords         = {Big data analytics; business intelligence system; data virtualization; data warehouse; schema on read},
  correspondence_address1 = {Janković, S.; Faculty of Transport and Traffic Engineering, University of BelgradeSerbia; email: s.jankovic@sf.bg.ac.rs},
  document_type           = {Article},
  doi                     = {10.1080/17517575.2018.1462404},
  keywords                = {Data integration; Data warehouses; Decision making; Decision support systems; Digital storage; Information analysis; Information systems; Virtual reality; Virtualization, Big Data Analytics; Business intelligence systems; Data storage technology; Data virtualization; Decision making process; Enterprise information system; Heterogeneous data sources; schema on read, Big data},
  language                = {English},
  publisher               = {Taylor and Francis Ltd.},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045666430&doi=10.1080%2f17517575.2018.1462404&partnerID=40&md5=a241009211579e700176db43a1e2bf1c},
}

@Article{Chang2018251,
  author                  = {Chang, H.},
  title                   = {Making sense of the big picture: Data linkage and integration in the era of big data},
  journal                 = {Healthcare Informatics Research},
  year                    = {2018},
  volume                  = {24},
  number                  = {4},
  pages                   = {251-252},
  issn                    = {20933681},
  note                    = {cited By 0},
  abbrev_source_title     = {Healthc. Informatics Res.},
  affiliation             = {Healthcare Informatics Research, Kyung Hee University, Seoul, South Korea},
  correspondence_address1 = {Chang, H.; Healthcare Informatics Research, Kyung Hee UniversitySouth Korea},
  document_type           = {Editorial},
  doi                     = {10.4258/hir.2018.24.4.251},
  language                = {English},
  publisher               = {Korean Society of Medical Informatics},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062837171&doi=10.4258%2fhir.2018.24.4.251&partnerID=40&md5=243679008f227e7197b3684c40f75b3c},
}

@Conference{Hsseinoiun2018211,
  author              = {Hsseinoiun, S. and Abdullah, R. and Jusoh, Y.Y. and Jabar, M.},
  title               = {Information System Success and Knowledge Grid Integration in Facilitating Knowledge Sharing among Big Data Community},
  year                = {2018},
  editor              = {Doraisamy S., Azman A., Iskandar D.N.A., Annamalai M., Ruger S., Yusoff F.H., Abd. Rahman N., Moffat A., Noah S.A.M.},
  pages               = {211-215},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Proc. - Int. Conf. Inf. Retr. Knowl. Manag.: Diving Data Sci., CAMP},
  abstract            = {Nowadays many domains interested to use big data to improve their decision making, strategic planning, and productivity while communication infrastructure supports various applications for users to share their resources, ideas or experiences. However, accessing, managing, analyzing, and using the rapidly expanding big data had raised challenges especially because of dispersed and heterogeneous nature of data. This review aimed to identify the factors to influence facilitating knowledge sharing among big data community from user satisfaction aspect and the way knowledge grid effect big data sharing by Delone and Maclean model for information system success. The research analysis and results revealed three features of knowledge grid which may influence information and system quality which defined as main factors affect knowledge sharing among the community from member's aspect. It also demonstrates seven factors to measure the facilitating knowledge sharing from community member's satisfaction view and quantity of knowledge sharing. Finally, the review established an initial conceptual model for facilitating knowledge sharing among big data which in follow up research will review by domain experts. © 2018 IEEE.},
  affiliation         = {Faculty of Computer Science AndInformation Technology, University Putra Malaysia, Selangor, Malaysia},
  art_number          = {8464790},
  author_keywords     = {big data community; knowledge grid; knowledge sharing},
  document_type       = {Conference Paper},
  doi                 = {10.1109/INFRKM.2018.8464790},
  isbn                = {9781538638125},
  journal             = {Proceedings - 2018 4th International Conference on Information Retrieval and Knowledge Management: Diving into Data Sciences, CAMP 2018},
  keywords            = {Decision making; Information retrieval; Information systems; Information use; Knowledge management, Communication infrastructure; Conceptual model; Domain experts; Information system success; Knowledge grids; Knowledge-sharing; Research analysis; User satisfaction, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054348518&doi=10.1109%2fINFRKM.2018.8464790&partnerID=40&md5=2afff63a6f25d4416112d15a99e3b4fe},
}

@Article{Saggi2018758,
  author                  = {Saggi, M.K. and Jain, S.},
  title                   = {A survey towards an integration of big data analytics to big insights for value-creation},
  journal                 = {Information Processing and Management},
  year                    = {2018},
  volume                  = {54},
  number                  = {5},
  pages                   = {758-790},
  issn                    = {03064573},
  note                    = {cited By 12},
  abbrev_source_title     = {Inf. Process. Manage.},
  abstract                = {Big Data Analytics (BDA) is increasingly becoming a trending practice that generates an enormous amount of data and provides a new opportunity that is helpful in relevant decision-making. The developments in Big Data Analytics provide a new paradigm and solutions for big data sources, storage, and advanced analytics. The BDA provide a nuanced view of big data development, and insights on how it can truly create value for firm and customer. This article presents a comprehensive, well-informed examination, and realistic analysis of deploying big data analytics successfully in companies. It provides an overview of the architecture of BDA including six components, namely: (i) data generation, (ii) data acquisition, (iii) data storage, (iv) advanced data analytics, (v) data visualization, and (vi) decision-making for value-creation. In this paper, seven V's characteristics of BDA namely Volume, Velocity, Variety, Valence, Veracity, Variability, and Value are explored. The various big data analytics tools, techniques and technologies have been described. Furthermore, it presents a methodical analysis for the usage of Big Data Analytics in various applications such as agriculture, healthcare, cyber security, and smart city. This paper also highlights the previous research, challenges, current status, and future directions of big data analytics for various application platforms. This overview highlights three issues, namely (i) concepts, characteristics and processing paradigms of Big Data Analytics; (ii) the state-of-the-art framework for decision-making in BDA for companies to insight value-creation; and (iii) the current challenges of Big Data Analytics as well as possible future directions. © 2018 Elsevier Ltd},
  affiliation             = {Department of Computer Science, Thapar, University Patiala, India},
  author_keywords         = {Big data; Big data visualization; Data analytics; Decision-making; Machine learning; Smart agriculture; Smart city application; Value-creation; Value-discover; Value-realization},
  coden                   = {IPMAD},
  correspondence_address1 = {Saggi, M.K.; Department of Computer Science, Thapar, University PatialaIndia; email: mandeepsaggi90@gmail.com},
  document_type           = {Article},
  doi                     = {10.1016/j.ipm.2018.01.010},
  keywords                = {Agriculture; Data acquisition; Data visualization; Decision making; Digital storage; Learning systems; Object oriented programming; Smart city; Visualization, Data analytics; Smart agricultures; Smart city applications; Value creation; Value-discover; Value-realization, Big data},
  language                = {English},
  publisher               = {Elsevier Ltd},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041554154&doi=10.1016%2fj.ipm.2018.01.010&partnerID=40&md5=b4b6a2ee2fa7af11cd66464753266e04},
}

@Conference{Tomar2018119,
  author              = {Tomar, D. and Tomar, P.},
  title               = {Integration of Cloud Computing and Big Data Technology for Smart Generation},
  year                = {2018},
  pages               = {119-124},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Proc. Int. Conf. Conflu. Cloud Comput., Data Sci. Eng., Conflu.},
  abstract            = {Cloud computing is the new in the era of computing technique and a blessing for an organization that desire to work on large scale and complex computation by providing powerful architecture. Cloud environment provide an easy way to access the Big Data analytics. But this easy access of data gives few issues, to be faced by the software industry to manage Big Data. This paper focus on the deployment of Cloud Technology for handling Big Data and further discuss the key features and categorization of Big Data and Hadoop framework that controls the difficulties in dealing with the Big Data in the cloud-environment including two case studies focusing on the utilization of Cloud Technology for Big Data and identify various imperative open research challenges in this area. © 2018 IEEE.},
  affiliation         = {Gautam Buddha University, School of ICT, Greater Noida, U.P., India},
  art_number          = {8443052},
  author_keywords     = {Big Data; Cloud Technology; Hadoop Architecture},
  document_type       = {Conference Paper},
  doi                 = {10.1109/CONFLUENCE.2018.8443052},
  isbn                = {9781538617182},
  journal             = {Proceedings of the 8th International Conference Confluence 2018 on Cloud Computing, Data Science and Engineering, Confluence 2018},
  keywords            = {Cloud computing; Computer architecture; Data handling; Software engineering, Big Data Analytics; Big data technologies; Cloud environments; Cloud technologies; Complex computation; Computing techniques; Hadoop frameworks; Research challenges, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053665364&doi=10.1109%2fCONFLUENCE.2018.8443052&partnerID=40&md5=00cd415603e4805db0b3f9e92f7e53cf},
}

@Article{Wang2018,
  author                  = {Wang, X. and Qi, D. and Lin, W. and Yu, M. and Zheng, Z. and Zhou, N. and Chen, P.},
  title                   = {A general framework for big data knowledge discovery and integration},
  journal                 = {Concurrency Computation},
  year                    = {2018},
  volume                  = {30},
  number                  = {13},
  issn                    = {15320626},
  note                    = {cited By 0},
  abbrev_source_title     = {Concurr. Comput.},
  abstract                = {Data structure description, conceptual modeling, and logic reasoning for knowledge discovery are three critical factors for the integration of information with heterogeneity. In particular, technologies of NoSQL databases and Internet of Things raise an urgent requirement for a uniform expression of heterogeneous data, and little attention has been paid to researches on the integration of NoSQL databases with traditional data models, as well as the semantic description of big data. To tackle these problems, in this paper, a concept-and-relation-oriented grid data model called GODM model is first proposed based on the definitions of Monad, Compounder, Relation, etc. Then, the GODM model is utilized to uniformly describe traditional data models and NoSQL data models, which eliminates structure differences of heterogeneous data. Next, based on the GODM relation mechanism, an extendable semantic system is built up by choosing SHOIQ(D) description logic as the example to establish the correspondence with GODM grammar subset, providing a fundamental support for semantic integration and knowledge discovery of heterogeneous data. After that, comprehensive comparisons with GODM and other models are made, especially the distinctions between GODM and OWL on the aspects of relation mechanism, hybrid schema, description logic, grammatical constructors, etc. Besides, experimental evaluations and analyses on time and space efficiencies of some primary common data models are conducted after the proposal of a general evaluation model, with the results showing that the GODM model has great advantage on properties of expressiveness, flexibility, etc, particularly time and space efficiency. In summary, the GODM model describes heterogeneous data from both aspects of data structure and semantic relationship and realizes a hybrid schema reconciling the schemaful and schemaless data models, making it especially suitable for dynamic data integration and knowledge discovery from big data models. Copyright © 2018 John Wiley & Sons, Ltd.},
  affiliation             = {Research Institute of Computer Systems, South China University of Technology, Guangzhou, 510006, China; Guangdong Provincial Key Laboratory of Petrochemical Equipment Fault Diagnosis, Maoming, 525000, China},
  art_number              = {e4422},
  author_keywords         = {data integration; data model; GODM; hybrid schema; knowledge representation; NoSQL; time and space efficiency},
  coden                   = {CCPEB},
  correspondence_address1 = {Wang, X.; Research Institute of Computer Systems, South China University of TechnologyChina; email: wxyyuppie@139.com},
  document_type           = {Article},
  doi                     = {10.1002/cpe.4422},
  keywords                = {Big data; Computer circuits; Data description; Data mining; Data structures; Efficiency; Formal languages; Knowledge representation; Semantics, Comprehensive comparisons; Discovery and integration; Experimental evaluation; GODM; Hybrid schema; NoSQL; Semantic relationships; Space efficiencies, Data integration},
  language                = {English},
  publisher               = {John Wiley and Sons Ltd},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041035012&doi=10.1002%2fcpe.4422&partnerID=40&md5=4ee950d5cdadca8177e32a422ee8a769},
}

@Conference{Weng201893,
  author              = {Weng, J.-Y. and Yang, C.-T. and Chang, C.-H.},
  title               = {The Integration of Shared Storages with the CephFS and Rados Gateway for Big Data Accessing},
  year                = {2018},
  editor              = {Demartini C., Reisman S., Liu L., Tovar E., Takakura H., Yang J.-J., Lung C.-H., Ahamed S.I., Hasan K., Conte T., Nakamura M., Zhang Z., Akiyama T., Claycomb W., Cimato S.},
  volume              = {2},
  pages               = {93-98},
  publisher           = {IEEE Computer Society},
  note                = {cited By 0},
  abbrev_source_title = {Proc Int Comput Software Appl Conf},
  abstract            = {In recent years, high availability shared storage will become a popular information technology industry development orientation. Currently, information technology industries emphasize to reduce high risk data requirements and improve read and write performance of data storage. Therefore, the main purpose of this work is to improve read and write performance with the best way on Ceph Storage Cluster. In this system, the data is stored on Hadoop Distributed File System (HDFS), and the data stored in-memory virtual distributed store system that mentioned as Alluxio automatically. Then, the data would be processed through Hadoop Map Reduce method and the output would be inserted into Hadoop Distributed File System and Alluxio environment. The first experiment is to use S3 as application program interface that will connect to RADOS Gateway stored data into Object Storage Daemon (OSD). The second experiment is based on the first out experiment would be through Ceph File System (CephFS) connected to Object Storage Daemon directly. The data is saved in Ceph environment more secure than in Alluxio as in-memory storage system because OSD can be used for data backup based on object storage level. We can use S3 browser (GUI) to maintain data like grant access, maintain folders maintenance, create user accounts, move data location etc. The last one, we used Inkscope monitors all system. If there is any problem, system will give warning or error responds to users automatically. © 2018 IEEE.},
  affiliation         = {Department of Computer Science, Tunghai University, Taichung City, Taiwan; College of Computing and Informatics, Providence University, Taichung City, Taiwan},
  art_number          = {8377836},
  author_keywords     = {Big data; Ceph Storage System; Share Storage},
  coden               = {PSICD},
  document_type       = {Conference Paper},
  doi                 = {10.1109/COMPSAC.2018.10209},
  isbn                = {9781538626665},
  issn                = {07303157},
  journal             = {Proceedings - International Computer Software and Applications Conference},
  keywords            = {Application programs; Digital storage; File organization, Application program interfaces; Data requirements; Hadoop distributed file system (HDFS); Hadoop distributed file systems; High availability; Information technology industry; Object storages; Storage systems, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055557781&doi=10.1109%2fCOMPSAC.2018.10209&partnerID=40&md5=b7d0a931d56207c1aad438472a64bf63},
}

@Article{McDonald2018230,
  author              = {McDonald, J.F.},
  title               = {Back to the future - The integration of big data with machine learning is re-establishing the importance of predictive correlations in ovarian cancer diagnostics and therapeutics},
  journal             = {Gynecologic Oncology},
  year                = {2018},
  volume              = {149},
  number              = {2},
  pages               = {230-231},
  issn                = {00908258},
  note                = {cited By 1},
  abbrev_source_title = {Gynecol. Oncol.},
  affiliation         = {Integrated Cancer Research Center, School of Biological Sciences, Petit Institute for Bioengineering and Bioscience, Georgia Institute of Technology, the Ovarian Cancer Institute, 315 Ferst Drive, Atlanta, GA 30332, United States},
  coden               = {GYNOA},
  document_type       = {Editorial},
  doi                 = {10.1016/j.ygyno.2018.03.053},
  keywords            = {cancer diagnosis; Editorial; female; human; ovary cancer; prediction; priority journal; support vector machine; blood; gene therapy; genetic database; genetics; information processing; machine learning; ovary tumor; predictive value, Databases, Genetic; Datasets as Topic; Female; Genetic Therapy; Humans; Machine Learning; Ovarian Neoplasms; Predictive Value of Tests},
  language            = {English},
  publisher           = {Academic Press Inc.},
  pubmed_id           = {29572028},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044149209&doi=10.1016%2fj.ygyno.2018.03.053&partnerID=40&md5=16741508cc1106e591a1e6feaaa24e0a},
}

@Article{Wang20181131,
  author                  = {Wang, L. and Zhao, T. and Zhang, Y. and Su, Y. and Tian, S.},
  title                   = {Multi-source Integration and Storage Optimization Method for Big Data of Power Distribution and Utilization [配用电大数据多源集成及存储优化方法]},
  journal                 = {Gaodianya Jishu/High Voltage Engineering},
  year                    = {2018},
  volume                  = {44},
  number                  = {4},
  pages                   = {1131-1139},
  issn                    = {10036520},
  note                    = {cited By 0},
  abbrev_source_title     = {Gaodianya Jishu},
  abstract                = {In the face of massive, heterogeneous and fast growing big data of power distribution and utilization, how to apply big data technology to improve the breadth, depth, and accuracy of power distribution and utilization business becomes a new opportunity and challenge in power industry. In order to solve the two major problems of big data with the multi-source integration and efficient storage, according to the composition and characteristics of big data of power distribution and utilization,we adopt standardized metadata and corresponding data dictionaries to realize the standardized integration of multi-source data of power distribution and utilization. On the basis of data integration, the optimization method of big data storage is studied based on the Hadoop platform. A Hash bucket algorithm considering data correlation is proposed. The algorithm realizes the centralized storage of related data, so as to enhance the efficiency of data query and processing. On the basis of data storage optimization, the parallel association query for multi-source big data of power distribution and utilization based on MapReduce is realized. Tests on a Hadoop platform show that, after optimization of hash bucket storage, the time of the multi-source data parallel association query is significantly shortened than traditional Hadoop method. © 2018, High Voltage Engineering Editorial Department of CEPRI. All right reserved.},
  affiliation             = {Department of Electrical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China; Electric Power Research Institute, Shanghai Municipal Electric Power Company of State Grid, Shanghai, 200437, China; China Electric Power Research Institute, Beijing, 100192, China},
  author_keywords         = {Big data of power distribution and utilization; Data integration; Hadoop; Hash bucket storage; Parallel association query},
  coden                   = {GAJIE},
  correspondence_address1 = {Wang, L.; Department of Electrical Engineering, Shanghai Jiao Tong UniversityChina; email: lintong@sjtu.edu.cn},
  document_type           = {Article},
  doi                     = {10.13336/j.1003-6520.hve.20180329012},
  keywords                = {Data integration; Digital storage, Big data technologies; Centralized storages; Hadoop; Multi-source integrations; Optimization method; Parallel association; Power distributions; Storage optimization, Big data},
  language                = {Chinese},
  publisher               = {Science Press},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052706704&doi=10.13336%2fj.1003-6520.hve.20180329012&partnerID=40&md5=d9ccd750098030bfe493905b2b1d12ff},
}

@Conference{Xiao2018245,
  author              = {Xiao, W. and Guoqi, L. and Bin, L.},
  title               = {Research on big data integration based on Karma modeling},
  year                = {2018},
  editor              = {Babu M.S.P., Wenzheng L., Xiaohui L.},
  volume              = {2017-November},
  pages               = {245-248},
  publisher           = {IEEE Computer Society},
  note                = {cited By 1},
  abbrev_source_title = {Proc.IEEE Int. Conf. Software Eng. Serv. Sci., ICSESS},
  abstract            = {Aiming at the problem of data integration about heterogeneous and large amount of data in big data 4V features, the method of data integration based on Karma modeling is explored, and the data set of literature area is used as an example to verify the method. First of all, analyze specifically part of the literature data sets that are obtained. And then using Protégé ontology modeling tool to build the related domain ontology. Through the Karma modeling tool, the literature data set is mapped to the literature domain ontology and uniformly published as RDF data so that the semantic mapping is achieved, which effectively solve the important problem of multi-source and heterogeneous data. The Karma model that is built and published will be applied to complete big data set for big data integration. Finally, we sum up the results of the practice and address our future works. © 2017 IEEE.},
  affiliation         = {School of Reliability and Systems Engineering, Beihang University, Beijing, 100191, China},
  author_keywords     = {big data integration; Karma modeling; ontology; RDF data},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICSESS.2017.8342906},
  isbn                = {9781538645703},
  issn                = {23270586},
  journal             = {Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS},
  keywords            = {Data integration; Ontology; Semantic Web; Semantics; Software engineering, Domain ontologies; Heterogeneous data; Large amounts; Literature data; Modeling tool; Ontology model; RDF data; Semantic mapping, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047019269&doi=10.1109%2fICSESS.2017.8342906&partnerID=40&md5=2b66bce13fb00569fb2d63b6ce75cdce},
}

@Article{Kitchens2018540,
  author              = {Kitchens, B. and Dobolyi, D. and Li, J. and Abbasi, A.},
  title               = {Advanced Customer Analytics: Strategic Value Through Integration of Relationship-Oriented Big Data},
  journal             = {Journal of Management Information Systems},
  year                = {2018},
  volume              = {35},
  number              = {2},
  pages               = {540-574},
  issn                = {07421222},
  note                = {cited By 2},
  abbrev_source_title = {J Manage Inf Syst},
  abstract            = {As more firms adopt big data analytics to better understand their customers and differentiate their offerings from competitors, it becomes increasingly difficult to generate strategic value from isolated and unfocused ad hoc initiatives. To attain sustainable competitive advantage from big data, firms must achieve agility in combining rich data across the organization to deploy analytics that sense and respond to customers in a dynamic environment. A key challenge in achieving this agility lies in the identification, collection, and integration of data across functional silos both within and outside the organization. Because it is infeasible to systematically integrate all available data, managers need guidance in finding which data can provide valuable and actionable insights about customers. Leveraging relationship marketing theory, we develop a framework for identifying and evaluating various sources of big data in order to create a value-justified data infrastructure that enables focused and agile deployment of advanced customer analytics. Such analytics move beyond siloed transactional customer analytics approaches of the past and incorporate a variety of rich, relationship-oriented constructs to provide actionable and valuable insights. We develop a customized kernel-based learning method to take advantage of these rich constructs and instantiate the framework in a novel prototype system that accurately predicts a variety of customer behaviors in a challenging environment, demonstrating the framework’s ability to drive significant value. Copyright © Taylor & Francis Group, LLC.},
  affiliation         = {University of Virginia, United States},
  coden               = {JMISE},
  document_type       = {Article},
  doi                 = {10.1080/07421222.2018.1451957},
  keywords            = {Competition; Data integration; Digital storage; Sales; Sustainable development, Agile deployments; Big Data Analytics; Customer behavior; Data infrastructure; Dynamic environments; Kernel-based learning; Relationship marketing; Sustainable competitive advantages, Big data},
  language            = {English},
  publisher           = {Routledge},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047254729&doi=10.1080%2f07421222.2018.1451957&partnerID=40&md5=153e6cfaf5ece007a16e737b5f669192},
}

@Article{Moon20181680,
  author                  = {Moon, Y.-J. and Choi, E. and Hwang, Y.-H.},
  title                   = {Design and implementation of the expert system for health and medical treatment using integration of big data},
  journal                 = {Journal of Theoretical and Applied Information Technology},
  year                    = {2018},
  volume                  = {96},
  number                  = {6},
  pages                   = {1680-1689},
  issn                    = {19928645},
  note                    = {cited By 1},
  abbrev_source_title     = {J. Theor. Appl. Inf. Technol.},
  abstract                = {This paper designs and implements the expert system for health and medical treatment using integration of public medical big data. According to the trend that the health and medical treatment data are gradually open to the public in the world, the integrated medical information system is required for the patients. By implementation of the medical expert system, representatives of the analytical results are average treatment expenses per medical center per disease, medical institutions frequently treating patients per disease, diseases susceptibility in the age group, number of patients per disease by region, and number of the medical clinics per department and district. The expert system makes the big data helpful for the medical centers, patients, governments, the medicine importers, pharmacists and insurance agencies etc. Overall, the expert system deals with not only the fundamental analysis of the diseases per age or per gender but also the practically beneficial information for all the interested parties with analysis of the public medical treatment big data. Furthermore, the expert system can easily be extended with increasing public medical big data open. © 2005 – ongoing JATIT & LLS.},
  affiliation             = {Hankuk University of Foreign Studies, Seoul, 02450, South Korea; Kunsan National UniversityJeonbuk 54150, South Korea},
  author_keywords         = {Big data; Expert system; Insurance agency; Medical center; Medical expense},
  correspondence_address1 = {Hwang, Y.-H.; Kunsan National UniversitySouth Korea; email: yhwang@kunsan.ac.kr},
  document_type           = {Article},
  language                = {English},
  publisher               = {Little Lion Scientific},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044837865&partnerID=40&md5=c9341fb253c254283d31773f12d461bd},
}

@Conference{Hu2018262,
  author              = {Hu, D. and Guo, Z.},
  title               = {Exploring deep integration of information technology and China's higher education in the era of big data},
  year                = {2018},
  editor              = {Liu J.C., Nishimura S., Jin Q., Zhang H.},
  volume              = {2018-March},
  pages               = {262-267},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Proc. - Int. Conf. Educ. Innov. Through Technol., EITT},
  abstract            = {With the rapid development of information technology represented by big data and its continuous infiltration in the field of education, the importance of educational informatization in the process of higher education reform and development has become increasingly prominent. On the basis of understanding the basic characteristics and structure of big data, this study first summarizes the role of big data in the development of higher education from the theoretical level. Secondly, from the aspect of practice, this study analyzes the application of big data technology in the field of personalized learning, improving the teaching level of teachers, and promoting the reform of education and teaching in colleges and universities. Finally, this study puts forward the countermeasures to promote the deep integration of information technology and higher education from the practice level, theory level, system level and organization level. © 2017 IEEE.},
  affiliation         = {Institute of Education, Tsinghua University, Beijing, China},
  author_keywords     = {Big data; Deep integration; Higher education; Information technology},
  document_type       = {Conference Paper},
  doi                 = {10.1109/EITT.2017.71},
  isbn                = {9781538606292},
  journal             = {Proceedings - 6th International Conference of Educational Innovation Through Technology, EITT 2017},
  keywords            = {Data integration; Engineering research; Information technology; Integration; Teaching, Basic characteristics; Big data technologies; Colleges and universities; Deep integrations; Higher education; Informatization; Personalized learning; System levels, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050624106&doi=10.1109%2fEITT.2017.71&partnerID=40&md5=186db28fd6a56f706d017ac08a93d6f5},
}

@Article{Abbes2018,
  author                  = {Abbes, H. and Gargouri, F.},
  title                   = {MongoDB-Based Modular Ontology Building for Big Data Integration},
  journal                 = {Journal on Data Semantics},
  year                    = {2018},
  volume                  = {7},
  number                  = {1},
  issn                    = {18612032},
  note                    = {cited By 0},
  abbrev_source_title     = {J. Data Semant.},
  abstract                = {Big Data are collections of data sets so large and complex to process using classical database management tools. Their main characteristics are volume, variety and velocity. Although these characteristics accentuate heterogeneity problems, users are always looking for a unified view of the data. Consequently, Big Data integration is a new research area that faces new challenges due to the aforementioned characteristics. Ontologies are widely used in data integration since they represent knowledge as a formal description of a domain of interest. With the advent of Big Data, their implementation faces new challenges due to the volume, variety and velocity dimensions of these data. This paper illustrates an approach to build a modular ontology for Big Data integration that considers the characteristics of big volume, high-speed generation and wide variety of the data. Our approach exploits a NOSQL database, namely MongoDB, and takes advantages of modular ontologies. It follows three main steps: wrapping data sources to MongoDB databases, generating local ontologies and finally composing the local ontologies to get a global one. We equally focus on the implementation of the two last steps. © 2017, Springer-Verlag GmbH Germany.},
  affiliation             = {MIRACL Laboratory, Higher Institute of Computer Science and Multimedia, Sfax University, Sfax, Tunisia},
  author_keywords         = {Big Data; Data integration; MongoDB; NOSQL; Ontology; Ontology merging; Transformation rules},
  correspondence_address1 = {Abbes, H.; MIRACL Laboratory, Higher Institute of Computer Science and Multimedia, Sfax UniversityTunisia; email: abbes.hanen@gmail.com},
  document_type           = {Article},
  doi                     = {10.1007/s13740-017-0081-z},
  keywords                = {Data acquisition; Data integration; Database systems; Metadata; Ontology, Database management; Formal Description; High speed generation; MongoDB; NOSQL; Ontology merging; Transformation rules; Velocity dimensions, Big data},
  language                = {English},
  publisher               = {Springer Berlin Heidelberg},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042312977&doi=10.1007%2fs13740-017-0081-z&partnerID=40&md5=8276319fa5ecef9584cfa46c5089acd9},
}

@Conference{Rayan2018330,
  author              = {Rayan, J.R. and Revanth, M. and Kiran, R.S.S. and Sam, B.B.},
  title               = {Review of effective integration with high cost utility and group analysis notification based best product identification using big data},
  year                = {2018},
  volume              = {2018-January},
  pages               = {330-334},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Int. Conf. Comput. Power, Energy, Inf. Commun., ICCPEIC},
  abstract            = {The system that were present already is using Content based, Collaborative Filtering Hybrid. But the problem is we could not come up proper stability with this Recommendation process. In system that is going to be proposed on this the paper insist on the cold start recommendation system, user input in social media is considered as the recommendation and the products are then after recommended to the public users. In the modification part, apart from the proposed system, User recommendations are accepted only after successful authentication of the Transaction ID and OTP to the user along with the Product details. We use SVM for processing the user Feed backs. This process ensures that only authenticated person can give the recommendations to friends. We cluster Group of same Product and recommend others based on group notification if new purchase is made within the Group. Vulgar Words Reviews are filtered and Alerted to the other Users. © 2017 IEEE.},
  affiliation         = {Computer Science Dept., Sathyabama University, Chennai, India},
  author_keywords     = {Alerted; Cold start; Collaborative Filtering; OTP; SVM; Transaction ID; Vulgar Words},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICCPEIC.2017.8290387},
  isbn                = {9781509043248},
  journal             = {6th International Conference on Computation of Power, Energy, Information and Communication, ICCPEIC 2017},
  keywords            = {Collaborative filtering, Alerted; Cold start; Cold-start Recommendations; Group analysis; Product identification; Transaction id; User recommendations; Vulgar Words, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046700913&doi=10.1109%2fICCPEIC.2017.8290387&partnerID=40&md5=47e9c06949f2f30155e5903dace0c835},
}

@Conference{Amaro20181046,
  author              = {Amaro, N. and Pina, J.M.},
  title               = {Big data in power systems leveraging grid optimization and wave energy integration},
  year                = {2018},
  editor              = {Mendonca J.P., Jardim-Goncalves R., Martins J., Zarli A., Marques M., Pallot M.},
  volume              = {2018-January},
  pages               = {1046-1054},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Int. Conf. Eng., Technol. Innov.: Eng., Technol. Innov. Manag. Beyond: New Challenges, New Approaches, ICE/ITMC - Proc.},
  abstract            = {Power systems have been through different challenges and technological innovations in the last years and are rapidly evolving into digital systems through the deployment of the smart grids concept. Producing large amounts of data, power systems can benefit from the application of big data analytics which can help leveraging the optimization processes going on in power grids nowadays. The whole value of chain of electric power can benefit from the application of big data techniques. This paper presents a short overview of possible applications and challenges that still need to be considered for this synergy to grow. Under the framework of an H2020 funded project named BigDataOcean, a case study will be described, showing how a data-driven approach can foster the development of offshore renewable sources using the example of wave energy. © 2017 IEEE.},
  affiliation         = {R and D Nester Centro de Investigação em Energia REN - State Grid, S.A., Lisbon, Portugal; Centre of Technology and Systems (CTS), UNINOVA, Caparica, Portugal},
  author_keywords     = {big data; BigDataOcean; wave energy},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICE.2017.8279997},
  isbn                = {9781538607749},
  journal             = {2017 International Conference on Engineering, Technology and Innovation: Engineering, Technology and Innovation Management Beyond 2020: New Challenges, New Approaches, ICE/ITMC 2017 - Proceedings},
  keywords            = {Automobile engines; Electric power transmission networks; Engineering research; Smart power grids; Wave energy conversion, Big Data Analytics; BigDataOcean; Data-driven approach; Grid optimization; Large amounts of data; Renewable sources; Technological innovation; Wave energy, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047553886&doi=10.1109%2fICE.2017.8279997&partnerID=40&md5=56601398615ef6ba3bfdabe4dac81acd},
}

@Article{LeFèvre201873,
  author                  = {Le Fèvre, C. and Poty, L. and Noël, G.},
  title                   = {Big data, generalities and integration in radiotherapy [Les big data, généralités et intégration en radiothérapie]},
  journal                 = {Cancer/Radiotherapie},
  year                    = {2018},
  volume                  = {22},
  number                  = {1},
  pages                   = {73-84},
  issn                    = {12783218},
  note                    = {cited By 0},
  abbrev_source_title     = {Cancer Radiother.},
  abstract                = {The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable. © 2017},
  affiliation             = {Département universitaire de radiothérapie, centre Paul-Strauss, unicancer, 3, rue de la Porte-de-l'Hôpital, Strasbourg cedex, 67065, France; Département informatique, centre Paul-Strauss, unicancer, 3, rue de la Porte-de-l'Hôpital, Strasbourg cedex, 67065, France; Laboratoire EA 3430, fédération de médecine translationnelle de Strasbourg (FMTS), université de Strasbourg, Strasbourg, 67000, France},
  author_keywords         = {Big data; Cancer; Genomics; Predictive model; Radiosensitivity; Radiotherapy},
  coden                   = {CARAF},
  correspondence_address1 = {Noël, G.; Laboratoire EA 3430, fédération de médecine translationnelle de Strasbourg (FMTS), université de StrasbourgFrance; email: gnoel@strasbourg.unicancer.fr},
  document_type           = {Short Survey},
  doi                     = {10.1016/j.canrad.2017.04.013},
  keywords                = {cancer radiotherapy; human; integration; personalized medicine; priority journal; radiosensitivity; Short Survey; clinical decision making; factual database; information processing; neoplasm; radiation tolerance; statistics and numerical data, Clinical Decision-Making; Data Collection; Databases, Factual; Humans; Neoplasms; Precision Medicine; Radiation Tolerance},
  language                = {English; French},
  publisher               = {Elsevier Masson SAS},
  pubmed_id               = {29150191},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035084253&doi=10.1016%2fj.canrad.2017.04.013&partnerID=40&md5=a782a29ad102f3fbb05373237015b1b4},
}

@Article{Sagi2018105,
  author                  = {Sagi, T. and Gal, A.},
  title                   = {Non-binary evaluation measures for big data integration},
  journal                 = {VLDB Journal},
  year                    = {2018},
  volume                  = {27},
  number                  = {1},
  pages                   = {105-126},
  issn                    = {10668888},
  note                    = {cited By 0},
  abbrev_source_title     = {VLDB J.},
  abstract                = {The evolution of data accumulation, management, analytics, and visualization has led to the coining of the term big data, which challenges the task of data integration. This task, common to any matching problem in computer science involves generating alignments between structured data in an automated fashion. Historically, set-based measures, based upon binary similarity matrices (match/non-match), have dominated evaluation practices of matching tasks. However, in the presence of big data, such measures no longer suffice. In this work, we propose evaluation methods for non-binary matrices as well. Non-binary evaluation is formally defined together with several new, non-binary measures using a vector space representation of matching outcome. We provide empirical analyses of the usefulness of non-binary evaluation and show its superiority over its binary counterparts in several problem domains. © 2017, Springer-Verlag GmbH Germany.},
  affiliation             = {University of Haifa, Haifa, Israel; Technion - Israel Institute of Technology, Haifa, Israel},
  author_keywords         = {Data integration; Evaluation; Matching},
  correspondence_address1 = {Sagi, T.; University of HaifaIsrael; email: tsagi@is.haifa.ac.il},
  document_type           = {Article},
  doi                     = {10.1007/s00778-017-0489-y},
  keywords                = {Bins; Data integration; Data visualization; Information management; Matrix algebra; Vector spaces, Data accumulation; Empirical analysis; Evaluation; Evaluation measures; Evaluation methods; Matching; Matching problems; Vector space representation, Big data},
  language                = {English},
  publisher               = {Springer New York LLC},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032511692&doi=10.1007%2fs00778-017-0489-y&partnerID=40&md5=c78097e8838caa8007d898f8011c88d1},
}

@Article{Hegazi2018207,
  author              = {Hegazi, M.O. and Saini, D.K. and Zia, K.},
  title               = {Moving from heterogeneous data sources to big data: Interoperability and integration issues},
  journal             = {International Journal of Advanced Computer Science and Applications},
  year                = {2018},
  volume              = {9},
  number              = {10},
  pages               = {207-212},
  issn                = {2158107X},
  note                = {cited By 0},
  abbrev_source_title = {Intl. J. Adv. Comput. Sci. Appl.},
  abstract            = {Heterogeneous databases now facing an emerging challenge of moving towards big data. These databases are adhoc polyglot systems, complex, and NoSQL tools which are semantically annotated. Integration of these heterogeneous databases becoming very challenging because of big data analytics is integrating human and machines contexts. In this paper, an attempt is made to study heterogeneous databases and their interoperability issues and integration issues, their impact on analysis of data. The data science has grown exponentially and a new paradigm has emerged which is of integration of heterogeneous data to big data. Information, knowledge and decision making become easier but the size of databases has grown and it became big data. © 2015 The Science and Information (SAI) Organization Limited.},
  affiliation         = {College of Computer Engineering and Sciences, Prince Sattam Bin Abdulaziz University, Al-Kharj, Saudi Arabia; Faculty of Computing and Information Technology, Sohar University, Sohar, Oman},
  author_keywords     = {Analytics and intelligence; Big data; Heterogeneous databases; Integration; Interoperability},
  document_type       = {Article},
  doi                 = {10.14569/IJACSA.2018.091025},
  language            = {English},
  publisher           = {Science and Information Organization},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057270850&doi=10.14569%2fIJACSA.2018.091025&partnerID=40&md5=a697687ae9d184eba276dee5286c5a83},
}

@Article{Hajoui20187323,
  author                  = {Hajoui, O. and Dehbi, R. and Talea, M. and Batouta, Z.I. and Bakhouyi, A.},
  title                   = {An approach for big data interoperability},
  journal                 = {Journal of Engineering and Applied Sciences},
  year                    = {2018},
  volume                  = {13},
  number                  = {17},
  pages                   = {7323-7328},
  issn                    = {1816949X},
  note                    = {cited By 0},
  abbrev_source_title     = {J. Eng. Appl. Sci.},
  abstract                = {NoSQL databases are increasingly used in big data and real-time web applications. But these databases are heterogeneous. They offer dfferent data storage models, implementations and languages to developers andusers. Ths wide variety of platforms makes it difficult data interoperability, data integration and even data migration from one system to another. Ths study proposes a literature review of study related to big data interoperability, the purpose of this study is to present and discuss the proposed solutions. Although, these solutions are ambitious, they neglect the semantic aspect of data that is comidered a main axis in an effective solution to data interoperability. In hs study, we present a new approach to data interoperability for NoSQL databases, inpahcular, it is addresses the data semantics problem. © Medwell Journals, 2018.},
  affiliation             = {LTI Laboratory, Faculty of Science Ben M'sik, Casablanca, Morocco; LR21 Laboratory, Faculty of Science Ain Chock, Hassan I1 University, Casablanca, Morocco},
  author_keywords         = {Big data interoperability; NoSQL databases; Ontologies; OWL; Persistence; Polyglot},
  correspondence_address1 = {Hajoui, O.; LTI Laboratory, Faculty of Science Ben M'sikMorocco},
  document_type           = {Article},
  doi                     = {10.3923/jeasci.2018.7323.7328},
  language                = {English},
  publisher               = {Medwell Journals},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055943214&doi=10.3923%2fjeasci.2018.7323.7328&partnerID=40&md5=dc010cb77151d8a17e293852b9dfbef4},
}

@Article{Tian2018452,
  author                  = {Tian, G.},
  title                   = {Integration of internet language and culture information resources based on big data},
  journal                 = {IPPTA: Quarterly Journal of Indian Pulp and Paper Technical Association},
  year                    = {2018},
  volume                  = {30},
  number                  = {8},
  pages                   = {452-456},
  issn                    = {03795462},
  note                    = {cited By 0},
  abbrev_source_title     = {IPPTA},
  abstract                = {In order to realize the effective utilization of the cultural information resources of the network language, based on the large data, a network language culture information resource integration system was designed. The integration platform of language information culture resources adopted the MVC composite design pattern in the construction of the standard three layers architecture. The integration system of language document information resources, the integration system of language and geographic information resources, and the interactive system of language and network information resources were integrated. Finally, the expected effect of the integration of language and cultural network information resources was realized. The design of the front interface of the integration system and the setting of the background information management were completed. The results showed that the resource integration platform could effectively use the network language and cultural information resources. Therefore, it improves the utilization of resources. © Indian Pulp and Paper Technical Association 2018. All rights reserved.},
  affiliation             = {Weinan Normal University, Weinan, China},
  author_keywords         = {Information resources; Network language culture; Resource integration platform; Resource integration system},
  coden                   = {IPPTD},
  correspondence_address1 = {Tian, G.; Weinan Normal UniversityChina},
  document_type           = {Article},
  keywords                = {Big data; Data integration, Background information; Composite design pattern; Geographic information; Information resource; Information resource integrations; Network language; Resource integration; Utilization of resources, Information management},
  language                = {English},
  publisher               = {Indian Pulp and Paper Technical Association},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061716811&partnerID=40&md5=a89ef9c98910bad9379a7ab7b579a393},
}

@Conference{Sazontev2018238,
  author                  = {Sazontev, V.V.},
  title                   = {Methods for big data integration in distributed computation environments},
  year                    = {2018},
  editor                  = {Kalinichenko L., Manolopoulos Y., Sukhomlin V., Skvortsov N., Stupnikov S.},
  volume                  = {2277},
  pages                   = {238-244},
  publisher               = {CEUR-WS},
  note                    = {cited By 0},
  abbrev_source_title     = {CEUR Workshop Proc.},
  abstract                = {One of the main challenges in data integration is to create an extensible end-to-end system, which will perform not only extraction, but also schema alignment and entity resolution techniques. This is even more challenging in a world of the big data, when we have to deal with the large number of heterogeneous data sources. In this case the system has to be automatic and less user depended. This paper aims to overview and analyze the modern approaches and systems to successfully perform big data integration. This work is performed as a master thesis, which is aimed to propose an architecture of the system to perform integration of heterogenous sources in a distributed computation environment, implement and apply it to a real-world problem of e-commerce domain as a part of master thesis. © 2018 CEUR-WS. All Rights Reserved.},
  affiliation             = {Lomonosov Moscow State University, Moscow, Russian Federation},
  author_keywords         = {Big data integration, Automatic entity resolution},
  correspondence_address1 = {Sazontev, V.V.; Lomonosov Moscow State UniversityRussian Federation; email: vladimir.sazontyev@gmail.com},
  document_type           = {Conference Paper},
  issn                    = {16130073},
  journal                 = {CEUR Workshop Proceedings},
  keywords                = {Big data; Distributed computer systems, Distributed computation environments; E-commerce domains; End-to-end systems; Entity resolutions; Heterogeneous data sources; Real-world problem; Schema alignments, Data integration},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059807461&partnerID=40&md5=9208ba3bc5faea1cd909cc62610e02ef},
}

@Conference{Gagliardelli20181015,
  author                  = {Gagliardelli, L. and Zhu, S. and Simonini, G. and Bergamaschi, S.},
  title                   = {Bigdedup: A big data integration toolkit for duplicate detection in industrial scenarios},
  year                    = {2018},
  editor                  = {Wognum N., Stjepandic J., Pellicciari M., Bil C., Peruzzini M.},
  volume                  = {7},
  pages                   = {1015-1023},
  publisher               = {IOS Press BV},
  note                    = {cited By 0},
  abbrev_source_title     = {Adv. Transdiscipl. Eng.},
  abstract                = {Duplicate detection aims to identify different records in data sources that refer to the same real-world entity. It is a fundamental task for: item catalogs fusion, customer databases integration, fraud detection, and more. In this work we present BigDedup, a toolkit able to detect duplicate records on Big Data sources in an efficient manner. BigDedup makes available the state-of-the-art duplicate detection techniques on Apache Spark, a modern framework for distributed computing in Big Data scenarios. It can be used in two different ways: (i) through a simple graphic interface that permit to the user to process structured and unstructured data in a fast and effective way; (ii) as a library that provides different components that can be easily extended and customized. In the paper we show how to use BigDedup and its usefulness through some industrial examples. © 2018 The authors and IOS Press.},
  affiliation             = {University of Modena and Reggio Emilia, Italy},
  author_keywords         = {Big Data; Data Integration; Duplicate detection; Entity Resolution; Record Linkage},
  correspondence_address1 = {Gagliardelli, L.; University of Modena and Reggio EmiliaItaly; email: luca.gagliardelli@unimore.it},
  document_type           = {Conference Paper},
  doi                     = {10.3233/978-1-61499-898-3-1015},
  isbn                    = {9781614994398},
  journal                 = {Advances in Transdisciplinary Engineering},
  keywords                = {Data integration; Distributed computer systems, Customer database; Duplicate detection; Entity resolutions; Graphic interfaces; Industrial scenarios; Real-world entities; Record linkage; Unstructured data, Big data},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057972161&doi=10.3233%2f978-1-61499-898-3-1015&partnerID=40&md5=0b807fc37ee87f6ef6d3ea263953deca},
}

@Article{Wu20184183,
  author                  = {Wu, G. and Saghir, V.},
  title                   = {Financial resource integration algorithm of virtual enterprise in big data environment},
  journal                 = {Journal of Intelligent and Fuzzy Systems},
  year                    = {2018},
  volume                  = {35},
  number                  = {4},
  pages                   = {4183-4194},
  issn                    = {10641246},
  note                    = {cited By 0},
  abbrev_source_title     = {J. Intelligent Fuzzy Syst.},
  abstract                = {The current resource integration algorithm lacks the consideration of users' needs, which can cause high violation of service-level agreement and poor data quality after integration. It affects the energy consumption and service quality of data center. To address this problem, a financial resource integration algorithm of virtual enterprise based on improved artificial bee colony in big data environment is proposed in this paper. The improved PageRank algorithm is used to extract the financial resource of virtual enterprise. The extracted resource is transformed. From the unified data resource centralization after transformation, service resources that satisfy users' needs and constraints are selected and combined. An improved artificial bee colony algorithm is applied to dynamically integrate service resources for different needs. Experimental results show that the proposed algorithm can effectively reduce the energy consumption of the data center, improve the data quality and user service satisfaction. The advantages and feasibility of the proposed algorithm in the integration of virtual enterprise financial resources under the big data environment are verified. © 2018 - IOS Press and the authors. All rights reserved.},
  affiliation             = {School of Economics and Management, Huainan Normal University, Huainan, 232038, China; NYU, Courant Institute of Mathematical Sciences, New York, NY, United States},
  author_keywords         = {Big data environment; enterprise financial resource; PageRank algorithm; resource integration; virtual resource},
  correspondence_address1 = {Wu, G.; School of Economics and Management, Huainan Normal UniversityChina; email: roywu1818@126.com},
  document_type           = {Article},
  doi                     = {10.3233/JIFS-169739},
  keywords                = {Data integration; Energy utilization; Evolutionary algorithms; Finance; Green computing; Integration; Metadata; Optimization; Quality of service; Virtual addresses; Virtual corporation, Artificial bee colonies; Artificial bee colony algorithms; Financial resources; Improved PageRank algorithms; PageRank algorithm; Resource integration; Service Level Agreements; Virtual resource, Big data},
  language                = {English},
  publisher               = {IOS Press},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056129143&doi=10.3233%2fJIFS-169739&partnerID=40&md5=8186e30ed140d0f463250349806a06e4},
}

@Conference{Ivaschenko2018248,
  author              = {Ivaschenko, A.V. and Ilyasova, N.Yu. and Khorina, A.A. and Isayko, V.A. and Krupin, D.N. and Bolotsky, V.A. and Sitnikov, P.V.},
  title               = {Integration issues of big data analysis on social networks},
  year                = {2018},
  editor              = {Fursov V., Goshin E., Kudryashov D., Sobolewski M.},
  volume              = {2212},
  pages               = {248-254},
  publisher           = {CEUR-WS},
  note                = {cited By 0},
  abbrev_source_title = {CEUR Workshop Proc.},
  abstract            = {Nowadays Social Media becomes one of the major providers of Big Data for analysis of users’ behaviour, focus, trends, and deviations. One user can be presented in several social networks by various avatars. Most users have different dynamics of data processing and generation. In order to provide a solution capable to deal with this, there was developed and implemented a software library for integration with a number of social networks. This paper describes the problem, solution architecture and technical details of its implementation supported by the results of simulation and real data analysis for a number of popular social networks. © 2018 CEUR-WS. All rights reserved.},
  affiliation         = {Samara National Research University, Moskovskoe Shosse 34А, Samara, 443086, Russian Federation; Image Processing Systems Institute, Branch of the Federal Scientific Research Centre “Crystallography and Photonics” of Russian Academy of Sciences, Molodogvardeyskaya str. 151, Samara, 443001, Russian Federation; IPSI SEC “Open Code”, Yarmarochnaya Str. 55, Samara, 443001, Russian Federation; ITMO University, Birzhevaya liniya 14 lit. A, Saint-Petersburg, 199034, Russian Federation},
  document_type       = {Conference Paper},
  issn                = {16130073},
  journal             = {CEUR Workshop Proceedings},
  keywords            = {Data handling; Information analysis; Nanotechnology; Social networking (online); Social sciences computing, Integration issues; Real data analysis; Social media; Software libraries; Solution architectures; Technical details, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055797233&partnerID=40&md5=68dac7061655786bb081da4c1c05193a},
}

@Article{Mehenni2018,
  author                  = {Mehenni, A. and Alimazighi, Z. and Bouktir, T. and Ahmed-Nacer, M.},
  title                   = {An optimal big data processing for smart grid based on hybrid MDM/R architecture to strengthening RE integration and EE in datacenter},
  journal                 = {Journal of Ambient Intelligence and Humanized Computing},
  year                    = {2018},
  issn                    = {18685137},
  note                    = {cited By 0; Article in Press},
  abbrev_source_title     = {J. Ambient Intell. Humanized Comput.},
  abstract                = {Supply chain is a hard business area, where you need to have a perfect balance between demand and supply, day in and day out, by an intricate system that sits underneath it all. Achieving such a system by meeting the ambitious targets of the agreement on climate change can only be achieved through an effective combination of energy efficiency and renewable energy integration. The uncertainty and variability of renewable energy generation can pose challenges for grid operators and can requires additional actions to balance the system. Significant researches which aim is to improve energy efficiency of data center indicates that operating reserves could be procured from many complex and costly techniques. In this paper, we investigate the problem from scheduling of workloads in a data center in order to minimize its energy consumption budget, minimize the conventional grid dependence, and maximize the renewable energy provided to data center, by the ability to temporarily delay or degrade service, with a modified supply-following algorithm. This algorithm attempts to align power consumption with the amount of wind power available, while minimizing the time by which jobs exceed their deadlines. Modification of the algorithm has been performed in the direction of big data processing (wind trace, workload requests, prices, …), servers management. This modification is performed by jobs classification into predefined classes using the classification and regression trees algorithm. New hybrid architecture that manages the Meter Data Management Repository MDM/R was introduced using MapReduce programming model for ETL process and Massive Parallel Processing Database for requests which strongly influences the accuracy and the speediness of the scheduler. © 2018, Springer-Verlag GmbH Germany, part of Springer Nature.},
  affiliation             = {Université Sciences Technologies Houari Boumediene, Bab Ezzouar, Algiers, Algeria; Université Ferhat Abbas Sétif 1, Sétif, Algeria},
  author_keywords         = {Big data processing; ETL; Job scheduler; Renewable energy integration; Server state management},
  correspondence_address1 = {Mehenni, A.; Université Sciences Technologies Houari BoumedieneAlgeria; email: mehennisalim2000@yahoo.fr},
  document_type           = {Article in Press},
  doi                     = {10.1007/s12652-018-1097-4},
  keywords                = {Budget control; Climate change; Computer architecture; Data integration; Electric power transmission networks; Energy efficiency; Energy utilization; Green computing; Information management; Integration; Scheduling; Smart power grids; Supply chains; Trees (mathematics); Wind power, Classification and regression tree; Job scheduler; Map-reduce programming; Meter data management; Renewable energy generation; Renewable energy integrations; State management; Uncertainty and variability, Big data},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055702050&doi=10.1007%2fs12652-018-1097-4&partnerID=40&md5=60280e971d5d0564cacc7048f2c1cc92},
}

@Article{Peters2018653,
  author              = {Peters, D.P.C. and Burruss, N.D. and Rodriguez, L.L. and McVey, D.S. and Elias, E.H. and Pelzel-Mccluskey, A.M. and Derner, J.D. and Schrader, T.S. and Yao, J. and Pauszek, S.J. and Lombard, J. and Archer, S.R. and Bestelmeyer, B.T. and Browning, D.M. and Brungard, C.W. and Hatfield, J.L. and Hanan, N.P. and Herrick, J.E. and Okin, G.S. and Sala, O.E. and Savoy, H. and Vivoni, E.R.},
  title               = {An integrated view of complex landscapes: A big data-model integration approach to transdisciplinary science},
  journal             = {BioScience},
  year                = {2018},
  volume              = {68},
  number              = {9},
  pages               = {653-669},
  issn                = {00063568},
  note                = {cited By 2},
  abbrev_source_title = {BioScience},
  abstract            = {The Earth is a complex system comprising many interacting spatial and temporal scales. We developed a transdisciplinary data-model integration (TDMI) approach to understand, predict, and manage for these complex dynamics that focuses on spatiotemporal modeling and cross-scale interactions. Our approach employs human-centered machine-learning strategies supported by a data science integration system (DSIS). Applied to ecological problems, our approach integrates knowledge and data on (a) biological processes, (b) spatial heterogeneity in the land surface template, and (c) variability in environmental drivers using data and knowledge drawn from multiple lines of evidence (i.e., observations, experimental manipulations, analytical and numerical models, products from imagery, conceptual model reasoning, and theory). We apply this transdisciplinary approach to a suite of increasingly complex ecologically relevant problems and then discuss how information management systems will need to evolve into DSIS to allow other transdisciplinary questions to be addressed in the future. © Published by Oxford University Press on behalf of American Institute of Biological Sciences 2018.},
  affiliation         = {US Department of Agriculture, Agricultural Research Service, Jornada Experimental Range Unit, Jornada Basin Long Term Ecological Research Program, Las Cruces, NM, United States; New Mexico State University, Jornada Experimental Range Unit, Jornada Basin Long Term Ecological Research Program, Las Cruces, NM, United States; US Department of Agriculture, Agricultural Research Service, Plum Island Animal Disease Center, Orient Point, NY, United States; US Department of Agriculture, Agricultural Research Service, Center for Grain and Animal Health Research, Arthropod-Borne Animal Diseases Research Unit, Manhattan, KS, United States; US Department of Agriculture, Animal and Plant Health Inspection Service, Veterinary Services, Fort Collins, CO, United States; US Department of Agriculture, Agricultural Research Service, Rangeland Resources and Systems Research Unit, Cheyenne, WY, United States; School of Natural Resources and the Environment, University of Arizona, Tucson, United States; Department of Plant and Environmental Sciences, Jornada Basin Long Term Ecological Research Program, New Mexico State University, Las Cruces, United States; US Department of Agriculture, Agricultural Research Service, National Laboratory for Agriculture and the Environment, Ames, IA, United States; Department of Geography, University of California, Los Angeles, United States; School of Life Sciences, Arizona State University, Tempe, United States; School of Earth and Space Exploration, School of Sustainable Engineering and the Built Environment, Arizona State University, Tempe, United States},
  author_keywords     = {Cross-scale interactions; Data science; Earth science; Landscape ecology; Machine learning},
  coden               = {BISNA},
  document_type       = {Article},
  doi                 = {10.1093/biosci/biy069},
  language            = {English},
  publisher           = {Oxford University Press},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055168309&doi=10.1093%2fbiosci%2fbiy069&partnerID=40&md5=f45fd9db1d3b25f4d11200317e071c36},
}

@Article{Hui2018101,
  author                  = {Hui, J. and Li, L. and Zhang, Z.},
  title                   = {Integration of big data: A survey},
  journal                 = {Communications in Computer and Information Science},
  year                    = {2018},
  volume                  = {901},
  pages                   = {101-121},
  issn                    = {18650929},
  note                    = {cited By 0},
  abbrev_source_title     = {Commun. Comput. Info. Sci.},
  abstract                = {Data integration provides users a uniform interface for multiple heterogonous data sources. This problem has attracted a large amount of attention from both research and industry areas. In this paper, we overview the state-of-art approaches in data integration which are roughly divided into five parts: schema matching, entity resolution, data fusion, integration system, and new problems arisen. © Springer Nature Singapore Pte Ltd. 2018.},
  affiliation             = {Department of Computer Science and Technology, Heilongjiang University, Harbin, China},
  author_keywords         = {Data fusion; Data integration; Entity resolution; Schema matching},
  correspondence_address1 = {Li, L.; Department of Computer Science and Technology, Heilongjiang UniversityChina; email: lilingli_grace@163.com},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-981-13-2203-7_9},
  editor                  = {Gan Y., Song X., Zhou Q., Jing W., Wang Y., Lu Z.},
  isbn                    = {9789811322020},
  keywords                = {Big data; Data fusion; Industrial research, Data-sources; Entity resolutions; Integration systems; Large amounts; Schema matching; Uniform interface, Data integration},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053937291&doi=10.1007%2f978-981-13-2203-7_9&partnerID=40&md5=83365caeeeb380fc685d2fad5f5b8729},
}

@Article{Kathiravelu2018,
  author                  = {Kathiravelu, P. and Sharma, A. and Galhardas, H. and Van Roy, P. and Veiga, L.},
  title                   = {On-demand big data integration: A hybrid ETL approach for reproducible scientific research},
  journal                 = {Distributed and Parallel Databases},
  year                    = {2018},
  issn                    = {09268782},
  note                    = {cited By 0; Article in Press},
  abbrev_source_title     = {Distrib Parallel Databases},
  abstract                = {Scientific research requires access, analysis, and sharing of data that is distributed across various heterogeneous data sources at the scale of the Internet. An eager extract, transform, and load (ETL) process constructs an integrated data repository as its first step, integrating and loading data in its entirety from the data sources. The bootstrapping of this process is not efficient for scientific research that requires access to data from very large and typically numerous distributed data sources. A lazy ETL process loads only the metadata, but still eagerly. Lazy ETL is faster in bootstrapping. However, queries on the integrated data repository of eager ETL perform faster, due to the availability of the entire data beforehand. In this paper, we propose a novel ETL approach for scientific data integration, as a hybrid of eager and lazy ETL approaches, and applied both to data as well as metadata. This way, hybrid ETL supports incremental integration and loading of metadata and data from the data sources. We incorporate a human-in-the-loop approach, to enhance the hybrid ETL, with selective data integration driven by the user queries and sharing of integrated data between users. We implement our hybrid ETL approach in a prototype platform, Óbidos, and evaluate it in the context of data sharing for medical research. Óbidos outperforms both the eager ETL and lazy ETL approaches, for scientific research data integration and sharing, through its selective loading of data and metadata, while storing the integrated data in a scalable integrated data repository. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
  affiliation             = {Emory University School of Medicine, Atlanta, United States; INESC-ID Lisboa/Instituto Superior Técnico, Universidade de Lisboa, Lisboa, Portugal; Université catholique de Louvain, Louvain-la-Neuve, Belgium},
  author_keywords         = {Big data; Data integration; ETL (extract, transform, and load); Scientific research},
  coden                   = {DAATE},
  correspondence_address1 = {Kathiravelu, P.; Université catholique de LouvainBelgium; email: pradeeban.kathiravelu@emory.edu},
  document_type           = {Article in Press},
  doi                     = {10.1007/s10619-018-7248-y},
  keywords                = {Big data; Data mining; Metadata, Data and metadata; Distributed data sources; ETL (extract, transform, and load); Heterogeneous data sources; Human-in-the-loop; Scientific data integration; Scientific research datum; Scientific researches, Data integration},
  language                = {English},
  publisher               = {Springer New York LLC},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053234563&doi=10.1007%2fs10619-018-7248-y&partnerID=40&md5=e2aaa08e9590385d7950cec593445168},
}

@Conference{Barbosa20181DUMMY,
  author              = {Barbosa, L. and Crescenzi, V. and Dong, X.L. and Merialdo, P. and Piai, F. and Qiu, D. and Shen, Y. and Srivastava, D.},
  title               = {Lessons Learned and Research Agenda for Big Data Integration of Product Specifications (Discussion Paper)},
  year                = {2018},
  editor              = {Bergamaschi S., Di Noia T., Maurino A.},
  volume              = {2161},
  pages               = {1DUMMY},
  publisher           = {CEUR-WS},
  note                = {cited By 0},
  abbrev_source_title = {CEUR Workshop Proc.},
  abstract            = {The product domain represents a challenging scenario for developing and evaluating big data integration solutions: the number of sources providing product specifications is very large, and ever increasing over time. The volume of available data is impressive, and these data keep changing very frequently. In this paper, we present ongoing efforts, challenges and our research agenda to address big data integration for product specifications. © 2018 CEUR-WS. All rights reserved.},
  affiliation         = {Universidade Federal de Pernambuco, Brazil; Roma Tre University, Italy; Amazon, United States; Wanderio, United States; Shanghai Jiao Tong University, China; AT and T Labs – Research, United States},
  document_type       = {Conference Paper},
  issn                = {16130073},
  journal             = {CEUR Workshop Proceedings},
  keywords            = {Data integration; Database systems; Specifications, Number of sources; Product specifications; Research agenda, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051852461&partnerID=40&md5=a1666af918df44b353c4907c13656240},
}

@Article{Li2018,
  author                  = {Li, L.},
  title                   = {Analysis of consumer behavior based on network integration data in the background of big data},
  journal                 = {Journal of Advanced Oxidation Technologies},
  year                    = {2018},
  volume                  = {21},
  number                  = {2},
  issn                    = {12038407},
  note                    = {cited By 0},
  abbrev_source_title     = {J. Adv. Oxid. Technol.},
  abstract                = {With the development of Internet technology, more and more people choose online shopping. The rapid development of online shopping also faces many challenges, such as privacy issues and data security issues, and the existence of these problems will affect the behavior of consumers. Therefore, the study of consumer behavior in the environment of big data is an urgent need for the development of Internet market in big data age. The era of big data was taken as a social background; then based on the theory of consumer behavior, the concept, characteristics and influence of big data itself were focused on, and the characteristics and development status of online shopping mode were combined; furthermore, the consumer behavior model based on network integration data in big data environment was established, and the theory was verified through empirical analysis. © 2018 Walter de Gruyter GmbH. All rights reserved.},
  affiliation             = {Zibo Vocational Institute, Zibo, Shandong, China},
  art_number              = {201807876},
  author_keywords         = {Big Data; Consumer Behavior Analysis; Data Mining; Network Integration Data; Online Shopping},
  correspondence_address1 = {Li, L.; Zibo Vocational InstituteChina},
  document_type           = {Article},
  doi                     = {10.26802/jaots.2018.07876},
  language                = {English},
  publisher               = {J.AOTs Sycamore Global Publications LLC},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051344861&doi=10.26802%2fjaots.2018.07876&partnerID=40&md5=c0f7f92ae339913ce86f02bb776d9973},
}

@Article{Li2018a,
  author                  = {Li, Y.},
  title                   = {English practical talents cultivation based on the integration of big data and industry and education},
  journal                 = {Journal of Advanced Oxidation Technologies},
  year                    = {2018},
  volume                  = {21},
  number                  = {2},
  issn                    = {12038407},
  note                    = {cited By 0},
  abbrev_source_title     = {J. Adv. Oxid. Technol.},
  abstract                = {With the advent of the big data era, society has put forward new requirements for English talents. In this paper, Business English is taken as an example to construct a model for evaluating and cultivating talents. In order to make use of big data to prove that employers and students of vocational education combine English with practical talents ability, firstly, the generalized regression neural network is optimized by genetic algorithm, and then the genetic algorithm-generalized regression neural network is designed. Secondly, university English major graduates are taken as an example, and the algorithm is tested in this paper: The results of genetic algorithm to optimize the generalized regression neural network for canon matching calculation are in good agreement with the actual situation, and the method is feasible and had certain advantages. © 2018 Walter de Gruyter GmbH. All rights reserved.},
  affiliation             = {School of Foreign Languages, Hubei Polytechnic University, Huangshi, Hubei, 435003, China},
  art_number              = {201806105},
  author_keywords         = {Applied Talents; Big Data; Genetic Algorithm; Integration of Production; Neural Networkd; Teaching},
  correspondence_address1 = {Li, Y.; School of Foreign Languages, Hubei Polytechnic UniversityChina},
  document_type           = {Article},
  doi                     = {10.26802/jaots.2018.06105},
  language                = {English},
  publisher               = {J.AOTs Sycamore Global Publications LLC},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051336985&doi=10.26802%2fjaots.2018.06105&partnerID=40&md5=f8eec339999949b9eca4cf2c61c8ebb4},
}

@Article{Alansari201847,
  author                  = {Alansari, Z. and Anuar, N.B. and Kamsin, A. and Soomro, S. and Belgaum, M.R. and Miraz, M.H. and Alshaer, J.},
  title                   = {Challenges of Internet of Things and big data integration},
  journal                 = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
  year                    = {2018},
  volume                  = {200},
  pages                   = {47-55},
  issn                    = {18678211},
  note                    = {cited By 1},
  abbrev_source_title     = {Lect. Notes Inst. Comput. Sci. Soc. Informatics Telecommun. Eng.},
  abstract                = {The Internet of Things anticipates the conjunction of physical gadgets to the Internet and their access to wireless sensor data which makes it expedient to restrain the physical world. Big Data convergence has put multifarious new opportunities ahead of business ventures to get into a new market or enhance their operations in the current market. considering the existing techniques and technologies, it is probably safe to say that the best solution is to use big data tools to provide an analytical solution to the Internet of Things. Based on the current technology deployment and adoption trends, it is envisioned that the Internet of Things is the technology of the future; while to-day’s real-world devices can provide real and valuable analytics, and people in the real world use many IoT devices. Despite all the advertisements that companies offer in connection with the Internet of Things, you as a liable consumer, have the right to be suspicious about IoT advertisements. The primary question is: What is the promise of the Internet of things concerning reality and what are the prospects for the future. © ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2018.},
  affiliation             = {University of Malaya, Kuala Lumpur, Malaysia; AMA International University, Salmabad, Bahrain; Wrexham Glyndŵr University, Wrexham, United Kingdom; Al-Balqa Applied University, Salt, Jordan},
  author_keywords         = {Big data; Cloud computing; Internet of Things},
  correspondence_address1 = {Miraz, M.H.; AMA International UniversityBahrain; email: m.miraz@gmail.com},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-319-95450-9_4},
  editor                  = {Miraz M.H., Excell P., Ware A., Ali M., Soomro S.},
  isbn                    = {9783319954493},
  keywords                = {Big data; Cloud computing; Data integration, Business ventures; Current technology; Iot devices; Physical world; Real-world; Wireless sensor data, Internet of things},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051120756&doi=10.1007%2f978-3-319-95450-9_4&partnerID=40&md5=aeff3d933c3a08d8986f0485745f3512},
}

@Article{Erkimbaev2018185,
  author                  = {Erkimbaev, A. and Zitserman, V. and Kobzev, G. and Kosinov, A.},
  title                   = {Integration of data on substance properties using big data technologies and domain-specific ontologies},
  journal                 = {Communications in Computer and Information Science},
  year                    = {2018},
  volume                  = {822},
  pages                   = {185-197},
  issn                    = {18650929},
  note                    = {cited By 0},
  abbrev_source_title     = {Commun. Comput. Info. Sci.},
  abstract                = {A new technology for storage and categorization of heterogeneous data on the properties of matter is proposed. Availability of a multitude of heterogeneous data from a variety of sources justifies the use of one of the popular toolkit for Big Data processing, Apache Spark. Its role in the proposed technology is to manage with extensive data warehouse in text files of the JSON format. The first stage of the technology involves the conversion of primary resources (relational databases, digital archives, Web-portals, etc.) to a standardized form of the JSON document. Advantages of JSON-format - the ability to store data and metadata within a text document, accessible perceptions of a person and a computer and support for the hierarchical structures needed to represent complex and irregular data structure. The presence of such data structures is associated with the possible expansion of the subject area: new types of materials, expansion of the nomenclature of properties, and so on. For the semantic integration of resources converted to the JSON format a repository of subject-oriented ontologies is used. The search for data in the JSON document store is implemented through a combination of SPARQL and SQL queries. The first one (addressed to the ontology repository) provide the user with the ability to view and search for adequate and related concepts. The second, accessing the JSON document sets, retrieves the required data from the document body using the capabilities of Apache Spark SQL. The efficiency of the developed technology is tested on the problems of thermophysical data integration with a characteristic for them complexity of the logical structure. © Springer International Publishing AG, part of Springer Nature 2018.},
  affiliation             = {Joint Institute for High Temperatures, Russian Academy of Sciences, Moscow, Russian Federation},
  author_keywords         = {JSON format; Ontology; Semi-structured data; Thermophysical properties},
  correspondence_address1 = {Erkimbaev, A.; Joint Institute for High Temperatures, Russian Academy of SciencesRussian Federation; email: adilbek@ihed.ras.ru},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-319-96553-6_14},
  editor                  = {Kalinichenko L., Skvortsov N., Stupnikov S., Malkov O., Sukhomlin V., Manolopoulos Y.},
  isbn                    = {9783319965529},
  keywords                = {Data integration; Data structures; Data warehouses; Digital storage; Electronic document exchange; Ontology; Portals; Semantics; Structural properties; Thermodynamic properties, Big data technologies; Domain-specific ontologies; Hierarchical structures; Irregular data structures; JSON format; Ontology repositories; Semantic integration; Semi structured data, Big data},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050402100&doi=10.1007%2f978-3-319-96553-6_14&partnerID=40&md5=21384374937c1d707a1302e183ceb8bc},
}

@Conference{Synnergren2018,
  author              = {Synnergren, J. and Ghosheh, N. and Dönnes, P.},
  title               = {Integration of biomedical big data requires efficient batch effect reduction},
  year                = {2018},
  editor              = {Al-Mubaid A.-M., Eulenstein O., Ding Q.},
  volume              = {2018-March},
  publisher           = {The International Society for Computers and Their Applications (ISCA)},
  note                = {cited By 0},
  abbrev_source_title = {Proc. Int. Conf. Bioinform. Comput. Biol., BICOB},
  abstract            = {Efficiency in dealing with batch effects will be the next frontier in large-scale biological data analysis, particularly when involving the integration of different types of datasets. Large-scale omics techniques have quickly developed during the last decade and huge amounts of data are now generated, which has started to revolutionize the area of medical research. With the increase in the volume of data across the whole spectrum of biology, problems related to data analytics are continuously increasing as analysis and interpretation of these large volumes of molecular data has become a real challenge. Tremendous efforts have been made to obtain data from various molecular levels and the most recent trends show that more and more researchers now are trying to integrate data of various molecular types to inform hypotheses and biological questions. Tightly connected to this work are the batch-related biases that commonly are apparent between different datasets, but these problems are often not tackled. In present study the ComBat algorithm was applied and evaluated on two different data integration problems. Results show that the batch effects present in the integrated datasets efficiently could be removed by applying the ComBat algorithm. © 2018 ISCA, BICOB.},
  affiliation         = {Systems Biology Research Center, University of Skövde, Skövde, SE-541 28, Sweden; SciCross AB, Gothia Science Park, Skövde, SE-541 23, Sweden},
  document_type       = {Conference Paper},
  isbn                = {9781943436118},
  journal             = {Proceedings of the 10th International Conference on Bioinformatics and Computational Biology, BICOB 2018},
  keywords            = {Big data; Bioinformatics; Biology, Biological data; Data analytics; Integration problems; Medical research; Molecular data; Molecular levels; Molecular type; Recent trends, Data integration},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048592521&partnerID=40&md5=a46c69b1883b3d069158df6d9e5b4715},
}

@Conference{Kirmse2018175,
  author              = {Kirmse, A. and Kraus, V. and Hoffmann, M. and Meisen, T.},
  title               = {An architecture for efficient integration and harmonization of heterogeneous, distributed data sources enabling big data analytics},
  year                = {2018},
  editor              = {Smialek M., Filipe J., Camp O., Filipe J., Hammoudi S.},
  volume              = {1},
  pages               = {175-182},
  publisher           = {SciTePress},
  note                = {cited By 0},
  abbrev_source_title = {ICEIS - Proc. Int. Conf. Enterp. Inf. Syst.},
  abstract            = {We present a lightweight integration architecture as an enabler for the application of process optimization via Big Data analytics and machine learning in large scale, multi-site manufacturing companies by harmonizing heterogeneous data sources. The reference implementation of the architecture is entirely based on opensource software and makes use of message queuing techniques in combination with Big Data related storage and extraction technologies. The approach specifically targets challenges related to different network zones and security levels in enterprise information architectures and across divergent production sites. Copyright © 2018 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
  affiliation         = {Cybernetics Lab IMA/ZLW and IfU in Aachen, RWTH Aachen University, Dennewartstr. 27, Aachen, 52068, Germany},
  author_keywords     = {Big Data; Hadoop; Industry 4.0; Ingestion and Integration Pattern; OPC UA},
  document_type       = {Conference Paper},
  isbn                = {9789897582981},
  journal             = {ICEIS 2018 - Proceedings of the 20th International Conference on Enterprise Information Systems},
  keywords            = {Data integration; Data mining; Digital storage; Industry 4.0; Information systems; Information use; Integration; Learning systems; Network architecture; Optimization, Distributed data sources; Enterprise information architectures; Hadoop; Heterogeneous data sources; Integration architecture; Integration patterns; OPC UA; Reference implementation, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047753841&partnerID=40&md5=5b16e2a6042e53454df241c7577d060b},
}

@Book{Acakpovi2018193,
  title                   = {Modern electrical grid optimization with the integration of big data and artificial intelligence techniques},
  publisher               = {Nova Science Publishers, Inc.},
  year                    = {2018},
  author                  = {Acakpovi, A. and Asabere, N.Y.},
  volume                  = {29},
  isbn                    = {9781536130775; 9781536130768},
  note                    = {cited By 0},
  abbrev_source_title     = {Adv. in Energy Res.},
  abstract                = {This chapter presents the current state of integration of big data, data mining and artificial intelligence techniques in advanced Energy Systems Optimization. Recent trends in Energy systems were mainly directed towards hybrid energy systems which are made of a combination of two or more different distributed energy resources (DER). Majority of these distributed energy supplies which derived from renewable energy are related to variables that vary randomly in time and that become hardly predictable. The high intermittency observed with solar irradiation, wind speed velocity and direction to mention few, are illustrations of the variability of the DER resources. Massive data collected over years and generated by multiple sensors are sometimes needed to accurately predict most of these stochastic variables and therefore the reality of big data and the intervention of data mining cannot be undermined. Moreover the integration of many DERs into a hybrid energy supply poses the problem of cost optimization and continuity of power supply which have become complex to solve due to the volume of DERs to integrate and the complexity in modelling each individual DER. Traditional optimization solvers for linear and non-linear optimization problems have become obsolete in resolving the current HES optimization problem. In this regard, the need for modern Artificial intelligence techniques best suited for this nature of problem becomes paramount. A comprehensive review of relevant artificial techniques applicable to the optimization of DER has been elaborated in this chapter in addition to a review of relevant software needed to model advanced DERs. © 2018 Nova Science Publishers, Inc. All rights reserved.},
  affiliation             = {Electrical/Electronic Engineering Department, Accra Technical University, Accra, Ghana; Department of Computer Sciences, Accra Technical University, Accra, Ghana},
  author_keywords         = {Artificial Intelligence; Big Data; DER; HES},
  correspondence_address1 = {Acakpovi, A.; Electrical/Electronic Engineering Department, Accra Technical UniversityGhana; email: acakpovia@gmail.com},
  document_type           = {Book Chapter},
  journal                 = {Advances in Energy Research},
  language                = {English},
  pages                   = {193-234},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044541019&partnerID=40&md5=d552f373a6786fc224cc11597e6e3f82},
}

@Article{Fan2018,
  author                  = {Fan, J. and Yan, J. and Ma, Y. and Wang, L.},
  title                   = {Big data integration in remote sensing across a distributed metadata-based spatial infrastructure},
  journal                 = {Remote Sensing},
  year                    = {2018},
  volume                  = {10},
  number                  = {1},
  issn                    = {20724292},
  note                    = {cited By 1},
  abbrev_source_title     = {Remote Sens.},
  abstract                = {Since Landsat-1 first started to deliver volumes of pixels in 1972, the volumes of archived data in remote sensing data centers have increased continuously. Due to various satellite orbit parameters and the specifications of different sensors, the storage formats, projections, spatial resolutions, and revisit periods of these archived data are vastly different. In addition, the remote sensing data received continuously by each data center arrives at a faster code rate; it is best to ingest and archive the newly received data to ensure users have access to the latest data retrieval and distribution services. Hence, an excellent data integration, organization, and management program is urgently needed. However, the multi-source, massive, heterogeneous, and distributed storage features of remote sensing data have not only caused difficulties for integration across distributed data center spatial infrastructures, but have also resulted in the current modes of data organization and management being unable meet the rapid retrieval and access requirements of users. Hence, this paper proposes an object-oriented data technology (OODT) and SolrCloud-based remote sensing data integration and management framework across a distributed data center spatial infrastructure. In this framework, all of the remote sensing metadata in the distributed sub-centers are transformed into the International Standardization Organization (ISO) 19115-based unified format, and then ingested and transferred to the main center by OODT components, continuously or at regular intervals. In the main data center, in order to improve the efficiency of massive data retrieval, we proposed a logical segmentation indexing (LSI) model-based data organization approach, and took SolrCloud to realize the distributed index and retrieval of massive metadata. Finally, a series of distributed data integration, retrieval, and comparative experiments showed that our proposed distributed data integration and management program is effective and promises superior results. Specifically, the LSI model-based data organization and the SolrCloud-based distributed indexing schema was able to effectively improve the efficiency of massive data retrieval.},
  affiliation             = {School of Computer Science, China University of Geoscience, Wuhan, 430074, China; Hubei Key Laboratory of Intelligent Geo-Information Processing, China University of Geosciences Wuhan, Wuhan, 430074, China; Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, 100094, China},
  art_number              = {7},
  author_keywords         = {Data integration; Data management; Distributed data centers; Multi-sourced remote sensing big data; OODT},
  correspondence_address1 = {Yan, J.; School of Computer Science, China University of GeoscienceChina; email: yanjn@cug.edu.cn},
  document_type           = {Article},
  doi                     = {10.3390/rs10010007},
  keywords                = {Big data; Digital storage; Efficiency; Indexing (of information); Information management; LSI circuits; Metadata; Orbits; Remote sensing; Spatial distribution, Comparative experiments; Distributed data; Distributed indexing; Distributed metadata; Distribution services; International standardization organization; Object oriented data; OODT, Data integration},
  language                = {English},
  publisher               = {MDPI AG},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040663529&doi=10.3390%2frs10010007&partnerID=40&md5=eb89918edfdb2b7d8a4bb95970ed803b},
}

@Conference{Liu20171368,
  author                  = {Liu, D. and Ma, L. and Liu, X. and Yu, H. and Tan, H. and Zhao, X. and Zhao, Y. and Lv, G.},
  title                   = {Research on key issues of data integration technology in electric power system in big data environment},
  year                    = {2017},
  volume                  = {2017-January},
  pages                   = {1368-1372},
  publisher               = {Institute of Electrical and Electronics Engineers Inc.},
  note                    = {cited By 2},
  abbrev_source_title     = {IEEE Int. Conf. Commun. Softw. Netw., ICCSN},
  abstract                = {In recent years, the State Grid has built amounts of business systems, e.g. OA, marketing and MIS systems. And it gradually developed into big data. However, with the construction of information increasingly deepening and a sharp increase of data volume, new challenges and inconvenience have been brought out for data seekers. In this paper, an architecture model of data integration in power field was proposed. The key factors in the model, e.g. data acquiring, extracting and integrating were investigated. A new method based on the highly frequent rate of date acquirement was put forward. A concept to build data extraction wrapper through bottom-up pattern and an automating repetitive record detection model for unsupervised learning were also proposed. The architecture model can help users to obtain required data by conducting data integration for information islands, storage of unstructured data in business systems, thus provide convenient service for the staffs in the State Grid. Experimental results show that the proposed approach accomplished duplicate record detection with high accuracy. © 2017 IEEE.},
  affiliation             = {State Grid Shandong Electric Power Research Institute, Jinan, 250003, China; Shandong Zhongshi Yitong Group Co., Ltd., Jinan, 250003, China},
  author_keywords         = {big data; data integration; electric power system; unstructured data; wrapper},
  correspondence_address1 = {Liu, D.; State Grid Shandong Electric Power Research InstituteChina; email: liudonglan2006@126.com},
  document_type           = {Conference Paper},
  doi                     = {10.1109/ICCSN.2017.8230333},
  isbn                    = {9781509038220},
  journal                 = {2017 9th IEEE International Conference on Communication Software and Networks, ICCSN 2017},
  keywords                = {Big data; Digital storage; Electric power systems; Network architecture, Architecture modeling; Business systems; Detection models; Duplicate record detection; Information island; Integration technologies; Unstructured data; wrapper, Data integration},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049113493&doi=10.1109%2fICCSN.2017.8230333&partnerID=40&md5=7910c3f697a1d0bc6da7b4069c2d324a},
}

@Conference{Bilal2017753,
  author              = {Bilal, H.S.M. and Lee, S.},
  title               = {Integration of transtheoretical model with wellness big data for healthy behavior assessment to adoption},
  year                = {2017},
  volume              = {2017-December},
  pages               = {753-756},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Int. Conf. Inf. Commun. Technol. Converg.: ICT Converg. Technolo. Lead. Fourth Ind. Revolut., ICTC},
  abstract            = {Innovative wellness gadgets are the products of convergence of science and technology in this dynamic digital era. It has not been possible before to provide just-in-time intervention to avoid unhealthy behavior. The change in behavior requires the understanding of the behavior theories and then practical implementation of the stages. Transtheoretical model supports to identify the stage of human behavior and the transition for improvement. Behavior analysis is performed through unbiased recording of actions in term of big data. Just-in-time coaching is provided to motivate the users, stage-wise to adopt the healthy behavior without any big deviation. © 2017 IEEE.},
  affiliation         = {Department of Computer Science and Engineering, Kyung Hee University, Suwon, South Korea},
  author_keywords     = {big data; healthy behavior adoption; personalized coaching; Persuasive technologies; transtheoretical model; wellness},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICTC.2017.8190772},
  isbn                = {9781509040315},
  journal             = {International Conference on Information and Communication Technology Convergence: ICT Convergence Technologies Leading the Fourth Industrial Revolution, ICTC 2017},
  keywords            = {Behavioral research; Just in time production, healthy behavior adoption; personalized coaching; Persuasive technology; Transtheoretical models; wellness, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046902279&doi=10.1109%2fICTC.2017.8190772&partnerID=40&md5=69f3a74bcceb2ed60daa24f997375ecc},
}

@Article{Babar201765,
  author                  = {Babar, M. and Arif, F.},
  title                   = {Smart urban planning using Big Data analytics to contend with the interoperability in Internet of Things},
  journal                 = {Future Generation Computer Systems},
  year                    = {2017},
  volume                  = {77},
  pages                   = {65-76},
  issn                    = {0167739X},
  note                    = {cited By 20},
  abbrev_source_title     = {Future Gener Comput Syst},
  abstract                = {The recent growth and expansion in the field of Internet of Things (IoT) is providing a great business prospective in the direction of the new era of smart urban. The insight of the smart urban is extensively preferred, as it improves the excellence of life of citizens, connecting several regulations, that is, smart transportation, smart parking, smart environment, smart healthcare, and so forth. Continuous intensification of the multifaceted urban set-up is extensively challenged by real-time processing of data and smart decision capabilities. Consequently, in this paper, we propose a smart city architecture which is based on Big Data analytics. The proposed scheme is comprised of three modules: (1) data acquisition and aggregation module collects varied and diverse data interrelated to city services, (2) data computation and processing module performs normalization, filtration, processing and data analysis, and (3) application and decision module formulates decisions and initiates events. The proposed architecture is a generic solution for the smart urban planning and variety of datasets is analyzed to validate this architecture. In addition, we tested reliable datasets on Hadoop server to verify the threshold limit value (TLV) and the investigation demonstrates that the proposed scheme offer valuable imminent into the community development systems to get better the existing smart urban architecture. Moreover, the efficiency of proposed architecture in terms of throughput is also shown. © 2017 Elsevier B.V.},
  affiliation             = {National University of Sciences and TechnologyIslamabad, Pakistan},
  author_keywords         = {Big Data analytics; Interoperability; IoT; Smart city},
  coden                   = {FGCSE},
  correspondence_address1 = {Babar, M.; National University of Sciences and TechnologyPakistan; email: babar.phd@students.mcs.edu.pk},
  document_type           = {Article},
  doi                     = {10.1016/j.future.2017.07.029},
  keywords                = {Architecture; Data handling; Internet of things; Interoperability; Smart city; Urban growth; Urban planning; Urban transportation, Community development; Data analytics; Decision capability; Internet of Things (IOT); Processing modules; Proposed architectures; Realtime processing; Threshold limit values, Big data},
  language                = {English},
  publisher               = {Elsevier B.V.},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026257239&doi=10.1016%2fj.future.2017.07.029&partnerID=40&md5=e23b0a566b7d00addb30b18c40e12176},
}

@Book{deOliveiraVeras2017209,
  title                   = {Computational techniques in data integration and big data handling in omics},
  publisher               = {Elsevier Inc.},
  year                    = {2017},
  author                  = {de Oliveira Veras, A.A. and de Sá, P.H.C.G. and da Costa Pinheiro, K. and Barh, D. and Azevedo, V. and Jucá Ramos, R.T. and da Costa da Silva, A.L.},
  volume                  = {1},
  isbn                    = {9780128047491; 9780128046593},
  note                    = {cited By 0},
  abbrev_source_title     = {Omics Technol. and Bio-eng.: Towards Improv. Qual. of Life},
  abstract                = {The term Big Data describes the approaches that are used for the manipulation of large amounts of information that are generated by different knowledge areas, such as Economics, Astronomy, Life Sciences, and Social Networks. Since the advent of Deep Sequencing technologies, which are characterized by large data production per run, Omics sciences require Big Data approaches.Thus, several fields of life science now rely highly on computational processing, large storage capacity, and new algorithms that perform traditional genomic, transcriptomic, and proteomic analyses with specific tools. The challenges that arise from large amounts of collected data (including processing, storage capacity, and sharing) will be overcome as new approaches and technological advances are developed. © 2018 Elsevier Inc. All rights reserved.},
  affiliation             = {Federal University of Para, Belem, Brazil; Federal University of Minas Gerais, Belo Horizonte, Minas Gerais, Brazil; Institute of Integrative Omics and Applied Biotechnology (IIOAB), Purba Medinipur, India},
  author_keywords         = {Big Data; Bioinformatics; Cloud computing; Computational biology; Data mining; NGS; Omics},
  correspondence_address1 = {de Oliveira Veras, A.A.; Federal University of ParaBrazil},
  document_type           = {Book Chapter},
  doi                     = {10.1016/B978-0-12-804659-3.00012-9},
  journal                 = {Omics Technologies and Bio-engineering: Towards Improving Quality of Life},
  language                = {English},
  pages                   = {209-222},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054417617&doi=10.1016%2fB978-0-12-804659-3.00012-9&partnerID=40&md5=a40e1ca9e5de48c2a42e2411e71c6e2f},
}

@Article{Mahmoodi201757,
  author              = {Mahmoodi, J. and Leckelt, M. and van Zalk, M.W.H. and Geukes, K. and Back, M.D.},
  title               = {Big Data approaches in social and behavioral science: four key trade-offs and a call for integration},
  journal             = {Current Opinion in Behavioral Sciences},
  year                = {2017},
  volume              = {18},
  pages               = {57-62},
  issn                = {23521546},
  note                = {cited By 4},
  abbrev_source_title = {Curr. Opin. Behav. Sci.},
  abstract            = {Big Data approaches have given rise to novel methodological tools to investigate human decisions and behaviors beyond what is possible with traditional forms of analysis. Like any other paradigm in the social and behavioral sciences, however, Big Data is not immune to a number of typical trade-offs: (1) Prediction versus explanation, pertaining to the overall research goals; (2) induction versus deduction, regarding the epistemological focus; (3) bigness versus representativeness in sampling approaches; and (4) data access versus scientific independence, addressing the forms of data usage. In this paper, we discuss these trade-offs and how Big Data and traditional approaches typically relate to them, and propose ways to overcome each trade-off by integrating advantages of different research approaches in the social and behavioral sciences with Big Data. © 2017 Elsevier Ltd},
  affiliation         = {University of Geneva, Switzerland; University of Münster, Germany; University of Oxford, United Kingdom},
  document_type       = {Review},
  doi                 = {10.1016/j.cobeha.2017.07.001},
  keywords            = {behavior; behavioral research; behavioral science; decision making; information processing; integration; prediction; priority journal; Review; sociology},
  language            = {English},
  publisher           = {Elsevier Ltd},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026783248&doi=10.1016%2fj.cobeha.2017.07.001&partnerID=40&md5=22f7133ad46e69086fa191b8864a5f81},
}

@Book{Gao201757,
  title                   = {Frameworks for Big Data Integration, Warehousing, and Analytics},
  publisher               = {Elsevier},
  year                    = {2017},
  author                  = {Gao, F.},
  isbn                    = {9780128119693; 9780128119686},
  note                    = {cited By 0},
  abbrev_source_title     = {Big Data Appl. in Power Syst.},
  abstract                = {Big data is a term for large and complex datasets that traditional processing approaches are not suitable to deal with them. Big data usually comes from the Internet, enterprise systems, Internet of Things, and other information systems. Data collection and preparation, storage management, data processing, data analysis, and knowledge presentation would generate new insights to support decision-making and business intelligent operation. Smart grid is a developing trend of electrical power energy industry. The core message is to implement the next generation of cyber-physical systems shaping future energy industry that is based on a deep merge of operational technology and internet information technology. The growth of smart grid is dependent on the availability of high performance computing (HPC) and analytics technology to process a massive amount of data set. Deployment of advanced technologies within smart grid and usage of state-of-the-art computing systems provide utility companies with innovative capabilities. These advances lead to unprecedented explosion of data volumes. As smart grid operations will leverage advanced metering infrastructure to drive more real time decision-making and operational activities, complex event processing and stream computing are needed for the modern smart grid. The chapter discusses one core technique that would support the growth of smart grid, big data with HPC, with a focus on the platform, data integration, warehousing, and analytics that are particularly adaptive to handle a variety of characteristics of energy industry data. Finally, the chapter summarizes and proposes a comprehensive, technical solution for smart grid platform with applications focusing on complementary operation of multiform energy system that supports all aspects within a data lifetime cycle, e.g., acquisition, storage, analytics, and visualization. © 2018 Elsevier Inc. All rights reserved.},
  affiliation             = {Tsinghua University Energy Internet Research Institute, Beijing, China},
  author_keywords         = {BaaS; Complementary operation of multiform energy system; Complex event processing; Lambda architecture; MapReduce; Microgrid; Microservice architecture; Smart grid; Spark},
  correspondence_address1 = {Gao, F.; Tsinghua University Energy Internet Research InstituteChina},
  document_type           = {Book Chapter},
  doi                     = {10.1016/B978-0-12-811968-6.00004-8},
  journal                 = {Big Data Application in Power Systems},
  language                = {English},
  pages                   = {57-73},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042275077&doi=10.1016%2fB978-0-12-811968-6.00004-8&partnerID=40&md5=95be581cb1dc648947a3c4f9b31a412c},
}

@Conference{Tanuska201797,
  author              = {Tanuska, P. and Spendla, L. and Kebisek, M. and Vazan, P. and Hrcka, L.},
  title               = {Data integration and transformation proposal for big data analyses in automotive industry},
  year                = {2017},
  volume              = {2017-January},
  pages               = {97-102},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {INES - IEEE Int. Conf. Intell. Eng. Syst., Proc.},
  abstract            = {In our paper, we have focused on data integration and transformation process in the automotive industry, with emphasis on production data collected from the shop floor. One of the main issues addressed, is that the data are not stored in a central data storage, but in individual devices and systems, utilising different data formats. Our paper briefly describes the main tasks, required to collect production data into the big data storage and transform them into a unified data structure. We have also provided results of the initial analyses that were performed on the integrated and transformed data set. © 2017 IEEE.},
  affiliation         = {Faculty of Materials Science and Technology, Slovak University of Technology, Trnava, Slovakia},
  document_type       = {Conference Paper},
  doi                 = {10.1109/INES.2017.8118535},
  isbn                = {9781479976775},
  journal             = {INES 2017 - IEEE 21st International Conference on Intelligent Engineering Systems, Proceedings},
  keywords            = {Automotive industry; Data integration; Data storage equipment; Digital storage; Metadata, Data set; Data storage; Individual devices; Main tasks; Production data; Shop floor; Transformation process, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043505239&doi=10.1109%2fINES.2017.8118535&partnerID=40&md5=491b538b40f4a1282ee5df35f6079f34},
}

@Conference{Yang2017602,
  author              = {Yang, Z.-X. and Zhu, M.-H.},
  title               = {Integration method for wireless communication modes in Internet of Vehicles in the big data environment},
  year                = {2017},
  volume              = {2017-January},
  pages               = {602-607},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 1},
  abbrev_source_title = {Proc. - Int. Conf. Smart Grid Electr. Autom., ICSGEA},
  abstract            = {Internet of Vehicles has great effect on improving the efficiency of the transportation system and driving safety. Communication process of Internet of Vehicles can be done adopting various wireless communication modes which include 4G, WLAN and WAVE in the Big data environment. As each wireless communication mode has different traffic scene applicability and different communication effects, this paper proposed a integration method for wireless communication mode based on support vector machine. This method obtained learning samples which indicate the communication mode with best communication performance through simulation of various traffic scenes in OPENT Modeler. Through the study of support vector machine algorithm, this designed method can output the predicted result mode of wireless communication adaptively under unknown traffic scenes. The outstanding results show that the integration method based on support vector machine can accurately choose the optimal communication mode in Internet of Vehicles. © 2017 IEEE.},
  affiliation         = {Software engineering Institute, East China Normal University, Shanghai, 200062, China; Electronic and Information Engineering Institute, Lanzhou Jiaotong University, Lanzhou, 730070, China},
  author_keywords     = {Big data; Communication performance; Internet of vehicles; Support vector machine; Wireless communication mode},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICSGEA.2017.136},
  isbn                = {9781538628133},
  journal             = {Proceedings - 2017 International Conference on Smart Grid and Electrical Automation, ICSGEA 2017},
  keywords            = {Electric power transmission networks; Integration; Smart power grids; Support vector machines; Vectors; Vehicles; Wireless telecommunication systems, Communication effects; Communication performance; Communication process; Internet-of-vehicles; Optimal communication; Support vector machine algorithm; Transportation system; Wireless communications, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044302750&doi=10.1109%2fICSGEA.2017.136&partnerID=40&md5=11341dfb3dbda82102f40af505eeb085},
}

@Conference{Abid2017856,
  author              = {Abid, M.R. and Lghoul, R. and Benhaddou, D.},
  title               = {ICT for renewable energy integration into smart buildings: IoT and big data approach},
  year                = {2017},
  editor              = {Cornish D.R.},
  pages               = {856-861},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 2},
  abbrev_source_title = {IEEE AFRICON: Sci., Technol. Innov. Africa, AFRICON},
  abstract            = {SG (Smart Grids) are emerging as a very promising technology with buildings as one of its most critical components. SG are meant to leverage energy-efficiency and promote green usage via efficient renewable energy integration. SG pose inherent challenges stemming, mainly, from its inter-disciplinary nature. Besides ICT (Information and Communication Technology), SG involves two other broad disciplines: 1. Power systems and 2. Control systems. Still, ICT is the major component that manifests SG ' Smartness'. In this work, we present the architecture of a real-world smart micro-grid testbed to be deployed in a university campus. We highlight its main components with an emphasis on the ICT component. We are advocating that SG will utilize Internet of Things (IoT) to source all types of data, and thus making the whole system fall within the realm of Big Data. To handle the huge amount of data that will be collected, we advise the deployment of a private local Cloud using open source platform for HPC (High-Performance-Computing) along with Hadoop/MapReduce as the underlying data storage and processing model. We deem this project as an ideal blueprint that can be easily adopted for similar real-world smart micro-grid testbeds in Africa and around the world. © 2017 IEEE.},
  affiliation         = {Alakhawayn University, Morocco; University of Houston, Houston, TX, United States},
  art_number          = {8095594},
  author_keywords     = {Big Data; High Performance Computing; Internet of Things; Smart Grids; Wireless Sensor Networks},
  document_type       = {Conference Paper},
  doi                 = {10.1109/AFRCON.2017.8095594},
  isbn                = {9781538627754},
  journal             = {2017 IEEE AFRICON: Science, Technology and Innovation for Africa, AFRICON 2017},
  keywords            = {Data handling; Digital storage; Electric power transmission networks; Energy efficiency; Internet of things; Open systems; Smart power grids; Testbeds; Wireless sensor networks, Critical component; High performance computing; Information and Communication Technologies; Internet of Things (IOT); Open source platforms; Renewable energy integrations; Smart grid; Smart Micro Grids, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039961745&doi=10.1109%2fAFRCON.2017.8095594&partnerID=40&md5=0865bacda1294a457dfef3ea16417a2d},
}

@Article{Li201719,
  author              = {Li, B. and Kisacikoglu, M.C. and Liu, C. and Singh, N. and Erol-Kantarci, M.},
  title               = {Big Data Analytics for Electric Vehicle Integration in Green Smart Cities},
  journal             = {IEEE Communications Magazine},
  year                = {2017},
  volume              = {55},
  number              = {11},
  pages               = {19-25},
  issn                = {01636804},
  note                = {cited By 4},
  abbrev_source_title = {IEEE Commun Mag},
  abstract            = {The huge amount of data generated by devices, vehicles, buildings, the power grid, and many other connected things, coupled with increased rates of data transmission, constitute the big data challenge. Among many areas associated with the Internet of Things, smart grid and electric vehilces have their share of this challenge by being both producers and consumers (ie., prosumers) of big data. Electric vehicls can significantly help smart cities to become greener by reducing emissions of the transportation sector and play an important role in green smart cities. In this article, we first survey the data analytics techniques used for handling the big data of smart grid and electric vehicles. The data generated by electric vehicles come from sources that vary from sensors to trip logs. Once this vast amount of data are analyzed using big data techniques, they can be used to develop policies for siting charging stations, developing smart charging algorithms, solving energy efficiency issues, evaluating the capacity of power distribution systems to handle extra charging loads, and finally, determining the market value for the services provided by electric vehicles (i.e., vehicle-to-grid opportunities). This article provides a comprehensive overview of the data analytics landscape on the electric vehicle integration to green smart cities. It serves as a roadmap to the future data analytics needs and solutions for electric vehicle integration to smart cities. © 1979-2012 IEEE.},
  affiliation         = {Illinois Instititue of Technology, United States; University of Alabama, United States; Clarkson University, United States; University of Ottawa, Canada},
  art_number          = {8114543},
  coden               = {ICOMD},
  document_type       = {Article},
  doi                 = {10.1109/MCOM.2017.1700133},
  keywords            = {Data integration; Electric power distribution; Electric power transmission networks; Electric vehicles; Energy efficiency; Integration; Smart city; Smart power grids; Vehicle transmissions, Big Data Analytics; Charging station; Data analytics; Power distribution system; Reducing emissions; Smart charging; Transportation sector; Vehicle integration, Big data},
  language            = {English},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047644667&doi=10.1109%2fMCOM.2017.1700133&partnerID=40&md5=9ebf48f770d68b8506757cd10a0e0514},
}

@Conference{Zaib20171,
  author              = {Zaib, N.A.M. and Bazin, N.E.N. and Mustaffa, N.H. and Sallehuddin, R.},
  title               = {Integration of system dynamics with big data using python: An overview},
  year                = {2017},
  volume              = {2017-January},
  pages               = {1-4},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {ICT Int. Stud. Proj. Conf.: Elev. Commun. Through ICT, ICT-ISPC},
  abstract            = {ig Data has rapidly boomed into a hot topic that attracts attention from governments, academia, and industry around the world. Furthermore, the rapid development of Internet, Internet of Things, and Machine To Machine Communication has led to an extensive growth of data whether in industry or business area. This paper provided discussion about the definition, the characteristics of Big Data and important of Big Data to be integrated with System Dynamics model. Next, we present a basic step on how to simulate SD model into Python environment. Finally, we concluded the paper by presenting several suggestions for future references. © 2017 IEEE.},
  affiliation         = {Department of Computer Science, Universiti Teknologi Malaysia (UTM), Skudai, Johor, 81310, Malaysia},
  author_keywords     = {PySd; Python; System Dynamics},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICT-ISPC.2017.8075337},
  isbn                = {9781538629963},
  journal             = {6th ICT International Student Project Conference: Elevating Community Through ICT, ICT-ISPC 2017},
  keywords            = {Computer software; High level languages; Machine-to-machine communication; System theory, Hot topics; PySd; Python; Sd models; System Dynamics; System dynamics model, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043704939&doi=10.1109%2fICT-ISPC.2017.8075337&partnerID=40&md5=5ae340b395c52bd2774ca71ead55157f},
}

@Conference{Xiang201764,
  author              = {Xiang, G. and Fang, W.},
  title               = {The research of data integration and business intelligent based on drilling big data},
  year                = {2017},
  pages               = {64-68},
  publisher           = {Association for Computing Machinery},
  note                = {cited By 0},
  abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
  abstract            = {With the development of information technology, ChangQing drilling engineering company has accumulated a large number of data about drilling, and the research foundation of drilling big data technology had been formed. But now, huge volumes of data are distributed in different heterogeneous data sources due to the long-term decentralized construction, which is hard to realize the comprehensive analysis of related data. In this paper, aiming at the practical problems, a data integration and business intelligent-project based on drilling big data has been put forward. Referencing to the knowledge of this field, the system applies kettle which is a data integration tool to realize the integration of ETL heterogeneous data resource, establishes the data warehouse based on theme, and uses fine report which is a business intelligence tools to organize the views of drilling big data according to different user's requires, shows flexibly in multi-perspective view, thus provides powerful data support for user's drilling decision. © 2017 Association for Computing Machinery.},
  affiliation         = {Northwestern Polytechnical University, Shanxi, Xi'an, China},
  author_keywords     = {Business intelligence; Data integration; Data warehouse; Multi-source heterogeneous big data},
  document_type       = {Conference Paper},
  doi                 = {10.1145/3149572.3149603},
  isbn                = {9781450353373},
  journal             = {ACM International Conference Proceeding Series},
  keywords            = {Competitive intelligence; Data integration; Data warehouses; Information analysis; Information management, Big data technologies; Business intelligent; Comprehensive analysis; Drilling engineering; Heterogeneous data; Heterogeneous data sources; Multi-perspective views; Multi-Sources, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045665728&doi=10.1145%2f3149572.3149603&partnerID=40&md5=b3cdfc026246127429c08c3cbb2a513b},
}

@Article{Ullah201790,
  author                  = {Ullah, F. and Habib, M.A. and Farhan, M. and Khalid, S. and Durrani, M.Y. and Jabbar, S.},
  title                   = {Semantic interoperability for big-data in heterogeneous IoT infrastructure for healthcare},
  journal                 = {Sustainable Cities and Society},
  year                    = {2017},
  volume                  = {34},
  pages                   = {90-96},
  issn                    = {22106707},
  note                    = {cited By 20},
  abbrev_source_title     = {Sustainable Cities Soc.},
  abstract                = {Interoperability remains a major burden to the developers of Internet of Things systems. It is due to IoT devices are extremely heterogeneous regarding basic communication protocols, data formats, and technologies. Furthermore, due to the absence of worldwide satisfactory standards, Interoperability tools remains imperfect. In this paper, we have proposed Semantic Interoperability Model for Big-data in IoT (SIMB-IoT) to deliver semantic interoperability among heterogeneous IoT devices in health care domain. This model is used to recommend medicine with side effects for different symptoms collected from heterogeneous IoT sensors. Two datasets are taken for the analysis of big-data. One dataset contains diseases with drug details and the second dataset contains medicines with side effects. Information between physician and patient are semantically annotated and transferred in a meaningful way. A Lightweight Model for Semantic annotation of Big-data using heterogeneous devices in IoT is proposed to provide annotations for big data. Resource Description Framework (RDF) is a semantic web framework that is recycled to communicate things using Triples to make it semantically significant. RDF annotated patients’ data and made it semantically interoperable. SPARQL query is used to extract records from RDF graph. Tableau, Gruff-6.2.0, and Mysql tools are used in simulation in this article. © 2017 Elsevier Ltd},
  affiliation             = {Department of Computer Science, COMSATS Institute of Information Technology Sahiwal, Pakistan; Department of Computer Science, National Textile University, Faisalabad, Pakistan; Department of Computer Engineering, Bahria University, Islamabad, Pakistan; Department of Computer Science, COMSATS Institute of Information Technology Attock, Pakistan},
  author_keywords         = {Cloud services; Resource description framework; Semantic annotation; Semantic interoperability; SIMB-IoT; SPARQL},
  correspondence_address1 = {Jabbar, S.; Department of Computer Science, National Textile UniversityPakistan; email: sjabbar.research@gmail.com},
  document_type           = {Article},
  doi                     = {10.1016/j.scs.2017.06.010},
  keywords                = {Big data; Health care; Interoperability; Semantic Web, Cloud services; Resource description framework; Semantic annotations; Semantic interoperability; SIMB-IoT; SPARQL, Internet of things},
  language                = {English},
  publisher               = {Elsevier Ltd},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021173867&doi=10.1016%2fj.scs.2017.06.010&partnerID=40&md5=9ae4a84f25f9b948ab4814cddf9628cd},
}

@Conference{McGregor201792,
  author              = {McGregor, C. and Bonnis, B.},
  title               = {New Approaches for Integration: Integration of Haptic Garments, Big Data Analytics, and Serious Games for Extreme Environments},
  year                = {2017},
  volume              = {6},
  number              = {4},
  pages               = {92-96},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {IEEE Consum. Electron. Mag.},
  abstract            = {Haptic garments present new opportunities to increase realism in gaming. As Real As It Gets (ARAIG) is a new form of haptic garment that uses muscle stimulation, vibration, and 7.1 surround sound to provide a new level of realism in gaming. The integration of new haptic garments like ARAIG with big data analytics and serious games presents new opportunities for more realistic virtual training that has application in many domains. In particular, there is great potential to support repeatable virtual training for extreme environments. In 2016, the IEEE Life Sciences Technical Community worked across the IEEE Societies to demonstrate this interdisciplinary nature, with a focus on solving life science problems in extreme environments. This article is based on our keynote address at the International Conference on Consumer Electronics (ICCE)-Berlin in 2016. It provides an example of this interdisciplinary case study research in action. © 2012 IEEE.},
  affiliation         = {Institute of Technology, University of Ontario, Canada; University of Technology Sydney, Broadway, New South Wales, Australia; IFTech Inventing Future Technology Inc., Oshawa, Canada},
  art_number          = {8048749},
  document_type       = {Article},
  doi                 = {10.1109/MCE.2017.2715519},
  issn                = {21622248},
  journal             = {IEEE Consumer Electronics Magazine},
  keywords            = {Big data; E-learning; Integration; Serious games, Case study research; Data analytics; Extreme environment; Muscle stimulation; New approaches; Surround sound; Technical community; Virtual training, Data integration},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031085596&doi=10.1109%2fMCE.2017.2715519&partnerID=40&md5=3704e9a5a2b5b4b39240372c576e57c0},
}

@Book{Kuiler2017161,
  title                   = {Federal Big Data Analytics in the Health Domain: An Ontological Approach to Data Interoperability. An Ontological Approach to Data Interoperability.},
  publisher               = {Elsevier Inc.},
  year                    = {2017},
  author                  = {Kuiler, E.W. and McNeely, C.L.},
  isbn                    = {9780128124444; 9780128124437},
  note                    = {cited By 1},
  abbrev_source_title     = {Federal Data Sci.: Transform. Gov. and Agric. Policy Using Artif. Intell.},
  abstract                = {"Big data" in the health domain occupies a critical position on the federal policy and research agenda, with emphasis on leveraging large, complex data sets to manage population health, drive down disease rates, and control costs. The complexity of big data analytics requires new rules and algorithms to effect the interoperability of data derived from multiple sources. Accordingly, a lexicon and ontology-based approach to data interoperability is offered as a practical and adaptable framework to address challenges of data interoperability presented by big health data analytics and related issues. The use of ontologies as descriptive, heuristic, and normative instruments is presented as means for facilitating data interoperability by ensuring semantic congruity and syntactic conformance within and across large and complex data sets. A framework is provided for an ontological approach to health data interoperability, focusing on the importance of standards and considering implications for practice and policy in relevant federal agencies. © 2018 Elsevier Inc. All rights reserved.},
  affiliation             = {George Mason University, Arlington, VA, United States},
  author_keywords         = {Big data analytics; Data interoperability; Health data; Lexicon; Ontology},
  correspondence_address1 = {Kuiler, E.W.; George Mason UniversityUnited States},
  document_type           = {Book Chapter},
  doi                     = {10.1016/B978-0-12-812443-7.00010-7},
  journal                 = {Federal Data Science: Transforming Government and Agricultural Policy Using Artificial Intelligence},
  language                = {English},
  pages                   = {161-176},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047340250&doi=10.1016%2fB978-0-12-812443-7.00010-7&partnerID=40&md5=805df43c5fc86d90475a0c10683bc91f},
}

@Article{Rani20171,
  author                  = {Rani, P.S. and Suresh, R.M. and Sethukarasi, R.},
  title                   = {Multi-level semantic annotation and unified data integration using semantic web ontology in big data processing},
  journal                 = {Cluster Computing},
  year                    = {2017},
  pages                   = {1-13},
  issn                    = {13867857},
  note                    = {cited By 3; Article in Press},
  abbrev_source_title     = {Cluster Comput.},
  abstract                = {The potential applications of big data need semantic annotation and unified integration of heterogeneous data. This paper proposes MOUNT a multi-level annotation and integration framework that significantly process the heterogeneous dataset by exploiting the semantic knowledge to improve the query processing in the large scale infrastructure. The multi-level annotation proposes the coarse-grained and fine-grained annotation models. The coarse-grained annotation employs Yago and SEeds SEarch to categorize the domain information on the big data and fine-grained annotation enables semantic enrichment. Moreover, the MOUNT approach integrates the structured and unstructured data to form the global resource description framework ontology. Moreover, it facilitates the query processing by translating the natural language user query into structured triples. The experimental results prove that the MOUNT approach yields a better performance in terms of result accuracy by 94%. © 2017 Springer Science+Business Media, LLC},
  affiliation             = {R.M.D. Engineering College, Chennai, India; Sri Lakshmi Ammaal Engineering College, Chennai, India; R.M.K. Engineering College, Chennai, India},
  author_keywords         = {Annotation; Big data; Query; Structured; Unstructured; Yago},
  correspondence_address1 = {Rani, P.S.; R.M.D. Engineering CollegeIndia; email: pachashobharani@gmail.com},
  document_type           = {Article in Press},
  doi                     = {10.1007/s10586-017-1029-7},
  keywords                = {Data handling; Data integration; Ontology; Query processing; Semantic Web, Annotation; Query; Structured; Unstructured; Yago, Big data},
  language                = {English},
  publisher               = {Springer New York LLC},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028019767&doi=10.1007%2fs10586-017-1029-7&partnerID=40&md5=c2e099dc229ed11659f86461265acff3},
}

@Conference{Zhang2017392,
  author              = {Zhang, P. and Zhang, Q. and Liu, F. and Li, J. and Cao, N. and Song, C.},
  title               = {The Construction of the Integration of Water and Fertilizer Smart Water Saving Irrigation System Based on Big Data},
  year                = {2017},
  volume              = {2},
  pages               = {392-397},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 4},
  abbrev_source_title = {Proc. - IEEE Int. Conf. Comput. Sci. Eng. IEEE/IFIP Int. Conf. Embed. Ubiquitous Comput., CSE EUC},
  abstract            = {With the advent of emerging technologies such as the Internet of things and big data, the pace of transformation from traditional agriculture to modern agriculture will continue to be accelerated. Given that traditional agriculture exists many problems currently, such as low utilization of irrigation water and backward in management level, the integration of water and fertilizer irrigation intelligent big data system is established based on the technologies of Internet of things, big data and so on. The system uses the Internet of things and some other technologies to real-timely monitor and automatically collect the data related to the growth of crops in the fields and then upload them to Shandong Agricultural University big data central target database. The center of big data intelligently stores, screens, calibrates, mines and extracts the monitoring data to establish the crop growth model based on big data, which can predict and forecast the water requirement of crops in different growth periods and make the decision of automatic irrigation and fertilization, finally realize timely and proper irrigation of crops. © 2017 IEEE.},
  affiliation         = {College of Water Conservancy and Civil Engineering, Shandong Agricultural University, Taian, China; Agricultural Big Data Center, Shandong Agricultural University, Taian, China; College of Information Engineering, Qingdao Binhai University, Qingdao, China},
  art_number          = {8006036},
  author_keywords     = {Big data; Smart agriculture; The integration of water and fertilizer},
  document_type       = {Conference Paper},
  doi                 = {10.1109/CSE-EUC.2017.258},
  isbn                = {9781538632215},
  journal             = {Proceedings - 2017 IEEE International Conference on Computational Science and Engineering and IEEE/IFIP International Conference on Embedded and Ubiquitous Computing, CSE and EUC 2017},
  keywords            = {Agriculture; Crops; Data integration; Data mining; Fertilizers; Information management; Integration; Internet of things; Irrigation; Metadata; Ubiquitous computing; Water conservation; Water resources, Automatic irrigation; Emerging technologies; Integration of water and fertilizers; Irrigation waters; Modern agricultures; Smart agricultures; Water requirements; Water-saving irrigation, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034454128&doi=10.1109%2fCSE-EUC.2017.258&partnerID=40&md5=2a2718c141337167ffc04bedb448c01d},
}

@Conference{Nkenyereye2017946,
  author              = {Nkenyereye, L. and Jang, J.-W.},
  title               = {Integration of big data for querying CAN bus data from connected car},
  year                = {2017},
  pages               = {946-950},
  publisher           = {IEEE Computer Society},
  note                = {cited By 0},
  abbrev_source_title = {Int. Conf. Ubiquitous Future Netw., ICUFN},
  abstract            = {Data transmission by Connected Car via wireless communications technologies enable new in-car telematics services. The capability to efficiently process large volume of Controller Area Network (CAN) bus data within a reasonable time. Since these data are essential for many Connected Car applications, querying and extracting useful information using Hadoop framework will allow to enhance safety and driving experience. This paper studies design steps to take in consideration when implementing MapReduce patterns to analyses CAN bus data in order to produce useful data that are hosted in the cloud. In addition, we implement a mobile apps for collecting and transferring CAN bus data to remote data center which include application server and Hadoop ecosystem such Hive data warehouse. Experiment results show that MapReduce join algorithm is highly scalable and optimized for distributed computing than Statistical Analysis System (SAS) framework and HiveQL declarative language. © 2017 IEEE.},
  affiliation         = {Department Computer Engineering, Dong-Eui University, Busan, South Korea},
  art_number          = {7993938},
  author_keywords     = {Big data; CAN bus data; Connected Car; Hadoop; HiveQL language; MapReduce framework},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICUFN.2017.7993938},
  isbn                = {9781509047499},
  issn                = {21658528},
  journal             = {International Conference on Ubiquitous and Future Networks, ICUFN},
  keywords            = {Control system synthesis; Data communication systems; Data warehouses; Distributed computer systems; Information services; Wireless telecommunication systems, CAN bus; Controller area networkbus; Declarative Languages; Hadoop; HiveQL language; Mapreduce frameworks; Statistical analysis systems; Wireless communications, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028077668&doi=10.1109%2fICUFN.2017.7993938&partnerID=40&md5=8f41246c9ec740825f1db48c7d54fe68},
}

@Conference{Alguliyev2017,
  author              = {Alguliyev, R.M. and Aliguliyev, R.M. and Hajirahimova, M.S.},
  title               = {Big data integration architectural concepts for oil and gas industry},
  year                = {2017},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Appl. Inf. Commun. Technol., AICT - Conf. Proc.},
  abstract            = {In recent years economic an social activity fields is based on data. Oil and gas industry leaders understand the value of big data and are interested in digital oil industry becoming a reality. Here is big data is analysed as a key component in based decision making in oil and gas industry during exploration, drilling and production. In oil and gas industry architectural model is offered for integration and convergence of big data, business analyticss and transaction data. © 2016 IEEE.},
  affiliation         = {Institute of Information Technology, ANAS, Baku, Azerbaijan},
  art_number          = {7991832},
  author_keywords     = {big data; business analyticss; business intelligence; data mining; decision-making; oil and gas industry; predictive analyticss},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICAICT.2016.7991832},
  isbn                = {9781509018406},
  journal             = {Application of Information and Communication Technologies, AICT 2016 - Conference Proceedings},
  keywords            = {Competitive intelligence; Data integration; Data mining; Decision making; Gas industry; Gases, Architectural concepts; Architectural modeling; Oil and Gas Industry; Oil industries; predictive analyticss; Social activities; Transaction data, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034224992&doi=10.1109%2fICAICT.2016.7991832&partnerID=40&md5=0104f5bb36c7578b494bb88d377aae27},
}

@Conference{Brusakov2017697,
  author              = {Brusakov, M.I. and Botvin, G.A.},
  title               = {In-memory technology integration features for work with big data on high-Tech enterprises},
  year                = {2017},
  editor              = {Shaposhnikov S.},
  pages               = {697-698},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Proc. IEEE Int. Conf. Soft Comput. Meas., SCM},
  abstract            = {The analysis of in-memory technology implementation features for big data sets on hi-Tech enterprises based on SAP HANA technologies as a data storage is provided in article. With use of a column-store method of SAP HANA data storage technologies, the high speed of information read and the efficiency of use of data compression mechanisms can be achieved. The compressed data usage allows to cheapen the resources for processes of a decompression. Along with a parallel engineering of resources at the knowledge-intensive enterprise, the costs economy of storage and processing of Big Data sets with use of in-memory technologies based on SAP HANA allows to reduce volumes of information stored in an information system. © 2017 IEEE.},
  affiliation         = {St. Petersburg State University, Saint Petersburg, Russian Federation},
  art_number          = {7970694},
  author_keywords     = {engineering of resources of the hi-Tech enterprises; IT infrastructure; SAP HANA; technologies in-memory},
  document_type       = {Conference Paper},
  doi                 = {10.1109/SCM.2017.7970694},
  isbn                = {9781538618103},
  journal             = {Proceedings of 2017 20th IEEE International Conference on Soft Computing and Measurements, SCM 2017},
  keywords            = {Cost engineering; Data handling; Data storage equipment; Digital storage; Soft computing, Compression mechanism; Data storage technology; Efficiency of use; Hi-tech enterprise; IT infrastructures; Memory technology; Parallel engineering; SAP HANA, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027129677&doi=10.1109%2fSCM.2017.7970694&partnerID=40&md5=84a9d1d1552a27c280ca6800421dc816},
}

@Article{Johnson201731,
  author              = {Johnson, J. and Folger, J. and Stevens, T. and Malyuta, T.},
  title               = {Integration of big data misconceptions, probleMS and heeded capabilities},
  journal             = {CrossTalk},
  year                = {2017},
  volume              = {30},
  number              = {5},
  pages               = {31-33},
  issn                = {21601577},
  note                = {cited By 0},
  abbrev_source_title = {CrossTalk},
  abstract            = {The authors have been working on the problems of data integration for a number of years, in particular, integration of what is called Big Data - data defined by Gartneris famous three Vs: volume, velocity and variety. Based on our experience and interactions with both customers and vendors, we discuss here the common misconceptions about Big Data integration and cloud technologies, analyze problems that need to be addressed,1 and suggest capabilities of the solutions. The solution to which the authors contributed is described in a number of publications [1, 2, 5, 6]. © 2017 U.S. Department of Defense. All rights reserved.},
  affiliation         = {EOIR Technologies, United States; New York City College of Technology, CUNY, United States},
  document_type       = {Article},
  keywords            = {Big data, Cloud technologies, Data integration},
  language            = {English},
  publisher           = {U.S. Department of Defense},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050333503&partnerID=40&md5=fc12753a934193fc34d0373d411eeba5},
}

@Article{Malyuta2017,
  author              = {Malyuta, T. and Johnson, J. and Folger, J. and Stevens, T.},
  title               = {Integration of big data: Misconceptions, problems, and needed capabilities},
  journal             = {CrossTalk},
  year                = {2017},
  volume              = {30},
  number              = {4},
  issn                = {21601577},
  note                = {cited By 0},
  abbrev_source_title = {CrossTalk},
  abstract            = {The authors have been working on the problems of data integration for a number of years, in particular, integration of what is called Big Data - data defined by Gartner's famous three V's: volume, velocity and variety. Based on our experience and interactions with both customers and vendors, we discuss here the common misconceptions about Big Data integration and cloud technologies, analyze problems that need to be addressed,1 and suggest capabilities of the solutions. The solution to which the authors contributed is described in a number of publications [1, 2, 5, 6].},
  affiliation         = {New York College of Technology, CUNY, United States; EOIR Technologies, United States},
  document_type       = {Article},
  keywords            = {Big data, Cloud technologies; Gartner, Data integration},
  language            = {English},
  publisher           = {U.S. Department of Defense},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030996955&partnerID=40&md5=93beb3d52402bb0f8443d13d43825fef},
}

@Article{Marcheschi2017437,
  author                  = {Marcheschi, P.},
  title                   = {Relevance of eHealth standards for big data interoperability in radiology and beyond},
  journal                 = {Radiologia Medica},
  year                    = {2017},
  volume                  = {122},
  number                  = {6},
  pages                   = {437-443},
  issn                    = {00338362},
  note                    = {cited By 5},
  abbrev_source_title     = {Radiol. Med.},
  abstract                = {The aim of this paper is to report on the implementation of radiology and related information technology standards to feed big data repositories and so to be able to create a solid substrate on which to operate with analysis software. Digital Imaging and Communications in Medicine (DICOM) and Health Level 7 (HL7) are the major standards for radiology and medical information technology. They define formats and protocols to transmit medical images, signals, and patient data inside and outside hospital facilities. These standards can be implemented but big data expectations are stimulating a new approach, simplifying data collection and interoperability, seeking reduction of time to full implementation inside health organizations. Virtual Medical Record, DICOM Structured Reporting and HL7 Fast Healthcare Interoperability Resources (FHIR) are changing the way medical data are shared among organization and they will be the keys to big data interoperability. Until we do not find simple and comprehensive methods to store and disseminate detailed information on the patient’s health we will not be able to get optimum results from the analysis of those data. © 2016, Italian Society of Medical Radiology.},
  affiliation             = {Fondazione Gabriele Monasterio CNR/Regione Toscana, Pisa, Italy},
  author_keywords         = {Big data; DICOM; EHR; HL7; Radiology; Standards},
  coden                   = {RAMEA},
  correspondence_address1 = {Marcheschi, P.; Fondazione Gabriele Monasterio CNR/Regione ToscanaItaly; email: paolo.marcheschi@ftgm.it},
  document_type           = {Article},
  doi                     = {10.1007/s11547-016-0691-9},
  keywords                = {digital imaging and communications in medicine; expectation; health care organization; health level 7; human; information technology; medical information; medical record; patient coding; radiology; software; telehealth; legislation and jurisprudence; medical informatics; radiology; standards; telemedicine; United States, Medical Informatics; Radiology; Software; Telemedicine; United States},
  language                = {English},
  publisher               = {Springer-Verlag Italia s.r.l.},
  pubmed_id               = {27815798},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994257419&doi=10.1007%2fs11547-016-0691-9&partnerID=40&md5=24cd6d8eed9e5b96bce6ed4d1c575209},
}

@Article{Alias20173817,
  author                  = {Alias, N. and Kamal, M.H.A.},
  title                   = {Integration of a big data emerging on large sparse simulation and its application on green computing platform},
  journal                 = {ARPN Journal of Engineering and Applied Sciences},
  year                    = {2017},
  volume                  = {12},
  number                  = {12},
  pages                   = {3817-3826},
  issn                    = {18196608},
  note                    = {cited By 0},
  abbrev_source_title     = {ARPN J. Eng. Appl. Sci.},
  abstract                = {The process of analyzing large data and verifying a big data set are a challenge for understanding the fundamental concept behind it. Many big data analysis techniques suffer from the poor scalability, variation inequality, instability, lower convergence, and weak accuracy of the large-scale numerical algorithms. Due to these limitations, a wider opportunity for numerical analysts to develop the efficiency and novel parallel algorithms has emerged. Big data analytics plays an important role in the field of sciences and engineering for extracting patterns, trends, actionable information from large sets of data and improving strategies for making a decision. A large data set consists of a large-scale data collection via sensor network, transformation from signal to digital images, high resolution of a sensing system, industry forecasts, existing customer records to predict trends and prepare for new demand. This paper proposes three types of big data analytics in accordance to the analytics requirement involving a large-scale numerical simulation and mathematical modeling for solving a complex problem. First is a big data analytics for theory and fundamental of nanotechnology numerical simulation. Second, big data analytics for enhancing the digital images in 3D visualization, performance analysis of embedded system based on the large sparse data sets generated by the device. Lastly, extraction of patterns from the electroencephalogram (EEG) data set for detecting the horizontal-vertical eye movements. Thus, the process of examining a big data analytics is to investigate the behavior of hidden patterns, unknown correlations, identify anomalies, and discover structure inside unstructured data and extracting the essence, trend prediction, multi-dimensional visualization and real-time observation using the mathematical model. Parallel algorithms, mesh generation, domain-function decomposition approaches, inter-node communication design, mapping the subdomain, numerical analysis and parallel performance evaluations (PPE) are the processes of the big data analytics implementation. The superior of parallel numerical methods such as AGE, Brian and IADE were proven for solving a large sparse model on green computing by utilizing the obsolete computers, the old generation servers and outdated hardware, a distributed virtual memory and multi-processors. The integration of low-cost communication of message passing software and green computing platform is capable of increasing the PPE up to 60% when compared to the limited memory of a single processor. As a conclusion, large-scale numerical algorithms with great performance in scalability, equality, stability, convergence, and accuracy are important features in analyzing big data simulation. ©2006-2017 Asian Research Publishing Network (ARPN). All rights reserved.},
  affiliation             = {Center for Sustainable Nanomaterials, Ibnu Sina Institute for Scientific and Industrial Research, Universiti Teknologi Malaysia, Malaysia; Department of Mathematics, Faculty of Science, Universiti Teknologi Malaysia, Malaysia},
  author_keywords         = {Big data analytics; Fine-grained; Green computing; Parallel numerical method},
  correspondence_address1 = {Alias, N.; Center for Sustainable Nanomaterials, Ibnu Sina Institute for Scientific and Industrial Research, Universiti Teknologi MalaysiaMalaysia; email: normaalias@utm.my},
  document_type           = {Article},
  language                = {English},
  publisher               = {Asian Research Publishing Network},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021111246&partnerID=40&md5=f2080d0c921070122058bbd9bfb4e8e2},
}

@Conference{Ostrowski2017305,
  author              = {Ostrowski, D. and Kim, M.},
  title               = {A Semantic Based Framework for the Purpose of Big Data Integration},
  year                = {2017},
  pages               = {305-309},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Proc. - Int. Conf. Semant. Comput., ICSC},
  abstract            = {One of the most substantial opportunities in Big Data is to integrate disparate data sources across the enterprise. To realize this goal it can be valuable to leverage environments developed for high speed parallel processing as well as toolkits supporting the development and maintenance of semantic information. In support of this approach a proposed framework and methodology is presented to utilize an ontology-based data integration strategy. Our approach supports a rule-based translation to generate new ontology versions within a fast prototyping environment leveraging the Jena API within the context of the Apache Spark environment. © 2017 IEEE.},
  affiliation         = {Ford Motor Company, Dearborn, MI, United States; Dept. of EECS, University of CA, Irvine, Irvine, CA 92617, United States},
  art_number          = {7889553},
  author_keywords     = {Big Data; Data Integration; Ontology},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICSC.2017.62},
  isbn                = {9781509048960},
  journal             = {Proceedings - IEEE 11th International Conference on Semantic Computing, ICSC 2017},
  keywords            = {Data integration; Ontology; Semantics, Data-sources; Fast prototyping; High Speed; Integration strategy; Ontology-based; Parallel processing; Rule based; Semantic information, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018323856&doi=10.1109%2fICSC.2017.62&partnerID=40&md5=9f02e7c528924746011f502cfb045245},
}

@Article{Hong2017264,
  author              = {Hong, Z. and Chen, H. and Cheng, L.},
  title               = {Social governance data integration and decision analysis method based on big data},
  journal             = {Qinghua Daxue Xuebao/Journal of Tsinghua University},
  year                = {2017},
  volume              = {57},
  number              = {3},
  pages               = {264-269},
  issn                = {10000054},
  note                = {cited By 0},
  abbrev_source_title = {Qinghua Daxue Xuebao},
  abstract            = {This paper presents distributed data integration and visualization methods for distributed data integration for complex social governance data sets which have weak data analysis. The enhanced dynamic data description and Web visualization capabilities facilitate service-oriented intelligence society governance decision analyse using the large data processing mode to access, extract, integrate, and mine scattered data in different network routing databases. This paper presents a prototype system with trial evaluations. The results show that this method enhances real-time data integration, security, accuracy and data analysis visualization, and is more streamlined than the traditional model. © 2017, Tsinghua University Press. All right reserved.},
  affiliation         = {Telchina Smart Industry Group Co., Ltd., Jinan, 250101, China; Shizhong District of Jinan City Development and Reform Commission, Jinan, 250001, China; Jinan City Commission of Jiu San Society, Jinan, 250012, China},
  author_keywords     = {Big data; Data integration; Decision analysis; Smart; Social governance},
  coden               = {QDXKE},
  document_type       = {Article},
  doi                 = {10.16511/j.cnki.qhdxxb.2017.26.007},
  keywords            = {Big data; Complex networks; Data handling; Data visualization; Decision making; Decision theory; Information analysis; Visualization, Distributed data; Prototype system; Service Oriented; Smart; Social governance; Traditional models; Visualization method; Web visualization, Data integration},
  language            = {Chinese},
  publisher           = {Press of Tsinghua University},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025093541&doi=10.16511%2fj.cnki.qhdxxb.2017.26.007&partnerID=40&md5=7cf9bf87e8b543054299e81d1e27532a},
}

@Article{Andrew201788,
  author                  = {Andrew, C. and Heegaard, E. and Kirk, P.M. and Bässler, C. and Heilmann-Clausen, J. and Krisai-Greilhuber, I. and Kuyper, T.W. and Senn-Irlet, B. and Büntgen, U. and Diez, J. and Egli, S. and Gange, A.C. and Halvorsen, R. and Høiland, K. and Nordén, J. and Rustøen, F. and Boddy, L. and Kauserud, H.},
  title                   = {Big data integration: Pan-European fungal species observations' assembly for addressing contemporary questions in ecology and global change biology},
  journal                 = {Fungal Biology Reviews},
  year                    = {2017},
  volume                  = {31},
  number                  = {2},
  pages                   = {88-98},
  issn                    = {17494613},
  note                    = {cited By 13},
  abbrev_source_title     = {Fungal Biol. Rev.},
  abstract                = {Species occurrence observations are increasingly available for scientific analyses through citizen science projects and digitization of museum records, representing a largely untapped ecological resource. When combined with open-source data, there is unparalleled potential for understanding many aspects of the ecology and biogeography of organisms. Here we describe the process of assembling a pan-European mycological meta-database (ClimFun) and integrating it with open-source data to advance the fields of macroecology and biogeography against a backdrop of global change. Initially 7.3 million unique fungal species fruit body records, spanning nine countries, were processed and assembled into 6 million records of more than 10,000 species. This is an extraordinary amount of fungal data to address macro-ecological questions. We provide two examples of fungal species with different life histories, one ectomycorrhizal and one wood decaying, to demonstrate how such continental-scale meta-databases can offer unique insights into climate change effects on fungal phenology and fruiting patterns in recent decades. © 2017 British Mycological Society},
  affiliation             = {Section for Genetics and Evolutionary Biology (EVOGENE), University of Oslo, Blindernveien 31, Oslo, 0316, Norway; Forestry and Forest Resources, Norwegian Institute of Bioeconomy Research, Fanaflaten 4, Fana, N-5244, Norway; Cardiff School of Biosciences, Sir Martin Evans Building, Museum Avenue, Cardiff, CF10 3AX, United Kingdom; School of Biological Sciences, Royal Holloway, University of London, Egham, Surrey TW20 0EX, United Kingdom; Department of Research and Collections, Natural History Museum, University of Oslo, Oslo, NO-0318, Norway; Norwegian Institute for Nature Research, Gaustadsalléen 21, Oslo, NO-0349, Norway; Centre for Macroecology, Evolution and Climate, Natural History Museum of Denmark, University of Copenhagen, Copenhagen, DK-2100, Denmark; Swiss Federal Research Institute WSL, Birmensdorf, CH-8903, Switzerland; University of Cambridge, Department of GeographyCB2 3EN, United Kingdom; Global Change Research Centre and Masaryk University, Brno, 613 00, Czech Republic; Department of Botany and Biodiversity Research, University of Vienna, Vienna, A-1030, Austria; Bavarian Forest National Park, Freyunger Str. 2, Grafenau, D-94481, Germany; Department of Soil Quality, Wageningen University, PO Box 47, Wageningen, AA 6700, Netherlands; Mycology Section, Jodrell Laboratory, Royal Botanic Garden, Kew, Surrey, TW9 3DS, United Kingdom; Department of Botany and Plant Sciences, University of California, Riverside, CA 92521, United States},
  author_keywords         = {Biogeography; Citizen science; Fungi; Global change; Meta-database; Open-source},
  correspondence_address1 = {Kauserud, H.; Section for Genetics and Evolutionary Biology (EVOGENE), University of Oslo, Blindernveien 31, Norway; email: havard.kauserud@ibv.uio.no},
  document_type           = {Review},
  doi                     = {10.1016/j.fbr.2017.01.001},
  language                = {English},
  publisher               = {Elsevier Ltd},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010996151&doi=10.1016%2fj.fbr.2017.01.001&partnerID=40&md5=6c70ffe888213cfa9096cdaa94f06c11},
}

@Article{Sledgianowski201781,
  author                  = {Sledgianowski, D. and Gomaa, M. and Tan, C.},
  title                   = {Toward integration of Big Data, technology and information systems competencies into the accounting curriculum},
  journal                 = {Journal of Accounting Education},
  year                    = {2017},
  volume                  = {38},
  pages                   = {81-93},
  issn                    = {07485751},
  note                    = {cited By 11},
  abbrev_source_title     = {J. Account. Educ.},
  abstract                = {Recent initiatives of the American Accounting Association (AAA) and the Association to Advance Collegiate Schools of Business International (AACSB) have emphasized the importance of integrating Big Data and technology into the accounting curriculum. In response to these calls and to identify a common body of instructional resources toward this purpose, our paper uses the lens of the Competency Integration for Accounting Education framework to provide examples of Big Data and information systems integration into instructional resources. We loosely frame these instructional resources using accounting course subjects as the unit of analysis. © 2016 Elsevier Ltd},
  affiliation             = {Department of Accounting, Taxation and Legal Studies in Business, Frank G. Zarb School of Business, Hofstra University, Hempstead, NY 11549, United States; Hunter College - City University of New York, 695 Park Avenue, New York, NY 10065, United States},
  author_keywords         = {Accounting curriculum; Big Data; Competency integration; Information systems; Technology},
  correspondence_address1 = {Sledgianowski, D.; Department of Accounting, Taxation and Legal Studies in Business, Frank G. Zarb School of Business, Hofstra UniversityUnited States; email: Deb.Sledgianowski@Hofstra.edu},
  document_type           = {Article},
  doi                     = {10.1016/j.jaccedu.2016.12.008},
  language                = {English},
  publisher               = {Elsevier Ltd},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009227848&doi=10.1016%2fj.jaccedu.2016.12.008&partnerID=40&md5=e860959f2ac92580f5747386fc232cd6},
}

@Article{Tian2017169,
  author                  = {Tian, X. and Liu, L.},
  title                   = {Does big data mean big knowledge? Integration of big data analysis and conceptual model for social commerce research},
  journal                 = {Electronic Commerce Research},
  year                    = {2017},
  volume                  = {17},
  number                  = {1},
  pages                   = {169-183},
  issn                    = {13895753},
  note                    = {cited By 2},
  abbrev_source_title     = {Electron. Commer. Res.},
  abstract                = {The Big Data era has descended on many communities, from governments and e-commerce to health organizations. Information systems designers face great opportunities and challenges in developing a holistic big data research approach for the new analytics savvy generation. In addition business intelligence is largely utilized in the business community and thus can leverage the opportunities from the abundant data and domain-specific analytics in many critical areas. The aim of this paper is to assess the relevance of these trends in the current business context through evidence-based documentation of current and emerging applications as well as their wider business implications. In this paper, we use BigML to examine how the two social information channels (i.e., friends-based opinion leaders-based social information) influence consumer purchase decisions on social commerce sites. We undertake an empirical study in which we integrate a framework and a theoretical model for big data analysis. We conduct an empirical study to demonstrate that big data analytics can be successfully combined with a theoretical model to produce more robust and effective consumer purchase decisions. The results offer important and interesting insights into IS research and practice. © 2016, Springer Science+Business Media New York.},
  affiliation             = {Department of Business Technology and Entrepreneurship, Faculty of Business and Law, Swinburne University of Technology, Melbourne, Australia},
  author_keywords         = {Big data; Business intelligence; Customer knowledge management; Customer purchase behavior},
  correspondence_address1 = {Tian, X.; Department of Business Technology and Entrepreneurship, Faculty of Business and Law, Swinburne University of TechnologyAustralia; email: stian@swin.edu.au},
  document_type           = {Article},
  doi                     = {10.1007/s10660-016-9242-7},
  language                = {English},
  publisher               = {Springer New York LLC},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989168012&doi=10.1007%2fs10660-016-9242-7&partnerID=40&md5=33ce964fe42aeff2c263c3761aae4476},
}

@Conference{Chen2017238,
  author              = {Chen, W. and Wang, R. and Wu, R. and Tang, L. and Fan, J.},
  title               = {Multi-source and heterogeneous data integration model for big data analytics in power DCS},
  year                = {2017},
  editor              = {Xie B., Xu X.},
  pages               = {238-242},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 1},
  abbrev_source_title = {Proc. - Int. Conf. Cyber-Enabled Distrib. Comput. Knowl. Discov., CyberC},
  abstract            = {It is the vital significance for the strong and smart grid that big data analytics technologies apply in the power system. The multi-source and heterogeneous data integration technology based on big data platform is one of the indispensable content. As there are the problems of data heterogeneity and data islands in the dispatching and control system, a multi-source and heterogeneous data integration model is proposed for big data analytics. This model exists the data integration layer in the platform of big data analytics. The model can improve the Extract-Transform-Load (ETL) process in the big data platform according to the extracting rules and transform rules, which are made by uniform data model in the panoramic dispatching and control system. Research shows that the integrating model developed here is efficient to establish panoramic data and can adapt to various data sources by building uniform data model in the power dispatching and control system. With the development of big data technology, it is expected that the data integration model will be improved and used in more electric power applications. © 2016 IEEE.},
  affiliation         = {Jincheng Power Supply Company, Jincheng, China; North China Electric Power University, Beijing, China; Beijing Guodiantong Network Technology Co. Ltd., Beijing, China},
  art_number          = {7864239},
  author_keywords     = {Big data analysis; Data integration model; Power dispatching and control system; Uniform data model},
  document_type       = {Conference Paper},
  doi                 = {10.1109/CyberC.2016.54},
  isbn                = {9781509051540},
  journal             = {Proceedings - 2016 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery, CyberC 2016},
  keywords            = {Control systems; Data integration; Data mining; Distributed computer systems; Electric load dispatching; Electric power transmission networks; Power control; Smart power grids, Data heterogeneity; Electric power applications; Extract transform loads; Heterogeneous data integrations; Integrating model; Integration models; Power dispatching; Uniform data modeling, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015879783&doi=10.1109%2fCyberC.2016.54&partnerID=40&md5=2e27044e52263c13b589882450f85129},
}

@Article{Li2017267,
  author                  = {Li, G. and Huang, Z.},
  title                   = {Data Infrastructure for Remote Sensing Big Data: Integration, Management and On-Demand Service},
  journal                 = {Jisuanji Yanjiu yu Fazhan/Computer Research and Development},
  year                    = {2017},
  volume                  = {54},
  number                  = {2},
  pages                   = {267-283},
  issn                    = {10001239},
  note                    = {cited By 0},
  abbrev_source_title     = {Jisuanji Yanjiu yu Fazhan},
  abstract                = {The increasing growth of remote sensing data and geoscience research pushes earth sciences strongly and poses great challenges to data infrastructures for remote sensing big data, including the collection, storage, management, analysis and delivery. The de-fact remote sensing data infrastructures become bottleneck of the workflows for remote sensing data analysis because of their capability, scalability and performance. In this paper, data infrastructures for remote sensing big data are catalogued into 6 classes based on the features such as basic service unit, distributivity, heterogeneous, space-time continuation and on-demand processing. Then, architectures are designed for all the 6 classes of data infrastructures, and some implementation technologies such as data collection and integration, data storage and management, data service interface, and on-demand data processing, are discussed. With the architecture designs and implementation technologies, data infrastructures for remote sensing big data will provide PaaS (platform-as-a-service) and SaaS(software-as-a-service) services for developing much more remote sensing data analysis applications. With continuously growing data, tools and libraries in the infrastructures, users can easily develop analysis models to process remote sensing big data, create new applications based on these models, and exchange their knowledge each other by sharing models. © 2017, Science Press. All right reserved.},
  affiliation             = {Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, 100094, China; Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, China},
  author_keywords         = {Data infrastructure; Data integration; Data management; On-demand processing; Remote sensing big data},
  coden                   = {JYYFE},
  correspondence_address1 = {Huang, Z.; Department of Computer Science and Technology, Tsinghua UniversityChina; email: huangzc@tsinghua.edu.cn},
  document_type           = {Article},
  doi                     = {10.7544/issn1000-1239.2017.20160837},
  keywords                = {Application programs; Data handling; Data integration; Digital storage; Information analysis; Information management; Knowledge management; Platform as a Service (PaaS); Remote sensing; Software as a service (SaaS); Space optics; Storage management, Architecture designs; Data infrastructure; New applications; On demands; On-demand services; Remote sensing data; SaaS (software as a service); Scalability and performance, Big data},
  language                = {Chinese},
  publisher               = {Science Press},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019882530&doi=10.7544%2fissn1000-1239.2017.20160837&partnerID=40&md5=b1fd3230ff9dca0949ec7f460d5afcb1},
}

@Conference{Hajoui2017,
  author                  = {Hajoui, O. and Talea, M. and Bakhouyi, A. and Batouta, Z.I. and Dehbi, R.},
  title                   = {A comparative analysis of different approaches for big data interoperability},
  year                    = {2017},
  editor                  = {Ouzzif M., Jarir Z.},
  publisher               = {Institute of Electrical and Electronics Engineers Inc.},
  note                    = {cited By 0},
  abbrev_source_title     = {Proc. - Int. Conf. Syst. Collab., SysCo},
  abstract                = {NoSQL databases are an effective solution for storing and processing large data, but these databases are heterogeneous. They offer different data storage models, implementations and languages to developers and users. This wide variety of platforms makes it difficult data interoperability, data integration and even data migration from one system to another. This paper proposes a literature review of papers related to big data interoperability. This paper also compares different big data interoperability approaches using a multi-criteria analysis by applying the Complex Proportional Assessment Method (COPRAS). © 2016 IEEE.},
  affiliation             = {LTI Laboratory, Faculty of Science Ben M'Sik, Hassan II University, Casablanca, Morocco; LR2I Laboratory, Faculty of Science Aïn Chock, Hassan II University, Casablanca, Morocco},
  art_number              = {7831345},
  author_keywords         = {big data; D polyglot persistence; interoperability; Multi-Criteria Analysis Method (COPRAS); NoSQL databases},
  correspondence_address1 = {Hajoui, O.; LTI Laboratory, Faculty of Science Ben M'Sik, Hassan II UniversityMorocco; email: hajouio@yahoo.fr},
  document_type           = {Conference Paper},
  doi                     = {10.1109/SYSCO.2016.7831345},
  isbn                    = {9781509049264},
  journal                 = {Proceedings - 2016 3rd International Conference on Systems of Collaboration, SysCo 2016},
  keywords                = {Data handling; Data integration; Database systems; Digital storage; Interoperability, Comparative analysis; Complex proportional assessments; Data interoperability; Data storage models; Effective solution; Literature reviews; Multi Criteria Analysis; Nosql database, Big data},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013959739&doi=10.1109%2fSYSCO.2016.7831345&partnerID=40&md5=b19cac72564ade3021a067f0a5ebf7e7},
}

@Conference{Nino20171326,
  author              = {Nino, M. and Saenz, F. and Blanco, J.M. and Illarramendi, A.},
  title               = {Requirements for a big data capturing and integration architecture in a distributed manufacturing scenario},
  year                = {2017},
  pages               = {1326-1329},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 2},
  abbrev_source_title = {IEEE Int. Conf. Ind. Informatics (INDIN)},
  abstract            = {Big Data is one of the key enabling technologies in smart manufacturing, where manufacturing companies aim at leveraging the data generated throughout their processes. The potential of Big Data Analytics is particularly significant in the context of manufacturing companies distributed worldwide. These companies own several manufacturing plants operating the same process in different environments and conditions. This generates massive amounts of data that could be analyzed in order to improve process efficiency and product quality. This paper presents the requirements for an architecture to capture, integrate and analyze the large-scale volumes of data generated in a real-world manufacturing business scenario - a chemical manufacturing sector distributed worldwide-. This scenario serves as a case study for an applied research project on Big Data Analytics. The business nature of this scenario provides those real-life requirements the architecture has to deal with. Existing approaches can be extended to fulfill these requirements, in order to be effectively applied in similar manufacturing business contexts. © 2016 IEEE.},
  affiliation         = {Department of Computer Languages and Systems, University of the Basque Country (UPV/EHU), San Sebastián, Spain; Savvy Data Systems, San Sebastián, Spain},
  art_number          = {7819372},
  author_keywords     = {Big Data Analytics; Cloud Computing; Decision-Guidance Systems; Industry 4.0; Predictive Analytics; Prescriptive Control; Smart Manufacturing},
  document_type       = {Conference Paper},
  doi                 = {10.1109/INDIN.2016.7819372},
  isbn                = {9781509028702},
  issn                = {19354576},
  journal             = {IEEE International Conference on Industrial Informatics (INDIN)},
  keywords            = {Chemical analysis; Cloud computing; Distributed computer systems; Flow control; Manufacture; Predictive analytics, Chemical manufacturing; Data analytics; Decision guidance; Distributed manufacturing; Integration architecture; Manufacturing business; Manufacturing companies; Smart manufacturing, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012900432&doi=10.1109%2fINDIN.2016.7819372&partnerID=40&md5=8954718569cac809292c9d97845f5950},
}

@Article{Pfrommer2017173,
  author                  = {Pfrommer, J.},
  title                   = {Semantic interoperability at big-data scale with the open62541 OPC UA implementation},
  journal                 = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year                    = {2017},
  volume                  = {10218 LNCS},
  pages                   = {173-185},
  issn                    = {03029743},
  note                    = {cited By 0},
  abbrev_source_title     = {Lect. Notes Comput. Sci.},
  abstract                = {The OPC Unified Architecture (OPC UA) is a protocol for Ethernet-based communication in industrial settings. At its core, OPC UA defines a set of services for interaction with a server-side information model that combines object-orientation with semantic technologies. Additional companion specifications use the OPC UA meta-model to define domain-specific modeling concepts for semantic interoperability. The open62541 project is an open source implementation of the OPC UA standard. In this work, we give a short introduction to the core concepts of OPC UA and how the measures taken to scale OPC UA to Big-Data scale reflect in the architecture of open62541. © Springer International Publishing AG 2017.},
  affiliation             = {Fraunhofer IOSB, Fraunhoferstraße 1, Karlsruhe, 76131, Germany},
  author_keywords         = {Big-data; OPC UA; Open source; Semantic interoperability},
  correspondence_address1 = {Pfrommer, J.; Fraunhofer IOSB, Fraunhoferstraße 1, Germany; email: julius.pfrommer@iosb.fraunhofer.de},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-319-56877-5_11},
  editor                  = {Broering A., Soursos S., Zarko I.P., Serrano M.},
  isbn                    = {9783319568768},
  keywords                = {Computer architecture; Internet of things; Interoperability; Network architecture; Process control; Semantics, Domain specific modeling; Ethernet-based communications; OPC UA; Opc unified architectures; Open source implementation; Open sources; Semantic interoperability; Semantic technologies, Big data},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018658917&doi=10.1007%2f978-3-319-56877-5_11&partnerID=40&md5=855602d63d64259354d4a6221eea052d},
}

@Conference{McDonald20172579,
  author                  = {McDonald, S. and Groff, C. and Low, M. and Panny, M. and Dent, S. and Ishida, C.},
  title                   = {How boynton beach Florida is pioneering optimization of water utilities through integration of big data analytics to create gis-centric decision support dashboards},
  year                    = {2017},
  volume                  = {4},
  pages                   = {2579-2585},
  publisher               = {Water Environment Federation},
  note                    = {cited By 0},
  abbrev_source_title     = {Water Environ. Fed. Tech. Exhib. Conf., WEFTEC},
  abstract                = {The future of utility management is being shaped by ‘big data’. The collection, processing, and ultimately, the presentation and interpretation of data will have a greater impact on utility management than any other factor currently facing managers, plant operators, or elected officials today. Therefore, the goal of utility management is to increase their power to leverage data to make informed decisions. These decisions include: capital and CIP planning; asset management and ‘just in time’ repair/replacement; financial management (reserve levels, debt vs. cash financing); and optimization of operations. To meet this goal, the vision of the Boynton Beach Utilities (BBU) is to create a Utility Management Optimization Plan (UMOP) Desktop. The BBU Desktop allows the ability to visualize and track trends, and allows dynamic control by utility managers to keep ahead of changing conditions through integrated CIP plans, financial analyses, and rate setting “smart dashboards”. Copyright © 2017 Water Environment Federation.},
  affiliation             = {McGovern McDonald Engineers, United States; Boynton Beach Utilities, City of Boynton Beach, Florida, United States; Carollo Engineers, Inc., United States},
  author_keywords         = {Algorithm-based decision support model; Big data analytics; Capital; CIP planning; GIS-centric management tools; Integrated water resources planning; O and M optimization},
  correspondence_address1 = {McDonald, S.; McGovern McDonald EngineersUnited States; email: smcdonald@mmewater.com},
  document_type           = {Conference Paper},
  isbn                    = {9781510863682},
  journal                 = {Water Environment Federation Technical Exhibition and Conference 2017, WEFTEC 2017},
  keywords                = {Beaches; Decision making; Decision support systems; Finance; Information management; Managers; Water resources, Big Data Analytics; Capital; Decision support models; Management tool; Water resources planning, Big data},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052094445&partnerID=40&md5=233f2691e169b9901b481055f9aa0be8},
}

@Conference{Giuffrida2017165,
  author                  = {Giuffrida, G. and Gozzo, S. and Mazzeo Rinaldi, F. and Tomaselli, V.},
  title                   = {Big data and network analysis: A promising integration for decision-making},
  year                    = {2017},
  editor                  = {Carlo Lauro N., Amaturo E., Grassia M.G., Aragona B., Marino M.},
  volume                  = {2},
  pages                   = {165-174},
  publisher               = {Springer Berlin Heidelberg},
  note                    = {cited By 0},
  abbrev_source_title     = {Stud. Classif., Data Anal., Knowl. Organ.},
  abstract                = {In recent years, we have witnessed an extraordinary growth in globally generated data. The automatic extraction of such extraordinary amount of data, together with innovative data mining and predictive analytics techniques, represents an innovative opportunity in supporting decision-making. Thus, the main aim of this paper is to explore the opportunity of integrating Big Data techniques with Network Analysis methods. In particular, our study employs descriptive measurements and clustering methods of Network Analysis in order to define relational structures within a Big Data set. We discuss a Big Data tool that collects and analyses information from user interactions with published news and comments about a case study related to a recent Italian constitutional review bill with important political implications. © Springer International Publishing AG 2017.},
  affiliation             = {Department of Political and Social Sciences, University of Catania, Catania, Italy; ABE School, Royal Institute of Techonology, KTH, Stockholm, Sweden},
  author_keywords         = {Big data; Data mining; Decision-making; Network analysis},
  correspondence_address1 = {Tomaselli, V.; Department of Political and Social Sciences, University of CataniaItaly; email: tomavene@unict.it},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-319-55477-8_15},
  isbn                    = {9783319554761},
  issn                    = {14318814},
  journal                 = {Studies in Classification, Data Analysis, and Knowledge Organization},
  keywords                = {Data integration; Data mining; Decision making; Electric network analysis; Predictive analytics, Automatic extraction; Clustering methods; Political implications; Relational structures; User interaction, Big data},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045289566&doi=10.1007%2f978-3-319-55477-8_15&partnerID=40&md5=c33bec8b91923a2551b18fbccbe3a53d},
}

@Article{Yun2017123,
  author                  = {Yun, G.J.},
  title                   = {Integration of experiments and simulations to build material big-data},
  journal                 = {Minerals, Metals and Materials Series},
  year                    = {2017},
  volume                  = {Part F4},
  pages                   = {123-130},
  issn                    = {23671181},
  note                    = {cited By 0},
  abbrev_source_title     = {Miner. Met. Mater. Ser.},
  abstract                = {In this paper, a method for extracting stress-strain databases from material test measurements is introduced as one of the potential Integrated Computational Materials Engineering (ICME) tools. Measuring spatially heterogeneous stress and strain evolutionary data during material tests is a challenging and costly task. The proposed method can extract a large volume of spatially heterogeneous stress and strain evolutionary data from experimental boundary measurements such as tractions and displacements. For the purpose, nonlinear finite element models are intrusively implemented with artificial neural network (ANN)-based material constitutive models. Then a specialized algorithm that can auto-progressively train ANN material models guided by experimental measurements is executed. Any complex constitutive law is not presumed. From the algorithm, ANN gradually learns complex material constitutive behavior. The training databases are gradually accumulated with self-corrected stress and strain data predicted by the ANN. Finally, material databases are obtained. For an example, visco-elastoplastic material databases are obtained by the proposed method. © The Minerals, Metals & Materials Society 2017.},
  affiliation             = {Department of Mechanical & Aerospace Engineering, Seoul National University, Building 301 Room 1308, Gwanak-ro 1, Gwanak-gu, Seoul, 08826, South Korea},
  author_keywords         = {Artificial intelligence neural network; Material Big-Data; Nonlinear finite element analysis; Self-learning simulation},
  correspondence_address1 = {Yun, G.J.; Department of Mechanical & Aerospace Engineering, Seoul National University, Building 301 Room 1308, Gwanak-ro 1, Gwanak-gu, South Korea; email: gunjin.yun@snu.ac.kr},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-319-57864-4_12},
  editor                  = {Mason P., Schmitz G.J., Singh A.K., Fisher C.R., Strachan A., Glamm R., Manuel M.V.},
  isbn                    = {9783319578637},
  keywords                = {Complex networks; Concrete bridges; Database systems; Evolutionary algorithms; Finite element method; Neural networks, Boundary measurements; Computational materials; Constitutive behaviors; Elastoplastic materials; Material constitutive models; Non-linear finite element model; Non-linear finite-element analysis; Self-learning, Big data},
  language                = {English},
  publisher               = {Springer International Publishing},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042420997&doi=10.1007%2f978-3-319-57864-4_12&partnerID=40&md5=a35cdc41e5c7c44315721e70fc8d727b},
}

@Article{Bernardin201775,
  author                  = {Bernardin, V.L., Jr. and Ferdous, N. and Sadrsadat, H. and Trevino, S. and Chen, C.-C.},
  title                   = {Integration of national long-distance passenger travel demand model with tennessee statewide model and calibration to big data},
  journal                 = {Transportation Research Record},
  year                    = {2017},
  volume                  = {2653},
  number                  = {1},
  pages                   = {75-81},
  issn                    = {03611981},
  note                    = {cited By 2},
  abbrev_source_title     = {Transp Res Rec},
  abstract                = {The Tennessee Department of Transportation replaced the quick-response-based long-distance component in its statewide model by integrating the new national long-distance passenger travel demand model in a new statewide model and calibrating it to long-distance trips observed in cell phone origin–destination data. The national long-distance model is a tour-based simulation model developed from FHWA research on long-distance travel behavior and patterns. The tool allows the evaluation of many policy scenarios, including fare or service changes for various modes, such as commercial air, intercity bus, Amtrak rail, and highway travel. The availability of this tool presents an opportunity for state departments of transportation in developing statewide models. Commercial big data from cell phones for long-distance trips also presents an opportunity and a new data source for long-distance travel patterns, which previously have been the subject of limited data collection, in the form of surveys. This project is the first to seize on both of these opportunities by integrating the national long-distance model with the new Tennessee statewide model and by processing big data for use as a calibration target for long-distance travel in a statewide model. The paper demonstrates the feasibility of integrating the national model with statewide models, the ability of the national model to be calibrated to new data sources, the ability to combine multiple big data sources, and the value of big data on long-distance travel, as well as important lessons on its expansion. © 2017, SAGE Publications Ltd. All rights reserved.},
  affiliation             = {RSG, 2709 Washington Avenue, Suite 9, Evansville, IN 47714, United States; CH2M, 2411 Dulles Corner Park, Suite 500, Herndon, VA 20171, United States; RSG, 2200 Wilson Boulevard, Suite 205, Arlington, VA 22201, United States; Tennessee Department of Transportation, James K. Polk Building, 505 Deaderick Street, Suite 900, Nashville, TN 37243-0334, United States},
  coden                   = {TRRED},
  correspondence_address1 = {Bernardin, V.L.; RSG, 2709 Washington Avenue, Suite 9, United States; email: Vince.Bernardin@RSGinc.com},
  document_type           = {Article},
  doi                     = {10.3141/2653-09},
  keywords                = {Calibration; Cellular telephones; Data integration; Mobile phones; Telephone sets, Calibration targets; Department of Transportation; Passenger travels; Policy scenario; Simulation model; State departments of transportations; Travel behaviors; Travel patterns, Big data},
  language                = {English},
  publisher               = {SAGE Publications Ltd},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041311972&doi=10.3141%2f2653-09&partnerID=40&md5=da824415b8a08bd416d98eadedab96b5},
}

@Conference{Ke20171584,
  author              = {Ke, D. and Jiang, W. and Ni, C.},
  title               = {Bibliometric study on big data research: An integration of topic model and citation network analysis},
  year                = {2017},
  pages               = {1584-1597},
  publisher           = {International Conference on Scientometrics and Informetrics},
  note                = {cited By 0},
  abbrev_source_title = {ISSI - Int. Conf. Scientometrics Informetrics, Conf. Proc.},
  abstract            = {Big data has been attracting wide attention due to its great importance. The rapid development of big data in recent years has led to a large amount of publications containing the achieved knowledge of this area. To study the intellectual structure of the related research about big data, a retrospective bibliometric analysis is conducted based on the Web of Science databases. 13673 papers and 8016 citation links are collected. The LD A topic model are used to detect the topic distribution of big data research area. 11 topics about big data technology, application and security are found. Island algorithm is applied to find the most influential 28 research communities from citation network, and these communicates are labelled through topic distribution rather than traditional way of single tag. Labelling each cluster by topic distribution can reveal the research content for sub-structures, which reflects a much more comprehensive picture of big data research area and provide a valuable reference for researchers to understand the overview and present situations in this field.},
  affiliation         = {School of Information Management, Wuhan University, Wuhan, China; Huazhong Agricultural University, Wuhan, China},
  author_keywords     = {Algorithm; Big data; Citation and co-citation analysis; Cluster; Social network analysis; Topic model},
  document_type       = {Conference Paper},
  journal             = {ISSI 2017 - 16th International Conference on Scientometrics and Informetrics, Conference Proceedings},
  keywords            = {Algorithms; Information analysis; Social networking (online), Bibliometric analysis; Citation networks; Cluster; Co-Citation Analysis; Intellectual structures; Research communities; Topic distributions; Topic Modeling, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036606753&partnerID=40&md5=2a48fd8c825d270eae5df574c6de2ce0},
}

@Article{Bonura201786,
  author                  = {Bonura, S. and Cammarata, G. and Finazzo, R. and Francaviglia, G. and Morreale, V.},
  title                   = {A novel WebGIS-based situational awareness platform for trustworthy big data integration and analytics in mobility context},
  journal                 = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year                    = {2017},
  volume                  = {10574 LNCS},
  pages                   = {86-98},
  issn                    = {03029743},
  note                    = {cited By 0},
  abbrev_source_title     = {Lect. Notes Comput. Sci.},
  abstract                = {The availability of big amounts of dynamic data from several sources in mobility context and their real time integration can deliver a picture for emergency management in urban and extra-urban areas. A WebGIS portal is able to support the perception of all elements in current situation. However, in general, during the observation decision maker’s attention capacity is not sufficient to address concerns due to information overload. A situational picture is necessary to go beyond the simple perception of the elements in the environment, supporting the overall comprehension of the current situation and providing predictions and decision support. In this paper we present MAGNIFIER, a WebGIS-based intelligent system for emergency management, to entirely support the real-time situational awareness. Starting from the current situation and by using the practical reasoning model by Bratman, MAGNIFIER is able to suggest the appropriate course of actions to be executed to meet decision maker’s goals. © 2017, Springer International Publishing AG.},
  affiliation             = {R&D Laboratory - Engineering Ingegneria Informatica S.p.A., Viale Regione Siciliana, Palermo, 7275, Italy},
  author_keywords         = {Big data integration; Big data real-time analytics; Decision support system; Emergency management; Intelligent system; Practical reasoning; Situational awareness; WebGIS},
  correspondence_address1 = {Bonura, S.; R&D Laboratory - Engineering Ingegneria Informatica S.p.A., Viale Regione Siciliana, Italy; email: susanna.bonura@eng.it},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-319-69459-7_6},
  editor                  = {Paschke A., Debruyne C., Gaaloul W., Papazoglou M., Panetto H., Ardagna C.A., Meersman R.},
  isbn                    = {9783319694580},
  keywords                = {Artificial intelligence; Big data; Civil defense; Data integration; Decision making; Decision support systems; Disasters; Intelligent systems; Risk management; Trusted computing, Emergency management; Practical reasoning; Real-time analytics; Situational awareness; Web-GIS, Information management},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032692026&doi=10.1007%2f978-3-319-69459-7_6&partnerID=40&md5=49498377522c78af954ac411ef7300d4},
}

@Conference{Rezaee2017,
  author              = {Rezaee, Z. and Homayoun, S. and Mora, M.},
  title               = {Integration of real-time analysis of big data into sustainability attributes},
  year                = {2017},
  editor              = {Mora M., Rico M.},
  volume              = {1890},
  publisher           = {CEUR-WS},
  note                = {cited By 0},
  abbrev_source_title = {CEUR Workshop Proc.},
  abstract            = {The use real-time analysis of big data necessitates auditors modify their evidence-gathering procedures of employing continuous auditing in assuring sustainability attributes. We suggest a model that integrates assurance and its continuous auditing into all five economic, governance, social, ethical and environmental (EGSEE) dimensions of sustainability performance reporting. Real-time analysis of big data facilitates more transparent and timely available information for auditors to perform procedures provide reasonable assurance on accuracy, consistency and completeness of information. Big Data is often referred to as electronic data and is the capability of accessing, analysing, and assessing a huge amount of data and transforming them into information in a timely manner for decision making. The application of Big Data and Data Science Analytics to auditing is currently at an early stage. This study examines the real-time analysis of big data, which including evidence-gathering procedures and tests on audit and assurance services for sustainability attributes. We provide policy, practical and educational implications of employing real-time analysis of big data for sustainability performance as the implementation of continues auditing.},
  affiliation         = {University of Memphis, Memphis, United States; University of Gävle, Gävle, Sweden; University of Bristol, Bristol, United Kingdom},
  author_keywords     = {Auditing; Big data; Sustainability; XBRL},
  document_type       = {Conference Paper},
  issn                = {16130073},
  journal             = {CEUR Workshop Proceedings},
  keywords            = {Decision making; Metadata; Sustainable development, Auditing; Continuous auditing; Electronic data; Evidence gatherings; Real time analysis; Sustainability performance; XBRL, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029057307&partnerID=40&md5=92683b75eef54f26a330f5fe7c9c33d1},
}

@Article{Kathiravelu20179,
  author                  = {Kathiravelu, P. and Chen, Y. and Sharma, A. and Galhardas, H. and Van Roy, P. and Veiga, L.},
  title                   = {On-demand service-based big data integration: Optimized for research collaboration},
  journal                 = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year                    = {2017},
  volume                  = {10494 LNCS},
  pages                   = {9-28},
  issn                    = {03029743},
  note                    = {cited By 1},
  abbrev_source_title     = {Lect. Notes Comput. Sci.},
  abstract                = {Biomedical research requires distributed access, analysis, and sharing of data from various disperse sources in the Internet scale. Due to the volume and variety of big data, materialized data integration is often infeasible or too expensive including the costs of bandwidth, storage, maintenance, and management. Óbidos (On-demand Big Data Integration, Distribution, and Orchestration System) provides a novel on-demand integration approach for heterogeneous distributed data. Instead of integrating data from the data sources to build a complete data warehouse as the initial step, Óbidos employs a hybrid approach of virtual and materialized data integrations. By allocating unique identifiers as pointers to virtually integrated data sets, Óbidos supports efficient data sharing among data consumers. We design Óbidos as a generic service-based data integration system, and implement and evaluate a prototype for multimodal medical data. © 2017, Springer International Publishing AG.},
  affiliation             = {INESC-ID/Instituto Superior Técnico, Universidade de Lisboa, Lisbon, Portugal; Université catholique de Louvain, Louvain-la-Neuve, Belgium; Peking University, Beijing, China; Emory University, Atlanta, GA, United States},
  author_keywords         = {Big data integration; DICOM; Extract, Transform, Load (ETL); Integrated data repository; Materialized data integration; Virtual data integration},
  correspondence_address1 = {Kathiravelu, P.; INESC-ID/Instituto Superior Técnico, Universidade de LisboaPortugal; email: pradeeban.kathiravelu@tecnico.ulisboa.pt},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-319-67186-4_2},
  editor                  = {Begoli E., Luo G., Wang F.},
  isbn                    = {9783319671857},
  keywords                = {Big data; Data mining; Data warehouses; Digital storage; Health care; Information management, Biomedical research; Data integration system; DICOM; Extract, Transform, Load (ETL); Integrated data; Integration approach; Research collaborations; Virtual data integration, Data integration},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028991507&doi=10.1007%2f978-3-319-67186-4_2&partnerID=40&md5=e7c80e1876173ba90b9db23ed758d731},
}

@Article{Abbes201717,
  author                  = {Abbes, H. and Gargouri, F.},
  title                   = {Managing modular ontology evolution under big data integration},
  journal                 = {Lecture Notes in Business Information Processing},
  year                    = {2017},
  volume                  = {299},
  pages                   = {17-28},
  issn                    = {18651348},
  note                    = {cited By 0},
  abbrev_source_title     = {Lect. Notes Bus. Inf. Process.},
  abstract                = {Big Data integration frameworks provide unified view of the data available from heterogeneous data sources. These data sources are continuously evolving, forcing systems that integrate them to adapt their global schema after each change. This gets more challenging when aiming to maintain the global schema always reflecting data sources content. To cope with such complexity, in this paper we describe evolution scenarios and manage modular ontology evolution within Big Data integration framework in an a priori way according to changes performed against the data sources. © Springer International Publishing AG 2017.},
  affiliation             = {MIRACL Laboratory, Higher Institute of Computer Science and Multimedia, Sfax University, Sfax, Tunisia},
  author_keywords         = {Big Data integration; Data source evolution; Modular ontology; Ontology evolution},
  correspondence_address1 = {Abbes, H.; MIRACL Laboratory, Higher Institute of Computer Science and Multimedia, Sfax UniversityTunisia; email: abbes.hanen@gmail.com},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-319-65930-5_2},
  editor                  = {Morabito V., Themistocleous M.},
  isbn                    = {9783319659299},
  keywords                = {Big data; Information management; Information systems; Ontology, Data-source; Data-sources; Global schemas; Heterogeneous data sources; Integration frameworks; Modular ontologies; Ontology evolution, Data integration},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028637879&doi=10.1007%2f978-3-319-65930-5_2&partnerID=40&md5=ea903ce1567c352863069a2bbe43eb47},
}

@Article{Li2017157,
  author                  = {Li, L.},
  title                   = {Integration of information security and network data mining technology in the era of big data},
  journal                 = {Acta Technica CSAV (Ceskoslovensk Akademie Ved)},
  year                    = {2017},
  volume                  = {62},
  number                  = {1},
  pages                   = {157-165},
  issn                    = {00017043},
  note                    = {cited By 0},
  abbrev_source_title     = {Acta Tech CSAV},
  abstract                = {The purpose of this paper is to apply data mining technology to effectively analyze and process these data and find valuable information that can help the decision and understanding. In the paper, privacy preserving algorithm to data mining is studied, and the methods of classification of privacy preserving algorithm for existing data mining are introduced. In addition, the existing algorithms are summarized from the perspective of data processing technology, and the algorithm is evaluated and analyzed with the given criteria. Moreover, a privacy preserving mining algorithm for frequent patterns based on the increase of noise is put forward, which solves two key problems: the noise increase and transaction noise in the way of the noise generated. At last, an experiment is designed to verify the effectiveness of privacy preserving algorithm facing frequent pattern mining proposed by this paper. And in the same experimental platform, the time and space efficiency of privacy preserving based on frequent pattern mining in data cleaning are compared. The experimental results and comparative analysis show that the the privacy preserving system has good performance. In conclusion, the effectiveness of the system is verified and it can be used in the protection of information security.},
  affiliation             = {Nanjing Audit University Jinshen College, Jiangsu Nanjing210000, China},
  author_keywords         = {Data mining; Frequent pattern mining; Privacy preserving},
  coden                   = {ATCVA},
  correspondence_address1 = {Li, L.; Nanjing Audit University Jinshen College, Jiangsu Nanjing, China},
  document_type           = {Article},
  keywords                = {Big data; Data handling; Data privacy; Security of data, Comparative analysis; Data mining technology; Data processing technologies; Experimental platform; Frequent pattern mining; Network data mining; Privacy preserving; Space efficiencies, Data mining},
  language                = {English},
  publisher               = {Academy of Sciences of the Czech Republic},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028596914&partnerID=40&md5=89ce212104ed3662574cede4386e83b5},
}

@Article{Kanika2017192,
  author                  = {Kanika and Agrawal, A. and Khan, R.A.},
  title                   = {Security integration in big data life cycle},
  journal                 = {Communications in Computer and Information Science},
  year                    = {2017},
  volume                  = {721},
  pages                   = {192-200},
  issn                    = {18650929},
  note                    = {cited By 1},
  abbrev_source_title     = {Commun. Comput. Info. Sci.},
  abstract                = {We are living in a modern age, where technology is all around us. On single click user can do anything just like book a ticket, shopping, take an appointment to anyone, see medical reports, etc. Technology is so accessible because smart phones ownership. Large amount of data about users which is generated from various sources such as social networking sites, sensors devices, medical data etc. is called big data. With the increased use of big data, there arise many issues; especially security issues which may badly impact a person’s or an organization’s privacy. Yazan et al., presented threat and security attack model for big data security lifecycle. In this paper authors presents a critical review of the work and describes some security issues of big data. An approach to secure threat model for big data lifecycle has been proposed as a main contribution of the paper. © Springer Nature Singapore Pte Ltd. 2017.},
  affiliation             = {Department of Information Technology, BBA University, Lucknow, India},
  author_keywords         = {Big data; Security issues; Security threat model for big data lifecycle},
  correspondence_address1 = {Kanika; Department of Information Technology, BBA UniversityIndia; email: Sharma.kanika247@gmail.com},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-981-10-5427-3_21},
  editor                  = {Tyagi V., Grosky W., Gupta P.K., Oren T., Singh M., Sharma A.},
  isbn                    = {9789811054266},
  keywords                = {Life cycle; mHealth; Smartphones, Critical review; Data lifecycle; Large amounts; Medical data; Security attacks; Security issues; Social networking sites; Threat modeling, Big data},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028312351&doi=10.1007%2f978-981-10-5427-3_21&partnerID=40&md5=67f01b6321cc356e633ab3fa54f63ae1},
}

@Article{Silva2017,
  author                  = {Silva, B.N. and Khan, M. and Han, K.},
  title                   = {Integration of Big Data analytics embedded smart city architecture with RESTful web of things for efficient service provision and energy management},
  journal                 = {Future Generation Computer Systems},
  year                    = {2017},
  issn                    = {0167739X},
  note                    = {cited By 6; Article in Press},
  abbrev_source_title     = {Future Gener Comput Syst},
  abstract                = {Emergence of smart things has revolutionized the conventional internet into a connected network of things, maturing the concept of Internet of Things (IoT). With the evolution of IoT, many attempts were made to realize the notion of smart cities. However, demands for processing enormous amount of data and platform incompatibilities of connected smart things hindered the actual implementation of smart cities. Keeping it in view, we proposed a Big Data analytics embedded smart city architecture, which is further integrated with the web via a smart gateway. Integration with the web provides a universal communication platform to overcome the platform incompatibilities of smart things. We introduced Big Data analytics to enhance data processing speed. Further, we evaluated authentic datasets to determine the threshold values for intelligent decision-making and to present the performance improvement gained in data processing. Finally, we presented a representational state transfer (RESTful) web of things (WoT) integrated smart building architecture (smart home) to reveal the performance improvements of the proposed smart city architecture in terms of network performance and energy management of smart buildings. © 2017 Elsevier B.V.},
  affiliation             = {School of Computer Science and Engineering, Kyungpook National University, Daegu, Republic of Korea, South Korea; Department of Computer Science, Sarhad University of Science and information Technology, Peshawar, Pakistan, Pakistan},
  author_keywords         = {Big Data analytics; RESTful architecture; Smart city; Smart home; Web of things},
  coden                   = {FGCSE},
  correspondence_address1 = {Han, K.South Korea; email: kjhan@knu.ac.kr},
  document_type           = {Article in Press},
  doi                     = {10.1016/j.future.2017.06.024},
  keywords                = {Automation; Data handling; Decision making; Energy management; Gateways (computer networks); Information management; Intelligent buildings; Internet of things; Network architecture; Smart city, Big Data Analytics; Communication platforms; Connected networks; Intelligent decision making; Internet of Things (IOT); Performance improvements; Representational state transfer; Smart homes, Big data},
  language                = {English},
  publisher               = {Elsevier B.V.},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026395983&doi=10.1016%2fj.future.2017.06.024&partnerID=40&md5=d6784057681700a2de79796e1a30f43e},
}

@Conference{Escobedo2017267,
  author              = {Escobedo, G. and Jacome, N. and Arroyo-Figueroa, G.},
  title               = {Big data \& analytics to support the renewable energy integration of smart grids case study: Power solar generation},
  year                = {2017},
  editor              = {Kantere V., Walters R., Ramachandran M., Munoz V.M., Chang V., Wills G.},
  pages               = {267-275},
  publisher           = {SciTePress},
  note                = {cited By 1},
  abbrev_source_title = {IoTBDS - Proc. Int. Conf. Int. Things, Big Data Secur.},
  abstract            = {Smart Grid is the modernization of electrical networks using intelligent systems and information technologies. In smart grid environment, the application of big data analytics based decision support and intelligent control are mainly in the following four aspects: power generation side management, micro grid and renewable energy management, asset management and collaborative operations, and demand side management. The objective of this research is to present a technological infrastructure for the management of large volumes of information through Big Data tools to support the integration of renewable energy. The infrastructure includes a methodological architecture for the acquisition, processing, storage, management, analysis, monitoring and forecast of large amounts of data. The development of a Big Data application for the analysis and monitoring of the information generated by photovoltaic systems is included as a case study. Solar generation technologies have experienced strong energy market growth in the past few years, with corresponding increase in local grid penetration. The goal is to have timely information to make better decisions to improve the integration of renewable energy in the Smart Grid. Copyright © 2017 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
  affiliation         = {Instituto Nacional de Electricidad Y Energías Limpias, Reforma 113, Cuernavaca, Morelos, Mexico},
  author_keywords     = {Big data; Data analytics; Distributed generation; Electric power utility; Information systems; Photovoltaic systems; Renewable energy; Smart grid},
  document_type       = {Conference Paper},
  isbn                = {9789897582455},
  journal             = {IoTBDS 2017 - Proceedings of the 2nd International Conference on Internet of Things, Big Data and Security},
  keywords            = {Big data; Data integration; Digital storage; Distributed power generation; Electric power system control; Electric power systems; Electric power transmission networks; Information management; Information systems; Integration; Intelligent systems; Internet of things; Photovoltaic cells; Solar power generation, Data analytics; Electric power utilities; Photovoltaic systems; Renewable energies; Smart grid, Smart power grids},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024385762&partnerID=40&md5=ed28c23ad7a9b13d1bae9affdcdf56a8},
}

@Article{FossoWamba2017477,
  author                  = {Fosso Wamba, S. and Mishra, D.},
  title                   = {Big data integration with business processes: a literature review},
  journal                 = {Business Process Management Journal},
  year                    = {2017},
  volume                  = {23},
  number                  = {3},
  pages                   = {477-492},
  issn                    = {14637154},
  note                    = {cited By 12},
  abbrev_source_title     = {Bus. Process Manage. J.},
  abstract                = {Purpose: The purpose of this paper is to improve the understanding of the integration of business process management (BPM), business process re-engineering (BPR) and business process innovation (BPI) with big data. It focusses on synthesizing research published in the period 2006-2016 to establish both what the authors know and do not know about this topic, identifying areas for future research. Design/methodology/approach: The research is based on a review of 49 published papers on big data, BPM, BPR and BPI in the top journals in the field 2006-2016. Findings: In this paper, the authors have identified the most influential works based on citations and PageRank methods. Through network analysis the authors identify four major clusters that provide potential opportunities for future investigation. Practical implications: It is important for practitioners to be aware of the benefits of big data, BPM, BPR and BPI integration. This paper provides valuable insights for practitioners. Originality/value: This paper is based on a comprehensive literature review, which gives big data researchers the opportunity to understand business processes in depth. In addition, highlighting many gaps in the current literature and developing an agenda for future research, will save time and effort for readers looking to research topics within big data and business processes. © 2017, © Emerald Publishing Limited.},
  affiliation             = {Department of Information, Operations and Management Sciences, Toulouse Business School, Toulouse, France; Indian Institute of Technology Kanpur, Kanpur, India},
  author_keywords         = {Bibliometric analysis; Big data analytics; Network analysis; Research methodology},
  correspondence_address1 = {Fosso Wamba, S.; Department of Information, Operations and Management Sciences, Toulouse Business SchoolFrance; email: fossowam@gmail.com},
  document_type           = {Review},
  doi                     = {10.1108/BPMJ-02-2017-0047},
  language                = {English},
  publisher               = {Emerald Group Publishing Ltd.},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021342482&doi=10.1108%2fBPMJ-02-2017-0047&partnerID=40&md5=0a84042fda2b83c70d53667c8691291e},
}

@Article{Liao201795,
  author                  = {Liao, S. and Xie, Y. and Xiao, F.},
  title                   = {Research on the integration of architecture and interior design in the era of big data},
  journal                 = {Agro Food Industry Hi-Tech},
  year                    = {2017},
  volume                  = {28},
  number                  = {1},
  pages                   = {95-97},
  issn                    = {17226996},
  note                    = {cited By 0},
  abbrev_source_title     = {Agro Food Ind. Hi-Tech},
  abstract                = {Adopt building design and home interior design into the design processes so that both sides would be improved as required for the trend of social development. Therefore, this article would make deep analysis towards building and home design at this big data era based on concepts of building and home design integration. The analysis covered 4 aspects, building and home interior structure integration, cultivation integration, management and implementation integration, user engagement integration, which formed the integrated mode of building and interior home design, aiming to provide a brand new view of practical design plan towards building and home interior, and brings valuable reference for designers.},
  affiliation             = {Hunan Institute of Technology, Hengyang, Hunan, China; School of Business, Hunan Agricultural University, Changsha, Hunan, China},
  author_keywords         = {Architectural design; Big data era; Integration; Interior design; Workflow},
  correspondence_address1 = {Xiao, F.; Hunan Institute of TechnologyChina},
  document_type           = {Article},
  keywords                = {Big data; Buildings; Data integration; Integration; Interiors (building), Building design; Design integrations; Design process; Interior designs; Interior structure; Social development; User engagement; Workflow, Architectural design},
  language                = {English},
  publisher               = {TeknoScienze},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020498283&partnerID=40&md5=b46e028ed542cebbb9aacf8c399c7c59},
}

@Article{Kureychik2017302,
  author                  = {Kureychik, V. and Semenova, A.},
  title                   = {Combined method for integration of heterogeneous ontology models for big data processing and analysis},
  journal                 = {Advances in Intelligent Systems and Computing},
  year                    = {2017},
  volume                  = {573},
  pages                   = {302-311},
  issn                    = {21945357},
  note                    = {cited By 1},
  abbrev_source_title     = {Adv. Intell. Sys. Comput.},
  abstract                = {In the given paper a combined method for integration of heterogeneous ontology for big data processing and analysis is proposed. This allows perform semantic search through heterogeneous information resources, represented by different ontologies. The fundamental difference of the proposed approach is that it allows obtaining optimal weights on the basis of which the optimal alignment of ontologies is carried out. Performed calculations validate the productivity of the proposed method. © Springer International Publishing AG 2017.},
  affiliation             = {Autonomous Federal State Institution of Higher Education, Southern Federal University, Rostov, Russian Federation},
  author_keywords         = {Big data; Multiobjective optimization; Ontology; Ontology alignment; Swarm intelligence},
  correspondence_address1 = {Semenova, A.; Autonomous Federal State Institution of Higher Education, Southern Federal UniversityRussian Federation; email: alexaforum@rambler.ru},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-319-57261-1_30},
  editor                  = {Silhavy R., Senkerik R., Kominkova Oplatkova Z., Prokopova Z., Silhavy S.},
  isbn                    = {9783319572604},
  keywords                = {Artificial intelligence; Data handling; Data integration; Intelligent systems; Multiobjective optimization; Ontology; Semantics; Swarm intelligence, Combined method; Data processing and analysis; Heterogeneous information; Heterogeneous ontology; Ontology alignment; Optimal alignments; Optimal weight; Semantic search, Big data},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018716411&doi=10.1007%2f978-3-319-57261-1_30&partnerID=40&md5=82614e8b9bacf440bc4273076fad4c6e},
}

@Conference{Nadal2017,
  author              = {Nadal, S. and Romero, O. and Abelló, A. and Vassiliadis, P. and Vansummeren, S.},
  title               = {An integration-oriented ontology to govern evolution in Big Data ecosystems},
  year                = {2017},
  editor              = {Orsi G., Song I.Y., Martoglia R., De Antonellis V., Ferro N., Theobald M., Marcel P., Mandreoli F., Silvello G., De Virgilio R., Nikolaou C., Guerra F., Theodoridis Y., Penzo W., Bianchini D., Kotzinos D., Ioannidis Y., Stoyanovich J., Christophides V., Ives Z.},
  volume              = {1810},
  publisher           = {CEUR-WS},
  note                = {cited By 3},
  abbrev_source_title = {CEUR Workshop Proc.},
  abstract            = {Big Data architectures allow to flexibly store and process heterogeneous data, from multiple sources, in its original format. The structure of those data, commonly supplied by means of REST APIs, is continuously evolving, forcing data analysts using it need to adapt their analytical processes after each release. This gets more challenging when aiming to perform an integrated or historical analysis of multiple sources. To cope with such complexity, in this paper we present the Big Data Integration ontology, the core construct for a data governance protocol that systematically annotates and integrates data from multiple sources in its original format. To cope with syntactic evolution in the sources, we present an algorithm that semi-automatically adapts the ontology upon new releases. A functional evaluation on real-world APIs is performed in order to validate our approach. 2017, Copyright is with the authors.},
  affiliation         = {Universitat Politècnica de Catalunya, BarcelonaTech, Spain; University of Ioannina, Greece; Université Libre de Bruxelles, Belgium},
  author_keywords     = {Evolution; Modeling; Semantic web; Semi-structured data; Stream data},
  document_type       = {Conference Paper},
  issn                = {16130073},
  journal             = {CEUR Workshop Proceedings},
  keywords            = {Data integration; Models; Ontology; Semantic Web, Analytical process; Data architectures; Evolution; Functional evaluation; Heterogeneous data; Historical analysis; Semi structured data; Stream data, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017169150&partnerID=40&md5=ae4c531bbcb856e37e394c9033dbeeef},
}

@Article{Zhang2017D18,
  author                  = {Zhang, Z. and Zhao, W. and Xiao, J. and Wang, Y. and Song, F. and Zhu, J. and Tang, B. and Yang, Y. and Chen, T. and Zhang, S. and Dong, L. and Sheng, X. and Xia, L. and Gao, C. and Sang, J. and Zhang, L. and Fang, W. and Lu, M. and Zhang, Z. and Zou, D. and Xu, X. and Hao, L. and Chen, M. and Tian, D. and Li, C. and Yuan, N. and Zeng, J. and Wang, J. and Shi, S. and Zhang, Y. and Du, Z. and Song, S. and Ge, X. and Sun, S. and Li, M. and Li, M. and Liu, L. and Wei, T. and He, Z. and Yu, C. and Yin, H. and Wang, G. and Sun, Y. and Zou, S. and Liang, Y. and Wu, S. and Wang, F. and Liang, F. and Li, R. and Niu, G. and Ma, L. and Chen, H. and Sun, Y. and Yu, L. and Zhai, S. and Sun, M.},
  title                   = {The BIG Data Center: From deposition to integration to translation},
  journal                 = {Nucleic Acids Research},
  year                    = {2017},
  volume                  = {45},
  number                  = {D1},
  pages                   = {D18-D24},
  issn                    = {03051048},
  note                    = {cited By 50},
  abbrev_source_title     = {Nucleic Acids Res.},
  abstract                = {Biological data are generated at unprecedentedly exponential rates, posing considerable challenges in big data deposition, integration and translation. The BIG Data Center, established at Beijing Institute of Genomics (BIG), Chinese Academy of Sciences, provides a suite of database resources, including (i) Genome Sequence Archive, a data repository specialized for archiving raw sequence reads, (ii) Gene Expression Nebulas, a data portal of gene expression profiles based entirely on RNA-Seq data, (iii) Genome Variation Map, a comprehensive collection of genome variations for featured species, (iv) Genome Warehouse, a centralized resource housing genome-scale data with particular focus on economically important animals and plants, (v) Methylation Bank, an integrated database of whole-genome single-base resolution methylomes and (vi) Science Wikis, a central access point for biological wikis developed for community annotations. The BIG Data Center is dedicated to constructing and maintaining biological databases through big data integration and value-added curation, conducting basic research to translate big data into big knowledge and providing freely open access to a variety of data resources in support of worldwide research activities in both academia and industry. All of these resources are publicly available and can be found at http://bigd.big.ac.cn. © The Author(s) 2016.},
  affiliation             = {BIG Data Center, Beijing Institute of Genomics (BIG), Chinese Academy of Sciences, Beijing, 100101, China; CAS Key Laboratory of Genome Sciences and Information, Beijing Institute of Genomics, Chinese Academy of Sciences, Beijing, 100101, China; University of Chinese Academy of Sciences, Beijing, 100049, China},
  coden                   = {NARHA},
  correspondence_address1 = {Zhang, Z.; BIG Data Center, Beijing Institute of Genomics (BIG), Chinese Academy of SciencesChina; email: zhangzhang@big.ac.cn},
  document_type           = {Article},
  doi                     = {10.1093/nar/gkw1060},
  keywords                = {access to information; Article; data processing; DNA methylation; gene expression; gene sequence; genetic database; genetic variation; genome; RNA methylation; RNA sequence; translational research; animal; Asian continental ancestry group; dog; gene expression profiling; genetic variation; genetics; genomics; human; metabolism; mouse; Oryza; rat; sorghum; system analysis, Animals; Asian Continental Ancestry Group; Databases, Genetic; DNA Methylation; Dogs; Gene Expression Profiling; Genetic Variation; Genomics; Humans; Mice; Oryza; Rats; Sorghum; Systems Integration},
  language                = {English},
  publisher               = {Oxford University Press},
  pubmed_id               = {27899658},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016104570&doi=10.1093%2fnar%2fgkw1060&partnerID=40&md5=27ae9597cfe2350db7ceb9b1b3dfbe7c},
}

@Article{Poleto201716,
  author              = {Poleto, T. and De Carvalho, V.D.H. and Costa, A.P.C.S.},
  title               = {The full knowledge of big data in the integration of interorganizational information: An approach focused on decision making},
  journal             = {International Journal of Decision Support System Technology},
  year                = {2017},
  volume              = {9},
  number              = {1},
  pages               = {16-31},
  issn                = {19416296},
  note                = {cited By 6},
  abbrev_source_title = {Int. J. Decis. Support Syst. Technol.},
  abstract            = {Big Data is a radical shift or an incremental change for the existing digital infrastructures, that include the toolset used to aid the decision making process such as information systems, data repositories, formal modeling, and analysis of decisions. This work aims to provide a theoretical approach about the elements necessary to apply the big data concept in the decision making process. It identifying key components of the big data to define an integrated model of decision making using data mining, business intelligence, decision support systems, and organizational learning all working together to provide decision support with a reliable visualization of the decision-related opportunities. The concepts of data integration and semantic also was explored in order to demonstrate that, once mined, data must be integrated, ensuring conceptual connections and bequeathing meaning to use them appropriately for problem solving in decision. © 2017, IGI Global.},
  affiliation         = {Universidade Federal de Pernambuco, Recife, Brazil; Universidade Federal de Alagoas, Delmiro Gouveia, Brazil},
  author_keywords     = {Big Data; Data Integration; Decision Making Process; Decision-Related Opportunities; Organizational Learning},
  document_type       = {Article},
  doi                 = {10.4018/IJDSST.2017010102},
  keywords            = {Artificial intelligence; Data integration; Data mining; Data visualization; Decision making; Decision support systems; Information management; Knowledge management; Problem solving; Semantics, Decision making process; Decision-Related Opportunities; Digital infrastructures; Incremental changes; Integrated modeling; Inter-organizational; Organizational learning; Theoretical approach, Big data},
  language            = {English},
  publisher           = {IGI Global},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007293232&doi=10.4018%2fIJDSST.2017010102&partnerID=40&md5=fe3b9a8a18907ba7e45bf952fb7a5a3e},
}

@Article{Thingom2017729,
  author                  = {Thingom, C. and Yeon, G.},
  title                   = {An integration of big data and cloud computing},
  journal                 = {Advances in Intelligent Systems and Computing},
  year                    = {2017},
  volume                  = {469},
  pages                   = {729-737},
  issn                    = {21945357},
  note                    = {cited By 1},
  abbrev_source_title     = {Adv. Intell. Sys. Comput.},
  abstract                = {In this era, Big data and Cloud computing are the most important topics for organizations across the globe amongst the plethora of software’s. Big data is the most rapidly expanding research tool in understanding and solving complex problems in different interdisciplinary fields such as engineering, management health care, e-commerce, social network marketing finance and others. Cloud computing is a virtual service which is used for computation, data storage, data mining by creating flexibility and at minimum cost. It is pay & use model which is the next generation platform to analyse the various data which comes along with different services and applications without physically acquiring them. In this paper, we try to understand and work on the integration model of both Cloud Computing and Big Data to achieve efficiency and faster outcome. It is a qualitative paper to determine the synergy. © Springer Science+Business Media Singapore 2017.},
  affiliation             = {Centre for Digital Innovation, Christ University, Bangalore, India},
  author_keywords         = {Big data; Cloud computing; Integration; Research; Software},
  correspondence_address1 = {Thingom, C.; Centre for Digital Innovation, Christ UniversityIndia; email: chintureena.thingom@christuniversity.in},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-981-10-1678-3_70},
  editor                  = {Bhateja V., Satapathy S.C., Joshi A.},
  isbn                    = {9789811016776},
  keywords                = {Cloud computing; Complex networks; Computer software; Data integration; Data mining; Digital storage; Information management; Integration; Research, Complex problems; Different services; Integration models; Interdisciplinary fields; Minimum cost; Network marketing; Research tools; Virtual service, Big data},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984985724&doi=10.1007%2f978-981-10-1678-3_70&partnerID=40&md5=4ea8fc1550ace0d3990da4ca9a851598},
}

@Article{Masseroli20163,
  author                  = {Masseroli, M. and Kaitoua, A. and Pinoli, P. and Ceri, S.},
  title                   = {Modeling and interoperability of heterogeneous genomic big data for integrative processing and querying},
  journal                 = {Methods},
  year                    = {2016},
  volume                  = {111},
  pages                   = {3-11},
  issn                    = {10462023},
  note                    = {cited By 14},
  abbrev_source_title     = {Methods},
  abstract                = {While a huge amount of (epi)genomic data of multiple types is becoming available by using Next Generation Sequencing (NGS) technologies, the most important emerging problem is the so-called tertiary analysis, concerned with sense making, e.g., discovering how different (epi)genomic regions and their products interact and cooperate with each other. We propose a paradigm shift in tertiary analysis, based on the use of the Genomic Data Model (GDM), a simple data model which links genomic feature data to their associated experimental, biological and clinical metadata. GDM encompasses all the data formats which have been produced for feature extraction from (epi)genomic datasets. We specifically describe the mapping to GDM of SAM (Sequence Alignment/Map), VCF (Variant Call Format), NARROWPEAK (for called peaks produced by NGS ChIP-seq or DNase-seq methods), and BED (Browser Extensible Data) formats, but GDM supports as well all the formats describing experimental datasets (e.g., including copy number variations, DNA somatic mutations, or gene expressions) and annotations (e.g., regarding transcription start sites, genes, enhancers or CpG islands). We downloaded and integrated samples of all the above-mentioned data types and formats from multiple sources. The GDM is able to homogeneously describe semantically heterogeneous data and makes the ground for providing data interoperability, e.g., achieved through the GenoMetric Query Language (GMQL), a high-level, declarative query language for genomic big data. The combined use of the data model and the query language allows comprehensive processing of multiple heterogeneous data, and supports the development of domain-specific data-driven computations and bio-molecular knowledge discovery. © 2016 Elsevier Inc.},
  affiliation             = {Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Piazza Leonardo da Vinci 32, Milano, 20133, Italy},
  author_keywords         = {Data interoperability; Data modeling; Genomic data management; Metadata management; Operations for genomics; Query languages},
  coden                   = {MTHDE},
  correspondence_address1 = {Masseroli, M.; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Piazza Leonardo da Vinci 32, Italy; email: marco.masseroli@polimi.it},
  document_type           = {Article},
  doi                     = {10.1016/j.ymeth.2016.09.002},
  keywords                = {Article; computer analysis; controlled study; copy number variation; CpG island; data analysis; data processing; epigenetics; gene expression; gene mapping; gene sequence; genetic database; genetic transcription; GenoMetric Query Language; Genomic Data Model; genomics; mathematical model; next generation sequencing; priority journal; software; somatic mutation; tertiary analysis; data mining; DNA sequence; genetics; genomics; high throughput sequencing; human; procedures; regulatory sequence; sequence alignment; software; transcription initiation site, Data Mining; DNA Copy Number Variations; Genomics; High-Throughput Nucleotide Sequencing; Humans; Regulatory Sequences, Nucleic Acid; Sequence Alignment; Sequence Analysis, DNA; Software; Transcription Initiation Site},
  language                = {English},
  publisher               = {Academic Press Inc.},
  pubmed_id               = {27637471},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999089927&doi=10.1016%2fj.ymeth.2016.09.002&partnerID=40&md5=a934be3cf82d0a344c72482b2cc1e740},
}

@Conference{Xu201638,
  author              = {Xu, G. and Wu, S. and Xie, P.},
  title               = {Integration and exchange method of multi-source heterogeneous big data for intelligent power distribution and utilization},
  year                = {2016},
  pages               = {38-42},
  publisher           = {Association for Computing Machinery},
  note                = {cited By 0},
  abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
  abstract            = {With the development of smart grid and big data technologies, the stability and economy of distribution network operation are enhanced effectively. Intelligent power distribution and utilization (IPDU) big data platform, which exchanges operation data with other related distribution network management systems, makes decisions for demand side management, power system and distributed energy operation strategies by analyzing the big data. In order to solve the data fusion and exchange problems among all information systems, we proposed a kind of general information model for multi-source heterogeneous big data. In addition, a data fusion and exchange mechanism is established based on circle buffer to ensure the data quality. Finally, this paper demonstrates the effective of the method of IPDU big data fusion method by the example of distribution network reconfiguration. The method proposed in this paper can satisfy the data exchanging demands of future smart grid and demand side management, and it also has good confluent and extensible feature. © 2016 ACM.},
  affiliation         = {North China Electric Power University, Beinong Road #2, Changping, Beijing, 102206, China},
  author_keywords     = {Data fusion and exchange; Information model; Intelligent power distribution and utilization; Multi-source and heterogeneous},
  document_type       = {Conference Paper},
  doi                 = {10.1145/3018009.3018040},
  isbn                = {9781450348195},
  journal             = {ACM International Conference Proceeding Series},
  keywords            = {Data fusion; Demand side management; Electric power transmission networks; Electric utilities; Electronic data interchange; Information management; Information systems; Information theory; Smart power grids, Data fusion methods; Distributed energies; Distribution network operation; Distribution network reconfiguration; General information; Information Modeling; Intelligent power; Multi-Sources, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014910872&doi=10.1145%2f3018009.3018040&partnerID=40&md5=d74525d4ec8afb992c4e5b498fd40baa},
}

@Conference{Mahapatra201611,
  author              = {Mahapatra, T. and Gerostathopoulos, I. and Prehofer, C.},
  title               = {Towards integration of big data analytics in Internet of Things mashup tools},
  year                = {2016},
  volume              = {Part F127184},
  pages               = {11-16},
  publisher           = {Association for Computing Machinery},
  note                = {cited By 2},
  abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
  abstract            = {The increasing number and sensing capabilities of connected devices offer unique opportunities for developing sophisticated applications that employ data analysis as part of their business logic to make informed decisions based on sensed data. So far, mashup tools have been successful in supporting application development for Internet of Things. At the same time, Big Data analytics tools have allowed the analysis of very large and diverse data sets. The problem is that there is no consolidated development approach for integrating the two fields, IoT mashups and Big Data analytics. Such integration should go beyond merely specifying IoT mashups that only act as data providers. Mashup developers should also be able to specify Big Data analytics jobs and consume their results within a single application model. In this paper, we contribute to the direction of integrating Big Data analytics with IoT mashup tools by highlighting the need for such integration and the challenges that it entails via concrete examples. We also provide a research and development roadmap that can pave the way forward. © 2016 ACM.},
  affiliation         = {Fakultät für Informatik, Technische Universität München, Germany},
  author_keywords     = {Big data analytics; Development support; Iot mashups},
  document_type       = {Conference Paper},
  doi                 = {10.1145/3017995.3017998},
  isbn                = {9781450348744},
  journal             = {ACM International Conference Proceeding Series},
  keywords            = {Data integration; Integration; Internet of things, Application development; Application modeling; Data analytics; Development approach; Development support; Informed decision; Mashups; Research and development, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022081799&doi=10.1145%2f3017995.3017998&partnerID=40&md5=574389032fc5327f8a23372ddf295d1f},
}

@Book{Souza2016195,
  title                   = {Big data integration, privacy, and security},
  publisher               = {CRC Press},
  year                    = {2016},
  author                  = {Souza, R. and Patil, C.},
  isbn                    = {9781498754187; 9781498754156},
  note                    = {cited By 0},
  abbrev_source_title     = {The Hum. Elem. of Big Data: Issues, Anal., and Perform.},
  abstract                = {Big Data is transformative, ubiquitous technology that is not going to end and just keeps going rapidly. Companies are rapidly executing Big Data projects to deliberately change their business prototypes to speed up their strategic growth, build their main products, and expand their worldwide existence. However, as these technologies grow they confront an increasing number of global laws and measures. Therefore, companies must look for opportunities and difficulties as they develop their Big Data governance projects to enhance Big Data's features, while properly addressing issues of global privacy, security, and compliance. © 2017 by Taylor & Francis Group, LLC.},
  affiliation             = {Cipher Ltd., São Paulo, Brazil; Texec Pvt. Ltd., Pune, India},
  correspondence_address1 = {Souza, R.; Cipher Ltd.Brazil},
  document_type           = {Book Chapter},
  doi                     = {10.1201/9781315368061},
  journal                 = {The Human Element of Big Data: Issues, Analytics, and Performance},
  keywords                = {Data integration; Data privacy, Speed up; Strategic growth; Ubiquitous technology, Big data},
  language                = {English},
  pages                   = {195-212},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052921363&doi=10.1201%2f9781315368061&partnerID=40&md5=ae567896a59cb6443732f96aa07cc067},
}

@Conference{Xiang20161984,
  author              = {Xiang, F. and Chen, X. and Jiang, G.},
  title               = {A new manufacturing resources integration and sharing modes in big data environment},
  year                = {2016},
  pages               = {1984-1987},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Proc. IEEE Conf. Ind. Electron. Appl., ICIEA},
  abstract            = {The scale effect of big data brings great challenges to manufacturing resource integration, modeling, analysis and sharing. According to the application requirements, function requirements, performance requirements and operation conditions of manufacturing resources integration and sharing (MRIS) in big data environment, the characteristics of manufacturing resource big data are analyzed, then, a MRIS framework and three kinds of MRIS methods are proposed, such as physical centralization by merging the data source, physical centralization by maintaining the data source and logic centralization. © 2016 IEEE.},
  affiliation         = {School of Mechanical and Electronic Engineering, Wuhan University of Science and Technology, Wuhan, China},
  art_number          = {7603914},
  author_keywords     = {big data; logic centralization; Manufacturing resources integration and sharing; physical centralization},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICIEA.2016.7603914},
  isbn                = {9781509026050},
  journal             = {Proceedings of the 2016 IEEE 11th Conference on Industrial Electronics and Applications, ICIEA 2016},
  keywords            = {Computer circuits; Data integration; Industrial electronics; Integration; Manufacture, Application requirements; Data environment; Function requirements; logic centralization; Manufacturing resource; Operation conditions; Performance requirements; physical centralization, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997190796&doi=10.1109%2fICIEA.2016.7603914&partnerID=40&md5=e270ae9760594972c9c579565746370f},
}

@Article{Arunkumar201617681,
  author                  = {Arunkumar, G. and Madhu Viswanatham, V.},
  title                   = {Autonomic computing integration in server management,cloud computing and big-data},
  journal                 = {International Journal of Pharmacy and Technology},
  year                    = {2016},
  volume                  = {8},
  number                  = {3},
  pages                   = {17681-17693},
  issn                    = {0975766X},
  note                    = {cited By 1},
  abbrev_source_title     = {Intl. J. Pharm. Technol.},
  abstract                = {Autonomic computing has proved its ability to develop less human intervention systems over different areas of computing. This paper focus more on integration of autonomic computing architecture and policies used in various areas of computing. Server management aspects like performance enhancement,automatic work load provisioning,and load balancing can be automated using autonomic computing policies. Cloud environments are most essential in maintaining various resources to provide service. Management of provisioning allocation,data flow and Qos in cloud computing can be integrated with autonomic computing polices. Big data manages a variety of data from various sources to perform analysis and produces useful information to the users. Autonomic computing architecture can be used for management of data in tasks like automatic collection,auditing,uploading and consolidating data. © 2016,International Journal of Pharmacy and Technology. All rights reserved.},
  affiliation             = {SCSE, VIT University, Vellore, India},
  author_keywords         = {JIS; JVM; MAPE; ORB; PMI; QOS},
  correspondence_address1 = {Arunkumar, G.; SCSE, VIT UniversityIndia; email: arunkumar.g@vit.ac.in},
  document_type           = {Article},
  keywords                = {cloud computing; human; police; workload},
  language                = {English},
  publisher               = {International Journal of Pharmacy and Technology},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992347198&partnerID=40&md5=cc101bf8053ea4cbc780ce0a49313993},
}

@Conference{Utmal2016890,
  author              = {Utmal, M. and Pandey, R.K.},
  title               = {Taxonomy on the Integration of Hadoop and Rapid Miner for Big Data Analytics},
  year                = {2016},
  pages               = {890-893},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Proc. - Int. Conf. Comput. Intell. Commun. Networks, CICN},
  abstract            = {Today's research and industry aims at working with large data sets. High scalability and fault tolerance have been provided by some distributed data analytical solution like Hadoop but they are not too much user friendly and their functionalities can be exploited solely by the developer. The present paper proposes the concept of Radoop which is an extension of Rapid Miner a data mining tool with Hadoop functionalities. Our conclusion in the present paper is based on the fact that Radoop is a tool which is made for handling Big data analytics and meets well with the ever increasing demands of the data size. © 2015 IEEE.},
  affiliation         = {UICSA, RDVV, Jabalpur, India},
  art_number          = {7546223},
  author_keywords     = {Big Data; Hadoop; Radoop; Rapid Miner},
  document_type       = {Conference Paper},
  doi                 = {10.1109/CICN.2015.175},
  isbn                = {9781509000760},
  journal             = {Proceedings - 2015 International Conference on Computational Intelligence and Communication Networks, CICN 2015},
  keywords            = {Artificial intelligence; Data handling; Data mining; Fault tolerance; Industrial research; Miners, Data analytics; Data-mining tools; Distributed data; Hadoop; High scalabilities; Large datasets; Radoop; User friendly, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985902357&doi=10.1109%2fCICN.2015.175&partnerID=40&md5=bb3050b8ed9223560b4f4699046b6f44},
}

@Article{Chang20161680,
  author                  = {Chang, B.-R. and Tsai, H.-F. and Tsai, Y.-C. and Kuo, C.-F. and Chen, C.-C.},
  title                   = {Integration and optimization of multiple big data processing platforms},
  journal                 = {Engineering Computations (Swansea, Wales)},
  year                    = {2016},
  volume                  = {33},
  number                  = {6},
  pages                   = {1680-1704},
  issn                    = {02644401},
  note                    = {cited By 4},
  abbrev_source_title     = {Eng. Comput. (Swansea Wales)},
  abstract                = {Purpose - The purpose of this paper is to integrate and optimize a multiple big data processing platform with the features of high performance, high availability and high scalability in big data environment. Design/methodology/approach - First, the integration of Apache Hive, Cloudera Impala and BDAS Shark make the platform support SQL-like query. Next, users can access a single interface and select the best performance of big data warehouse platform automatically by the proposed optimizer. Finally, the distributed memory storage system Memcached incorporated into the distributed file system, Apache HDFS, is employed for fast caching query results. Therefore, if users query the same SQL command, the same result responds rapidly from the cache system instead of suffering the repeated searches in a big data warehouse and taking a longer time to retrieve. Findings - As a result the proposed approach significantly improves the overall performance and dramatically reduces the search time as querying a database, especially applying for the high-repeatable SQL commands under multi-user mode. Research limitations/implications - Currently, Shark's latest stable version 0.9.1 does not support the latest versions of Spark and Hive. In addition, this series of software only supports Oracle JDK7. Using Oracle JDK8 or Open JDK will cause serious errors, and some software will be unable to run. Practical implications - The problem with this system is that some blocks are missing when too many blocks are stored in one result (about 100,000 records). Another problem is that the sequential writing into In-memory cache wastes time. Originality/value - When the remaining memory capacity is 2 GB or less on each server, Impala and Shark will have a lot of page swapping, causing extremely low performance. When the data scale is larger, it may cause the JVM I/O exception and make the program crash. However, when the remaining memory capacity is sufficient, Shark is faster than Hive and Impala. Impala's consumption of memory resources is between those of Shark and Hive. This amount of remaining memory is sufficient for Impala's maximum performance. In this study, each server allocates 20 GB of memory for cluster computing and sets the amount of remaining memory as Level 1: 3 percent (0.6 GB), Level 2: 15 percent (3 GB) and Level 3: 75 percent (15 GB) as the critical points. The program automatically selects Hive when memory is less than 15 percent, Impala at 15 to 75 percent and Shark at more than 75 percent. © 2016 Emerald Group Publishing Limited.},
  affiliation             = {Department of Computer Science and Information Engineering, National University of Kaohsiung, Kaohsiung, Taiwan; Department of Marketing Management, Shu Te University, Kaohsiung, Taiwan; Department of Electrical Engineering, National Chiayi University, Chiayi City, Taiwan},
  author_keywords         = {Data warehouse; Distributed file system; Distributed memory storage; In-memory computing; Multiple big data processing platforms; SQL-like query},
  coden                   = {ENCOE},
  correspondence_address1 = {Kuo, C.-F.; Department of Computer Science and Information Engineering, National University of KaohsiungTaiwan; email: chinfukuo2006@nuk.edu.tw},
  document_type           = {Article},
  doi                     = {10.1108/EC-08-2015-0247},
  keywords                = {Cache memory; Cluster computing; Data handling; Data warehouses; Digital storage; Distributed computer systems; File organization; Memory architecture; Query processing; Search engines, Data environment; Design/methodology/approach; Distributed file systems; Distributed Memory; High availability; High scalabilities; Like queries; Processing platform, Big data},
  language                = {English},
  publisher               = {Emerald Group Publishing Ltd.},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978473165&doi=10.1108%2fEC-08-2015-0247&partnerID=40&md5=8c51b9e301f72f001d60a4c190d8bb66},
}

@Conference{Aggoune201621,
  author              = {Aggoune, A. and Bouramoul, A. and Kholladi, M.-K.},
  title               = {Big data integration: A semantic mediation architecture using summary},
  year                = {2016},
  pages               = {21-25},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 1},
  abbrev_source_title = {Int. Conf. Adv. Technol. Signal Image Process., ATSIP},
  abstract            = {This paper presents our semantic mediation architecture for homogeneously retrieving data from big data. The architecture is split into three layers to find relevant answers of this data. In the proposed ontology-based approach, we use our domain ontology on alimentation risks field as well as a global schema of mediator and we apply the summarization process based on ontology for describes part of the data set. Thus, the auto evolution of ontology is based on this huge amount of data. The research of answer is related to relevant summaries which represent high-level semantics. © 2016 IEEE.},
  affiliation         = {Fundamental Computer Science and Its Applications Department, University of Constantine2, Labstic Laboratory, Guelma University, Algeria; Fundamental Computer Science and Its Applications Department, Misc Laboratory, University of Constantine2, Algeria; El-Oued University, Misc Laboratory, University of Constantine2, Algeria},
  art_number          = {7523044},
  author_keywords     = {big data; matching; mediation architecture; ontology; semantic integration; summarization},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ATSIP.2016.7523044},
  isbn                = {9781467385268},
  journal             = {2nd International Conference on Advanced Technologies for Signal and Image Processing, ATSIP 2016},
  keywords            = {Architecture; Data integration; Image processing; Ontology; Semantics, Domain ontologies; Global schemas; High level semantics; matching; Mediation architecture; Semantic integration; Semantic mediation; summarization, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984636030&doi=10.1109%2fATSIP.2016.7523044&partnerID=40&md5=d13b57982ad348b2ea10c6e91294ac01},
}

@Conference{Chiu2016,
  author              = {Chiu, C.-H. and Lewis, N. and Singh, D.K. and Das, A.K. and Jalazai, M.M. and Platania, R. and Goswami, S. and Lee, K. and Park, S.-J.},
  title               = {BIC-LSU: Big data research integration with cyberinfrastructure for LSU},
  year                = {2016},
  volume              = {17-21-July-2016},
  publisher           = {Association for Computing Machinery},
  note                = {cited By 1},
  abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
  abstract            = {In recent years, big data analysis has been widely applied to many research fields including biology, physics, transporta-tion, and material science. Even though the demands for big data migration and big data analysis are dramatically increasing in campus IT infrastructures, there are several technical challenges that need to be addressed. First of all, frequent big data transmission between storage systems in different research groups imposes heavy burdens on a regular campus network. Second, the current campus IT infrastructure is not designed to fully utilize the hardware capacity for big data migration and analysis. Last but not the least, running big data applications on top of large-scale high-performance computing facilities is not straightforward, especially for researchers and engineers in non-IT disciplines. We develop a campus IT cyberinfrastructure for big data migration and analysis, called BIC-LSU, which consists of a task-aware Clos OpenFlow network, high-performance cache storage servers, customized high-performance transfer appli-cations, a light-weight control framework to manipulate ex-isting big data storage systems and job scheduling systems, and a comprehensive social networking-enabled web portal. BIC-LSU achieves 40Gb/s disk-to-disk big data transmis-sion, maintains short average transmission task completion time, enables the convergence of control on commonly de-ployed storage and job scheduling systems, and enhances easiness of big data analysis with a universal user-friendly interface. BIC-LSU software requires minimum dependen-cies and has high extensibility. Other research institutes can easily customize and deploy BIC-LSU as an augmented service on their existing IT infrastructures.},
  affiliation         = {Division of Computer Science and Engineering, Center for Computation and Technology, Louisiana State University, Baton Rouge, LA 70803, United States},
  art_number          = {a28},
  document_type       = {Conference Paper},
  doi                 = {10.1145/2949550.2949556},
  isbn                = {9781450347556},
  journal             = {ACM International Conference Proceeding Series},
  keywords            = {Cache memory; Data handling; Data storage equipment; Digital storage; Information analysis; Portals; Scheduling; Storage (materials); Weight control, Big data applications; Convergence of control; Cyber infrastructures; Data storage systems; High performance computing; Task completion time; Technical challenges; User friendly interface, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989184499&doi=10.1145%2f2949550.2949556&partnerID=40&md5=538316c79b031277d7d422925253663e},
}

@Book{Grossmann2016103,
  title                   = {Big data-integration and cleansing environment for business analytics with DICE},
  publisher               = {Springer International Publishing},
  year                    = {2016},
  author                  = {Grossmann, W. and Moser, C.},
  isbn                    = {9783319394176; 9783319394169},
  note                    = {cited By 3},
  abbrev_source_title     = {Domain-Specific Concept. Model.: Concepts, Methods and Tools},
  abstract                = {The paper presents the Data Integration and Cleansing Environment- DICE. Its embedded modeling method supports the data understanding and data preparation phases for business analytics endeavours and subsequently decision-making in business process activities. A prototypical implementation is presented by using an example in the field of campaign management which uses traditional customer data in combination with (big) data about customer sentiments from microblogging platforms. © Springer International Publishing Switzerland 2016. All rights reserved.},
  affiliation             = {Faculty of Computer Science, University of Vienna, Vienna, 1090, Austria},
  author_keywords         = {Big data; Business analytics; Data cleansing; Data integration; Statistical metadata},
  correspondence_address1 = {Grossmann, W.; Faculty of Computer Science, University of ViennaAustria; email: wilfried.grossmann@univie.ac.at},
  document_type           = {Book Chapter},
  doi                     = {10.1007/978-3-319-39417-6_5},
  journal                 = {Domain-Specific Conceptual Modeling: Concepts, Methods and Tools},
  language                = {English},
  pages                   = {103-123},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026686215&doi=10.1007%2f978-3-319-39417-6_5&partnerID=40&md5=69cc2c62f64165d146f8c4ce92d9c4bc},
}

@Conference{LeFevre201663,
  author              = {LeFevre, J. and Liu, R. and Inigo, C. and Paz, L. and Ma, E. and Castellanos, M. and Hsu, M.},
  title               = {Building the enterprise fabric for Big Data with Vertica and Spark integration},
  year                = {2016},
  volume              = {26-June-2016},
  pages               = {63-75},
  publisher           = {Association for Computing Machinery},
  note                = {cited By 1},
  abbrev_source_title = {Proc. ACM SIGMOD Int. Conf. Manage. Data},
  abstract            = {Enterprise customers increasingly require greater flexibility in the way they access and process their Big Data while at the same time they continue to request advanced analytics and access to diverse data sources. Yet customers also still require the robustness of enterprise class analytics for their mission-critical data. In this paper, we present our initial efforts toward a solution that satisfies the above requirements by integrating the HPE Vertica enterprise database with Apache Spark's open source big data computation engine. In particular, it enables fast, reliable transferring of data between Vertica and Spark; and deploying Machine Learning models created by Spark into Vertica for predictive analytics on Vertica data. This integration provides a fabric on which our customers get the best of both worlds: it extends Vertica's extensive SQL analytics capabilities with Spark's machine learning library (MLlib), giving Vertica users access to a wide range of ML functions; it also enables customers to leverage Spark as an advanced ETL engine for all data that require the guarantees offered by Vertica. © 2016 ACM.},
  affiliation         = {HPE Vertica, Sunnyvale, CA, United States},
  document_type       = {Conference Paper},
  doi                 = {10.1145/2882903.2903744},
  isbn                = {9781450335317},
  issn                = {07308078},
  journal             = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
  keywords            = {Artificial intelligence; Data integration; Engines; Learning systems; Sales, Data computation; Data-sources; Enterprise customers; Enterprise database; Machine learning models; Mission critical; Predictive analytics; Users access, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979657039&doi=10.1145%2f2882903.2903744&partnerID=40&md5=40322f7e87c35bd183efd9329593a0ac},
}

@Conference{Udupi2016268,
  author              = {Udupi, P.K. and Malali, P. and Noronha, H.},
  title               = {Big data integration for transition from e-learning to smart learning framework},
  year                = {2016},
  pages               = {268-271},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 4},
  abbrev_source_title = {MEC Int. Conf. Big Data Smart City, ICBDSC},
  abstract            = {Technology innovations triggered enhancement of e-learning paradigm towards smart learning environment. Large data availability, information processing tools and techniques further created new approach and explorations in teaching and learning. Expansion of education technology framework, diversified content characteristics and huge volume of information availability further made the e-learning to spearhead the learning platform irrespective of technology constraints. Current trends in big data analysis and abreast technology interventions spearhead new dimensions of e-leaning towards smart learning. This paper identifies and evaluates the key points of e-learning paradigm and proposes the possibility creating new framework for big data integration. This paper further explores the possible research on an integrated system and proposes a new models for integration of smart technology and big data framework within the e-learning paradigm, that leads towards smart learning. © 2016 IEEE.},
  affiliation         = {Department of Computing, Middle East College, Oman},
  art_number          = {7460379},
  author_keywords     = {Bigdata; e-learning; smart learning; smart systems},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICBDSC.2016.7460379},
  isbn                = {9781509013654},
  journal             = {2016 3rd MEC International Conference on Big Data and Smart City, ICBDSC 2016},
  keywords            = {Computer aided instruction; Data integration; E-learning; Engineering education, Education technology; Information availability; Learning environments; smart learning; Smart System; Teaching and learning; Technology constraints; Technology innovation, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973569022&doi=10.1109%2fICBDSC.2016.7460379&partnerID=40&md5=ba0d014c01179747ade410e91a86792d},
}

@Article{Xue20161,
  author                  = {Xue, Y. and Lai, Y.},
  title                   = {Integration of macro energy thinking and big data thinking part two applications and explorations},
  journal                 = {Dianli Xitong Zidonghua/Automation of Electric Power Systems},
  year                    = {2016},
  volume                  = {40},
  number                  = {8},
  pages                   = {1-13},
  issn                    = {10001026},
  note                    = {cited By 49},
  abbrev_source_title     = {Dianli Xitong Zidonghue},
  abstract                = {In part one of this series paper, the big data thinking and the macro energy thinking have been explained. On one hand, the energy system is considered in the context of the cyber-physical system, to break down the physical barriers among power system, primary energy system and end-use energy system. On the other hand, the private network and the Internet are combined together to constitute the communication system, to break down the barriers between operation and business activities. Thus, the above-mentioned physical and information systems can be integrated into a cyber-physical system, through causal data, statistical data, gambling data and corresponding big data technology. Along this direction, this paper explores the applications of power (energy) big data. Based on several topics that have been studied, the significance and approaches of big data technology in enhancing the economy and reliability of energy flow in different spatial and temporal scales are induced, which include: (1) introduce casual analysis measures to topics that usually relied entirely on statistical analysis, to improve the applicability and accuracy; (2) introduce statistical analysis measures to topics that usually relied entirely on casual analysis, to enhance the efficiency; (3) combine casual analysis, statistical analysis and experimental economics simulation analysis, to create a new research area of what a single analysis paradigm cannot solved, such as the interactions between the macro energy system and the natural environment, the social environment, market economy, policy and other non-energy sectors. © 2016 Automation of Electric Power Systems Press.},
  affiliation             = {NARI Group Corporation, (State Grid Electric Power Research Institute), Nanjing, 211106, China; State Key Laboratory of Smart Grid Protection and Control, Nanjing, 211106, China},
  author_keywords         = {Application research; Big data technology; Cyber-physical system (CPS); Decision support; End-use energy; Primary energy; Smart grid},
  coden                   = {DXZIE},
  correspondence_address1 = {Lai, Y.; NARI Group Corporation, (State Grid Electric Power Research Institute)China; email: laiyening@sgepri.sgcc.com.cn},
  document_type           = {Article},
  doi                     = {10.7500/AEPS20160311004},
  keywords                = {Decision support systems; Economics; Embedded systems; Macros; Reliability analysis; Smart power grids; Statistical methods, Application research; Cyber-physical systems (CPS); Data technologies; Decision supports; End-uses; Primary energies; Smart grid, Big data},
  language                = {Chinese},
  publisher               = {Automation of Electric Power Systems Press},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966644200&doi=10.7500%2fAEPS20160311004&partnerID=40&md5=d5503ee566e1aa4349f83a90fed3d758},
}

@Conference{Ostrowski2016382,
  author              = {Ostrowski, D. and Rychtyckyj, N. and MacNeille, P. and Kim, M.},
  title               = {Integration of Big Data Using Semantic Web Technologies},
  year                = {2016},
  pages               = {382-385},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 9},
  abbrev_source_title = {Proc. - IEEE Int. Conf. Semantic Comput., ICSC},
  abstract            = {In order to realize the promise of Big Data, applications will have to consider the integration of many disparate data sources. Due to data heterogeneity, this task presents a number of challenges that may not be completely resolved with existing Extract-Transform-Load (ETL)-based frameworks. In this paper, we explore the potential of Semantic Web Technologies as a means of integration and development of Big Data applications. In demonstration, a usage case study is presented examining supplier chain operations. Additionally, we review the overall challenges of data integration in this area. © 2016 IEEE.},
  affiliation         = {Ford Motor Company, Dearborn, MI, United States; Dept. of EECS, University of CA Irvine, Irvine, CA 92617, United States},
  art_number          = {7439370},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICSC.2016.101},
  isbn                = {9781509006618},
  journal             = {Proceedings - 2016 IEEE 10th International Conference on Semantic Computing, ICSC 2016},
  keywords            = {Data integration; Semantic Web, Big data applications; Data heterogeneity; Data-sources; Extract transform loads; Semantic Web technology, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964816162&doi=10.1109%2fICSC.2016.101&partnerID=40&md5=f1e0ee0c038179017df75c30bcbbc824},
}

@Article{Huang2016762,
  author              = {Huang, X. and Chen, J. and Tian, S. and Cao, Y. and Yang, H. and Jiang, L.},
  title               = {Big data integration for optimal planning and operation of electric vehicle charging stations},
  journal             = {Dianwang Jishu/Power System Technology},
  year                = {2016},
  volume              = {40},
  number              = {3},
  pages               = {762-767},
  issn                = {10003673},
  note                = {cited By 6},
  abbrev_source_title = {Dianwang Jishu},
  abstract            = {Planning and operation of electric vehicle charging station (EVCS) have problems such as data loss, unqualified data instantaneity. Mass heterogeneous, polymorphism, multi-property, and hard-sharing data are expected to be used reasonably for optimal planning and operation of the stations. Charging station data are typically big data. However, requirements of easy low-cost implementation and integration with other systems conflict each other in nature. This paper focuses on this integration problem. Firstly, big data required by EVCS optimal planning and operation are analyzed, including data origination, characteristics and application challenges. Secondly, four integration patterns suitable for EVCS big data application are presented. Correspondingly, concepts, connotations of the four patterns and involved key technologies are elaborated. Moreover, a general architecture for EVCS big data integration is proposed based on these four patterns. Finally, examples are given for application of the four patterns. © 2016, Power System Technology Press. All right reserved.},
  affiliation         = {College of Electrical and Information Engineering, Hunan University, Changsha, Hunan Province 410000, China; China Electric Power Research Institute, Haidian District, Beijing, 100192, China; Shandong Power Economic Research Institute, State Grid Shandong Electric Power Company, Ji'nan, Shandong Province 250000, China},
  author_keywords     = {Big data; Charging station; Data integration; Operation; Optimal planning},
  coden               = {DIJIE},
  document_type       = {Article},
  doi                 = {10.13335/j.1000-3673.pst.2016.03.015},
  keywords            = {Charging (batteries); Data integration; Electric losses; Electric vehicles; Planning, Big data applications; Charging station; Electric vehicle charging; General architectures; Integration patterns; Integration problems; Operation; Optimal planning, Big data},
  language            = {Chinese},
  publisher           = {Power System Technology Press},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962860517&doi=10.13335%2fj.1000-3673.pst.2016.03.015&partnerID=40&md5=bb2463b882743b7d81d7cdbaa09ba43c},
}

@Conference{Chen2016462,
  author              = {Chen, Y. and Xu, C. and Liu, Q. and Rao, W. and Min, H. and Su, G.},
  title               = {Octopus: Hybrid big data integration engine},
  year                = {2016},
  pages               = {462-466},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 6},
  abbrev_source_title = {Proc. - IEEE Int. Conf. Cloud Comput. Technol. Sci., CloudCom},
  abstract            = {Nowadays large enterprises maintain a huge amount of data in multiple backend systems including traditional database systems and recently popular big data systems. In an example of telecom providers, the key business data (e.g., billing information) is maintained in database systems whereas the huge signaling log data is on HDFS with Hive. How to integrate such data and provide a consolidate query and analytic becomes a challenging task. Neither traditional database warehouse nor recent Big Data system (e.g. Apache Spark and Hadoop) can fully leverage the power of each backend system. In this paper, we build a hybrid data processing engine, called Octopus, to fully integrate backend systems. Given the backend systems, data is distributed at multiple locations. Octopus focuses on the optimization of the amount of data movement. To this end, Octopus proposes a technique of query pushdown for such optimization. A proof-of-concept prototype of Octopus successfully verifies that Octopus can achieve much faster running time than Spark. For example, Octopus outperforms the recent Spark version 1.4.0 by 5.25 X faster running time to process an aggregation query. © 2015 IEEE.},
  affiliation         = {School of Software Engineering, Tongji University, China; IBM Watson Research Lab, New York, NY, United States},
  art_number          = {7396194},
  document_type       = {Conference Paper},
  doi                 = {10.1109/CloudCom.2015.111},
  isbn                = {9781467395601},
  journal             = {Proceedings - IEEE 7th International Conference on Cloud Computing Technology and Science, CloudCom 2015},
  keywords            = {Cloud computing; Data handling; Data integration; Database systems; Engines; Molluscs; Query processing; Shellfish, Aggregation queries; Backend system; Business data; Data movements; Large enterprise; Proof of concept; Running time; Telecom providers, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964329458&doi=10.1109%2fCloudCom.2015.111&partnerID=40&md5=fd2db02eb2fe3de8202072295c6085ee},
}

@Article{Zhou2016449,
  author                  = {Zhou, N. and Sheng, W. and Liu, K.-Y. and Zhang, X. and Wang, S.},
  title                   = {WR approach: Determining accurate attribute values in big data integration},
  journal                 = {Jisuanji Yanjiu yu Fazhan/Computer Research and Development},
  year                    = {2016},
  volume                  = {53},
  number                  = {2},
  pages                   = {449-458},
  issn                    = {10001239},
  note                    = {cited By 1},
  abbrev_source_title     = {Jisuanji Yanjiu yu Fazhan},
  abstract                = {Big data integration lays the foundation for high quality data-driven decision. One critical section thereof is to determine the accurate attribute values from records in data pertaining to a given entity. The state-of-the-art approach R-topK argues to design rules to decide relative accuracy among the attribute values and thus obtain accurate values. Unfortunately, in cases where multiple true values or conflicted rules exist, it requires rounds of human intervention. In this paper, we propose a weighted rule (WR) approach for determining accurate attribute values in big data integration. Each rule is augmented with weight and thus avoid human intervention when conflicts occur. This paper designs a chase procedure-based inference algorithm, and proves that it can figure out weighted constraints over relative accuracy among attribute values in O(n2), which introduces constraints for finding accurate data values. Taking conflicts among constraints into consideration, this paper proposes an O(n) algorithm to discover accurate attribute values among the combination of data values. We conduct extensive experiments under real world and synthetic datasets, and the results demonstrate the effectiveness and efficiency of WR approach. WR approach boosts performance by factor of 3-15x and improves effectiveness by 7%-80%. © 2016, Science Press. All right reserved.},
  affiliation             = {China Electric Power Research Institute, Beijing, 100192, China; Key Laboratory of Data Engineering and Knowledge Engineering (Renmin University of China), Ministry of Education, Beijing, 100872, China; School of Information, Renmin University of China, Beijing, 100872, China},
  author_keywords         = {Big data integration; Data accuracy; Data cleaning; Data quality; Weighted rules},
  coden                   = {JYYFE},
  correspondence_address1 = {Zhang, X.; Key Laboratory of Data Engineering and Knowledge Engineering (Renmin University of China), Ministry of EducationChina; email: zhangxiao@ruc.edu.cn},
  document_type           = {Article},
  doi                     = {10.7544/issn1000-1239.2016.20148275},
  keywords                = {Data integration; Inference engines, Data accuracy; Data cleaning; Data quality; Effectiveness and efficiencies; Inference algorithm; State-of-the-art approach; Weighted constraints; Weighted rules, Big data},
  language                = {Chinese},
  publisher               = {Science Press},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959915705&doi=10.7544%2fissn1000-1239.2016.20148275&partnerID=40&md5=b340405210fa988af77a82db2a3a5e9d},
}

@Article{Dutta2016,
  author                  = {Dutta, R. and Das, A. and Aryal, J.},
  title                   = {Big data integration shows Australian bush-fire frequency is increasing significantly},
  journal                 = {Royal Society Open Science},
  year                    = {2016},
  volume                  = {3},
  number                  = {2},
  issn                    = {20545703},
  note                    = {cited By 19},
  abbrev_source_title     = {R. Soc. Open Sci.},
  abstract                = {Increasing Australian bush-fire frequencies over the last decade has indicated a major climatic change in coming future. Understanding such climatic change for Australian bush-fire is limited and there is an urgent need of scientific research, which is capable enough to contribute to Australian society. Frequency of bush-fire carries information on spatial, temporal and climatic aspects of bush-fire events and provides contextual information to model various climate data for accurately predicting future bush-fire hot spots. In this study, we develop an ensemble method based on a two-layered machine learning model to establish relationship between fire incidence and climatic data. In a 336 week data trial, we demonstrate that the model provides highly accurate bush-fire incidence hotspot estimation (91% global accuracy) from the weekly climatic surfaces. Our analysis also indicates that Australian weekly bush-fire frequencies increased by 40% over the last 5 years, particularly during summer months, implicating a serious climatic shift. © 2016 The Authors.},
  affiliation             = {CSIRO Data61, Hobart, TAS, Australia; School of Medicine, University of Tasmania, Hobart, TAS 7000, Australia; School of Land and Food, University of Tasmania, Hobart, TAS 7001, Australia},
  art_number              = {150241},
  author_keywords         = {Big data; Bush-fire frequency; Climatic shift; Decision science; Ensemble machinelearning},
  correspondence_address1 = {Dutta, R.; CSIRO Data61Australia; email: ritaban.dutta@csiro.au},
  document_type           = {Article},
  doi                     = {10.1098/rsos.150241},
  language                = {English},
  page_count              = {13},
  publisher               = {Royal Society Publishing},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958074352&doi=10.1098%2frsos.150241&partnerID=40&md5=de631d7d2b1ea3235d438cd6bdf10ad9},
}

@Article{Xue2016,
  author                  = {Xue, Y. and Lai, Y.},
  title                   = {Integration of macro energy thinking and big data thinking part one big data and power big data},
  journal                 = {Dianli Xitong Zidonghua/Automation of Electric Power Systems},
  year                    = {2016},
  volume                  = {40},
  number                  = {1},
  pages                   = {1-8},
  issn                    = {10001026},
  note                    = {cited By 60},
  abbrev_source_title     = {Dianli Xitong Zidonghue},
  abstract                = {The macro energy thinking which regards electricity as a hub between energy production and consumption, can promote "clean energy substitution" of the upstream primary energy and "electricity substitution" of the downstream end-use energy, in order to support the sustainable development of energy. Meanwhile the big data thinking regards various data resources as fundamental elements of production rather than simple process objects. The integration of these thinking will make the big data on power become the foundation of an extensively interconnected, openly interactive and highly intelligent macro energy system. Key elements of this integration include the acquirement, transmission and storage of wide-area power data with different timescales, the data from related domains, as well as the fast and in-depth knowledge extraction from the multi-source heterogeneous data and its applications. As the first part of a series of paper, this paper summarizes unique features of big data based on the deduction of the basic concept, data structures and essential characteristics of big data. For the comprehensive energy network, a knowledge extraction platform is constructed by integrating the causal data (based on mathematical models), the statistic data (with non-causal relationship) and the gambling data (of human participants). More case studies will be proposed in the subsequent paper, which will show the contributions of big data thinking to enhance the economy and reliability of macro energy systems. © 2016, Automation of Electric Power Systems Press.},
  affiliation             = {NARI Group Corporation (State Grid Electric Power Research Institute), Nanjing, 211106, China},
  author_keywords         = {Causal data; Cyber energy system; Energy interconnection; Gambling data; Knowledge extraction; Statistic data; Unstructured data},
  coden                   = {DXZIE},
  correspondence_address1 = {Lai, Y.; NARI Group Corporation (State Grid Electric Power Research Institute)China; email: laiyening@sgepri.sgcc.com.cn},
  document_type           = {Article},
  doi                     = {10.7500/AEPS20151208005},
  keywords                = {Data integration; Digital storage; Extraction; Integration, Causal data; Energy interconnection; Energy systems; Gambling data; Knowledge extraction; Statistic data; Unstructured data, Big data},
  language                = {Chinese},
  publisher               = {Automation of Electric Power Systems Press},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956983963&doi=10.7500%2fAEPS20151208005&partnerID=40&md5=ce400d8d0d56788cb9315b5da7c1a8e4},
}

@Conference{Fertier2016151,
  author                  = {Fertier, A. and Truptil, S. and Montarnal, A. and Barthe-Delanoë, A.-M. and Bénaben, F.},
  title                   = {Use of big data for continuous interoperability in crisis management},
  year                    = {2016},
  volume                  = {8},
  pages                   = {151-162},
  publisher               = {Springer International Publishing},
  note                    = {cited By 0},
  abbrev_source_title     = {Proc. I-ESA Conf.},
  abstract                = {Crisis management often involves several stakeholders, who need to be synchronized, despite their heterogeneity or their lack of time, without having any predefined solution for supporting their coordination or data sharing. To help them, crisis cells are set up at the moment the news of crisis is released and actually have only the time to centralize decisions. The purpose of the French ANR (French National Agency for Research) GéNéPi project is to permit interoperability, through supporting coordination and data sharing: inside the decisional level, between hierarchical echelons, and inside the operational level, between the stakeholders. A MIS (Mediation Information System) is provided by this project and encompasses: (i) the information analysis, on the basis of data collected during the preparation phase, (ii) the creation of one collaborative process and (iii) the agility of the solution by comparing two situation models on run-time. Such a system needs to deal with Big Data issues in order to be able to evaluate these models. The paper presents the context of the research and the improvements brought by the MIS. It also expresses the possibility of and the need for automate the data retrieval, thanks to Big Data methods, so that the MIS could evaluate the field situation in real time. © 2016, Springer International Publishing Switzerland.},
  affiliation             = {Centre Génie Industriel, Université de Toulouse—Mines Albi, Campus Jarlard, Albi, 81000, France; Université de Toulouse, INPT-ENSIACET, 4 Allée Emile Monso, Toulouse Cedex 4, 31432, France; LGC (Laboratoire de Génie Chimique), CNRS, Toulouse Cedex 04, 31432, France},
  author_keywords         = {Big data; Collaboration; Crisis management; Interoperability},
  correspondence_address1 = {Fertier, A.; Centre Génie Industriel, Université de Toulouse—Mines Albi, Campus Jarlard, France; email: audrey.fertier@mines-albi.fr},
  document_type           = {Book Chapter},
  doi                     = {10.1007/978-3-319-30957-6_12},
  issn                    = {21992533},
  journal                 = {Proceedings of the I-ESA Conferences},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047225119&doi=10.1007%2f978-3-319-30957-6_12&partnerID=40&md5=4b443dd5a3f985afeec7c340eab9e28a},
}

@Article{Cassavia201634,
  author                  = {Cassavia, N. and Ciampi, M. and De Pietro, G. and Masciari, E.},
  title                   = {Enhancing EHR systems interoperability by big data techniques},
  journal                 = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year                    = {2016},
  volume                  = {9832 LNCS},
  pages                   = {34-48},
  issn                    = {03029743},
  note                    = {cited By 0},
  abbrev_source_title     = {Lect. Notes Comput. Sci.},
  abstract                = {Information management in healthcare is nowadays experiencing a great revolution. After the impressive progress in digitizing medical data by private organizations, also the federal government and other public stakeholders have also started to make use of healthcare data for data analysis purposes in order to extract actionable knowledge. In this paper, we propose an architecture for supporting interoperability in healthcare systems by exploiting Big Data techniques. In particular, we describe a proposal based on big data techniques to implement a nationwide system able to improve EHR data access efficiency and reduce costs. © Springer International Publishing Switzerland 2016.},
  affiliation             = {ICAR-CNR, Rende, Italy},
  author_keywords         = {Big data; Healthcare; Interoperability},
  correspondence_address1 = {Masciari, E.; ICAR-CNRItaly; email: elio.masciari@icar.cnr.it},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-319-43949-5_3},
  editor                  = {Holzinger A., Renda M.E., Khuri S., Bursa M.},
  isbn                    = {9783319439488},
  keywords                = {Health care; Information management; Information science; Interoperability, Data access; EHR systems; Federal governments; Health-care system; Medical data; Private organizations; Reduce costs, Big data},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981501560&doi=10.1007%2f978-3-319-43949-5_3&partnerID=40&md5=f3878a51ce4f2f3bdbc63163e5bbbddd},
}

@Conference{Chatziantoniou2016,
  author              = {Chatziantoniou, D. and Tselai, F.},
  title               = {The data management entity: A simple abstraction to facilitate big data systems interoperability},
  year                = {2016},
  editor              = {Stefanidis K., Palpanas T.},
  volume              = {1558},
  publisher           = {CEUR-WS},
  note                = {cited By 0},
  abbrev_source_title = {CEUR Workshop Proc.},
  abstract            = {Today's big data era is described by intense variety in data management systems, query languages and programming paradigms. Each system targets well a specific application area, reinforcing the belief that the era of one-size fits all has gone. Interoperability, systems' connectivity and high-level data models become once again the core of research initiatives. In this paper we present our vision for a layered architecture to support interoperability among different data management systems, generalized under the term data management entities (DMEs). DMEs range from JVMs running Java programs to Hadoop systems employing complex MapReduce jobs to traditional RDBMS running SQL queries to stream engines and CEP scripts. The top layer consists of a universe of DMEs, communicating through a well defined http-like protocol: a DME transparently invokes another DME's data manipulation task, regardless task's nature. Communicating DMEs share/operate on a shared data object, a key-value set (KVS) - just a set of key-value pairs-which exists in the layer below and is referenced through a unique (internet-wide) address via a well-defined API. This layer serves as the transient common memory space for communicating DMEs and consists of globally addressable KVSs, organized in domains, sub-domains, etc. In a way, this approach constitutes a form of remote procedure call by reference (the KVS is the common reference). We argue that this architecture allows the construction of high level query languages and cost-based distributed query processing engines, involving completely heterogeneous data manipulation tasks. For example, we show that MapReduce evaluation algorithm and distributed relational query processing are just instances of the proposed architecture. We also claim that it can easily facilitate the end-to-end processing in big data applications, an established goal in the research agenda set by the Beckman report. © 2016, Copyright is with the authors.},
  affiliation         = {Department of Management Science and Technology, Athens University of Economics and Business (AUEB), Greece},
  document_type       = {Conference Paper},
  issn                = {16130073},
  journal             = {CEUR Workshop Proceedings},
  keywords            = {Big data; Computational linguistics; Computer architecture; Computer software; Data handling; Distributed computer systems; Engines; High level languages; HTTP; Hypertext systems; Interoperability; Java programming language; Query languages; Query processing; Search engines, Big data applications; Data management system; Distributed query processing; Layered architecture; Programming paradigms; Proposed architectures; Remote Procedure Call; Research initiatives, Information management},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964556205&partnerID=40&md5=9142a769ec93fee629a0ec6ceb48766a},
}

@Conference{Wulff20162316,
  author              = {Wulff, A. and Wunck, C.},
  title               = {Integration of business process management and Big Data technologies},
  year                = {2016},
  volume              = {8-10 March 2016},
  pages               = {2316},
  publisher           = {IEOM Society},
  note                = {cited By 0},
  abbrev_source_title = {Proc. Int. Conf. Ind. Eng. Oper. Manage.},
  abstract            = {In largely autonomous process control ever-increasing amounts of data are generated and made available for specific analysis functions. This is especially important in the field of sensor-based process control and for predictive analysis of machine data, server logs and text messages. A key challenge is to provide appropriate data processing solutions for effective and efficient integration of data and process management and appropriate analysis tools. Despite considerable advances in Big Data and IOT technology useful solutions are hardly available. A study conducted since 2013 examines the integration capabilities of process management platforms and the most noted Big Data reference platform Hadoop. As a result of this research an easy-to-use Integration library has been developed and released. The library comprises software adapters that allow the seamless integration of Hadoop tools into existing or even new business processes. The work has been validated with the implementation of use cases for the application areas "Predictive maintenance through analysis of operational machine data" and "Failure prediction with analysis of log data in a cellular network". Further research aims at outlining future applications resulting from the expected symbiosis of these technologies. © IEOM Society International. © IEOM Society International.},
  affiliation         = {Department of Management, Information, Technology, Jade University of Applied Sciences, Wilhelmshaven, 26389, Germany},
  author_keywords     = {Big data; BPMN; Business process management; Hadoop; Predictive maintenance},
  document_type       = {Conference Paper},
  isbn                = {9780985549749},
  issn                = {21698767},
  journal             = {Proceedings of the International Conference on Industrial Engineering and Operations Management},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018372802&partnerID=40&md5=4959b84ea0b46d302f5310fd2c73c14a},
}

@Article{GholamzadehNabati2016457,
  author                  = {Gholamzadeh Nabati, E. and Thoben, K.-D.},
  title                   = {On applicability of big data analytics in the closed-loop product lifecycle: Integration of CRISP-DM standard},
  journal                 = {IFIP Advances in Information and Communication Technology},
  year                    = {2016},
  volume                  = {492},
  pages                   = {457-467},
  issn                    = {18684238},
  note                    = {cited By 0},
  abbrev_source_title     = {IFIP Advances in Information and Communication Technology},
  abstract                = {The product use data can have an important role in closed-loop product lifecycle management (CL-PLM), where information feedbacks from the use data can contribute to improve the product design and performance. The product usage data can nowadays be collected easier than before, with the aid of sensors and technologies embedded in products. However, the collected data can have complex characteristics. They come from various sources, have different formats and high volume. In order to improve the product lifecycle processes with these data, discussing the use of data analysis in the product lifecycle is necessary. Analyzing the data with such characteristics has been also considered in the context of big data analytics. In this paper an approach for standardization of the process of usage data analysis based on a standard called Cross Industry Standard Process for Data Mining (CRISP-DM), is introduced and its potential integration in CL-PLM is investigated. The reference steps of analyzing usage data are identified. They cover the processes between data generation until feeding back the knowledge of use to the product design phase. © IFIP International Federation for Information Processing 2016.},
  affiliation             = {International Graduate School for Dynamics in Logistics, University of Bremen, Bremen, Germany; BIBA - Bremer Institute für Produktion und Logistik GmbH, Bremen, Germany},
  author_keywords         = {Big data; Closed-loop product lifecycle; CRISP-DM; Product use data; Standardization},
  correspondence_address1 = {Gholamzadeh Nabati, E.; International Graduate School for Dynamics in Logistics, University of BremenGermany; email: nab@biba.uni-bremen.de},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-319-54660-5_41},
  editor                  = {Eynard B., Bouras A., Bernard A., Rivest L., Harik R.},
  isbn                    = {9783319546599},
  keywords                = {Big data; Data handling; Data integration; Data mining; Information analysis; Product design; Standardization, Closed-loop product lifecycle; Complex characteristics; CRISP-DM; Data generation; Information feedback; Product use data; Product-life-cycle; Usage data analysis, Life cycle},
  language                = {English},
  publisher               = {Springer New York LLC},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015875736&doi=10.1007%2f978-3-319-54660-5_41&partnerID=40&md5=9e8fd5c0b1868721a99b6ccbc1de591e},
}

@Conference{Eftekhari20162746,
  author              = {Eftekhari, A. and Zulkernine, F. and Martin, P.},
  title               = {BINARY: A framework for big data integration for ad-hoc querying},
  year                = {2016},
  editor              = {Ak R., Karypis G., Xia Y., Hu X.T., Yu P.S., Joshi J., Ungar L., Liu L., Sato A.-H., Suzumura T., Rachuri S., Govindaraju R., Xu W.},
  pages               = {2746-2753},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Proc. - IEEE Int. Conf. Big Data, Big Data},
  abstract            = {Enormous amounts of data are generated everyday of both structured and unstructured nature. Regardless of their differences, data sources must be used in tandem in any effective big data operation. This paper proposes a Software as a Service (SaaS) framework called BINARY which provides a back-end infrastructure for ad-hoc querying, accessing, visualizing and joining data from different data sources such as Relational Database Management Systems like MySQL and big data storage systems like Apache Hive. BINARY is extendable and allows adding other storage engines (e.g. HBase) and analytics engines (e.g. R) as needed. A REST software architecture is used in the framework to enable loose connections between the engines and user interface programs to facilitate their independent updates without affecting the data infrastructure. Our approach is validated with a proof-of-concept prototype implemented on the OpenStack cloud system. © 2016 IEEE.},
  affiliation         = {School of Computing, Queen's University, Kingston, ON, Canada},
  art_number          = {7840922},
  author_keywords     = {ad-hoc querying; big data integration; cloud computing},
  document_type       = {Conference Paper},
  doi                 = {10.1109/BigData.2016.7840922},
  isbn                = {9781467390040},
  journal             = {Proceedings - 2016 IEEE International Conference on Big Data, Big Data 2016},
  keywords            = {Bins; Cloud computing; Data integration; Data storage equipment; Digital storage; Engines; Information management; Query processing; Relational database systems; Software as a service (SaaS); User interfaces; Virtual storage, Ad-hoc querying; Data infrastructure; Data operations; Data storage systems; Interface program; Proof of concept; Relational database management systems; Storage engines, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015225194&doi=10.1109%2fBigData.2016.7840922&partnerID=40&md5=dc0bddda4bbe674eb2fb86c90465c8d5},
}

@Conference{Ahmed2016532,
  author              = {Ahmed, F. and Samorani, M. and Bellinger, C. and Zaiane, O.R.},
  title               = {Advantage of integration in big data: Feature generation in multi-relational databases for imbalanced learning},
  year                = {2016},
  editor              = {Ak R., Karypis G., Xia Y., Hu X.T., Yu P.S., Joshi J., Ungar L., Liu L., Sato A.-H., Suzumura T., Rachuri S., Govindaraju R., Xu W.},
  pages               = {532-539},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 4},
  abbrev_source_title = {Proc. - IEEE Int. Conf. Big Data, Big Data},
  abstract            = {Most real world applications comprise databases having multiple tables. It becomes further complicated in the realm of Big Data where related information is spread over different data repositories. However, data mining techniques are usually applied on a single flat table. This work focuses on generating a mining table by aggregating information from multiple local tables and external data sources and automatically generating potentially discriminant features. It extends data aggregation techniques by navigating paths where a single table is traversed multiple times. Such paths are not considered by existing techniques, which results in the loss of several attributes. Our framework also prevents leakage of the class information by avoiding features built after the knowledge of the class label. Experiments are performed on transactional data of a U.S. consumer electronics retailer to predict causes of product returns. In addition, we augmented the dataset with Suppliers information and Reviews to show the value of data integration. The results show that our technique improves classification accuracy and generates discriminant features that mitigate the impact of class imbalance. © 2016 IEEE.},
  affiliation         = {Department of Computing Science, University of Alberta, Canada; Leavey School of Business, Santa Clara University, United States},
  art_number          = {7840644},
  author_keywords     = {Class imbalance; Classification; Data integration; Feature construction},
  document_type       = {Conference Paper},
  doi                 = {10.1109/BigData.2016.7840644},
  isbn                = {9781467390040},
  journal             = {Proceedings - 2016 IEEE International Conference on Big Data, Big Data 2016},
  keywords            = {Classification (of information); Data integration; Data mining, Class imbalance; Classification accuracy; External data sources; Feature construction; Feature generation; Imbalanced Learning; Relational Database; Transactional data, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015193815&doi=10.1109%2fBigData.2016.7840644&partnerID=40&md5=1709c2e1d68d5d4f0f252b15995f8ddb},
}

@Conference{Tian2016,
  author              = {Tian, X. and Liu, L. and Mirkovski, K. and Li, M.},
  title               = {Development of conceptual model for social commerce research through integration with big data analysis},
  year                = {2016},
  publisher           = {Pacific Asia Conference on Information Systems},
  note                = {cited By 1},
  abbrev_source_title = {Pac. Asia Conf. Inf. Syst., PACIS - Proc.},
  abstract            = {Information systems designers face great opportunities and challenges in developing a holistic big data research approach for the new analytics savvy generation. In addition business intelligence is largely utilized in the business community and thus can leverage the opportunities from the abundant data and domain-specific analytics in many critical areas. The aim of this paper is to assess the relevance of these trends in the current business context through evidence-based documentation of current and emerging applications as well as their wider business implications. In this paper, we use BigML to examine how the two social information channels (i.e., friends-based opinion leaders-based social information) influence consumer purchase decisions on social commerce sites. We undertake an empirical study in which we integrate a framework and a theoretical model for big data analysis. We conduct an empirical study to demonstrate that big data analytics can be successfully combined with a theoretical model to produce more robust and effective consumer purchase decisions. The results offer important and interesting insights into IS research and practice.},
  affiliation         = {Department of Business Technology and Entrepreneurship, Faculty of Business and Law, Swinburne University of TechnologyVIC 3122, Australia; School of Information Management, Victoria Business School, Victoria University of Wellington, Wellington, 6140, New Zealand; School of Computing and Information Technology, Faculty of Engineering and Information Sciences, University of WollongongNSW 2522, Australia},
  author_keywords     = {Big data analysis; Business intelligence; Social commerce},
  document_type       = {Conference Paper},
  isbn                = {9789860491029},
  journal             = {Pacific Asia Conference on Information Systems, PACIS 2016 - Proceedings},
  keywords            = {Commerce; Competitive intelligence; Data handling; Information analysis; Information systems; Purchasing; Social aspects, Business community; Business contexts; Emerging applications; Empirical studies; Research approach; Social commerces; Social information; Theoretical modeling, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011112377&partnerID=40&md5=cf9fe967f6ac825f8d4c06e4fef4dbec},
}

@Article{Harwood2016613,
  author                  = {Harwood, A. and Mayer, A.},
  title                   = {Big data and semantic technology: A future for data integration, exploration and visualisation},
  journal                 = {Statistical Journal of the IAOS},
  year                    = {2016},
  volume                  = {32},
  number                  = {4},
  pages                   = {613-626},
  issn                    = {18747655},
  note                    = {cited By 1},
  abbrev_source_title     = {Stat. J. IAOS},
  abstract                = {In a world of ever increasing data availability and user expectations, National Statistical Offices face mounting challenges to produce relevant and timely statistics. They need to transform their business practice to take advantage of big data - especially administrative data - by integrating non-traditional and survey data sources to maximise value, and utilising new technology to enable enhanced analysis. An example of a response to these challenges is the prototype GLIDE (Graphically Linked Information Discovery Environment) the Australian Bureau of Statistics (ABS) is currently developing using semantic web technology. This environment includes as a test case a prototype semantic linked employer-employee database (LEED) which integrates administrative tax data and ABS business register data to enable detailed microeconomic analysis. However, as data structures become more complex and multi-dimensional, data integration and exploration encounters challenges within traditional relational databases, prompting the exploration of alternatives. Semantic web technology allows for a flexible data structure, machine reasoning and inference on the dataset, a shared understanding of the data's meaning, reusable classifications and standards, easy exploration of many dimensions, and network analysis. The possible advantages of such an approach for official statistics are demonstrated through two practical examples, showing how the prototype GLIDE supports effective data exploration and visualisation, and enables network analysis, to solve real business problems.},
  affiliation             = {Australian Bureau of Statistics, Canberra, Australia},
  author_keywords         = {data analytics; data visualisation; linked data; official statistics; Semantic web},
  correspondence_address1 = {Mayer, A.; ABS House, 45 Benjamin Way, Australia; email: andreas.mayer@abs.gov.au},
  document_type           = {Conference Paper},
  doi                     = {10.3233/SJI-160989},
  language                = {English},
  publisher               = {IOS Press},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84998610688&doi=10.3233%2fSJI-160989&partnerID=40&md5=b64a0fe9ba0db7a2410c01b4bad0912e},
}

@Article{Talamo2016217,
  author              = {Talamo, C. and Atta, N. and Martani, C. and Paganin, G.},
  title               = {The integration of physical and digital urban infrastructures: The role of "big data" [L'integrazione delle infrastrutture urbane fisiche e digitali: Il ruolo dei "big Data"]},
  journal             = {TECHNE},
  year                = {2016},
  volume              = {11},
  pages               = {217-225},
  issn                = {22390243},
  note                = {cited By 3},
  abbrev_source_title = {Techne},
  abstract            = {The several innovations in the field of information management, the establishment of the big data and IoT (Internet of Things) concepts and the wide development and dissemination of sensing technologies are opening up innovative scenarios and outlining new research topics in the area of knowledge gathering and decision making, with specific forms when applied on either infrastructures or buildings, or urban properties. On this bases, the aim of the paper is to outline the state of the art of technological innovations and propose some hypotheses about potential future scenarios for the support services to the management and development of real estate and urban areas. The development of such services is envisioned through the integration of the physical and digital urban infrastructures. The analysis of the role of information in the interaction between tangible and intangible infrastructures poses a number of interpretational issues that the paper outlines. © 2016 Firenze University Press.},
  affiliation         = {Dipartimento ABC, Politecnico di Milano, Italy; ETH Zürich, Institut für Bau- und Infrastrukturmanagement (IBI), Infrastructure Management Group (IM), Svizzera, Switzerland; Lavoro Sviluppato Al Politecnico di Milano, Italy; Dipartimento di Architettura e Studi Urbani, Politecnico di Milano, Italy},
  author_keywords     = {Big data; Digital infrastructures; Internet of things; Urban maintenance},
  document_type       = {Article},
  doi                 = {10.13128/Techne-18424},
  language            = {English; Italian},
  publisher           = {Firenze University Press},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994504646&doi=10.13128%2fTechne-18424&partnerID=40&md5=7b4444713e8aedbde0acf3f145acf7a1},
}

@Conference{Nkenyereye2016554,
  author                  = {Nkenyereye, L. and Jang, J.-W.},
  title                   = {Integration of Big Data for Connected Cars Applications Based on Tethered Connectivity},
  year                    = {2016},
  editor                  = {Shakshuki E.},
  volume                  = {58},
  pages                   = {554-559},
  publisher               = {Elsevier B.V.},
  note                    = {cited By 1},
  abbrev_source_title     = {Procedia Comput. Sci.},
  abstract                = {The wireless communication technologies built-in or brought in the vehicle enable new in-car telematics services. The development of connected cars emphasizes the use of sophisticated computation framework for gathering, analyzing a large volume of data generated in all aspects of vehicle operations using Big Data technologies. Since these data are essential for many connected cars applications, the design and monitoring of MapReduce algorithms for processing vehicle's data using Hadoop framework will allow to build a hosting of analytics data source. This hosting data source allows different connected cars industry ecosystem to access useful data they need to afford connected cars applications. This paper studies design steps to take in consideration when implementing MapReduce patterns to analyze vehicle's data in order to produce accurate useful data that are hosted at the automakers and connect cars services providers. Experiment results show that MapReduce join algorithm is highly scalable and optimized for distributed computing than Statistical Analysis System (SAS) framework and HiveQL declarative language.},
  affiliation             = {Dong-Eui University, 176 Eomgwangro, Busanjin-Gu, Busan, 614-714, South Korea},
  author_keywords         = {Big data; Connected Car; Hadoop; Join algorithm; MapReduce framework; remote on-line vehicle diagnostics system},
  correspondence_address1 = {Jang, J.-W.; Dong-Eui University, 176 Eomgwangro, South Korea; email: jwjang@deu.ac.kr},
  document_type           = {Conference Paper},
  doi                     = {10.1016/j.procs.2016.09.083},
  issn                    = {18770509},
  journal                 = {Procedia Computer Science},
  keywords                = {Data handling; Distributed computer systems; Health care; Information services; Vehicles; Wireless telecommunication systems, Declarative Languages; Hadoop; Join algorithm; Mapreduce frameworks; Statistical analysis systems; Telematics services; Vehicle diagnostic; Wireless communication technology, Big data},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992315684&doi=10.1016%2fj.procs.2016.09.083&partnerID=40&md5=4fd8ef069e0ec076409b704c8acb4053},
}

@Article{Bondiombouy201648,
  author                  = {Bondiombouy, C. and Kolev, B. and Levchenko, O. and Valduriez, P.},
  title                   = {Multistore big data integration with CloudMdsQL},
  journal                 = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year                    = {2016},
  volume                  = {9940 LNCS},
  pages                   = {48-74},
  issn                    = {03029743},
  note                    = {cited By 2},
  abbrev_source_title     = {Lect. Notes Comput. Sci.},
  abstract                = {Multistore systems have been recently proposed to provide integrated access to multiple, heterogeneous data stores through a single query engine. In particular, much attention is being paid on the integration of unstructured big data typically stored in HDFS with relational data. One main solution is to use a relational query engine that allows SQL-like queries to retrieve data from HDFS, which requires the system to provide a relational view of the unstructured data and hence is not always feasible. In this paper, we propose a functional SQL-like query language (based on CloudMdsQL) that can integrate data retrieved from different data stores, to take full advantage of the functionality of the underlying data processing frameworks by allowing the ad-hoc usage of user defined map/filter/reduce operators in combination with traditional SQL statements. Furthermore, our solution allows for optimization by enabling subquery rewriting so that bind join can be used and filter conditions can be pushed down and applied by the data processing framework as early as possible. We validate our approach through implementation and experimental validation with three data stores and representative queries. The experimental results demonstrate the usability of the query language and the benefits from query optimization. © Springer-Verlag Berlin Heidelberg 2016.},
  affiliation             = {Inria, LIRMM, University of Montpellier, Montpellier, France},
  correspondence_address1 = {Kolev, B.; Inria, LIRMM, University of MontpellierFrance; email: boyan.kolev@inria.fr},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-662-53455-7_3},
  editor                  = {Hameurlain A., Chen Q., Kung J., Wagner R.},
  isbn                    = {9783662534540},
  keywords                = {Big data; Data handling; Data integration; Engines; Expert systems; Query languages; Query processing, Experimental validations; Heterogeneous data; Integrated access; Query optimization; Relational data; Relational queries; Relational views; Unstructured data, Search engines},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989864634&doi=10.1007%2f978-3-662-53455-7_3&partnerID=40&md5=9d08dc4bce2215a96f15ce9c4090919c},
}

@Conference{Abbes2016446,
  author                  = {Abbes, H. and Gargouri, F.},
  title                   = {Big Data Integration: A MongoDB Database and Modular Ontologies based Approach},
  year                    = {2016},
  editor                  = {Howlett R.J., Gabrys B., Jain L.C., Toro C., Lim C.P.},
  volume                  = {96},
  pages                   = {446-455},
  publisher               = {Elsevier B.V.},
  note                    = {cited By 10},
  abbrev_source_title     = {Procedia Comput. Sci.},
  abstract                = {Big Data are collections of data sets so large and complex to process using classical database management tools. Their main characteristics are volume, variety and velocity. Big Data integration is a new research area that faces new challenges due to these characteristics. Ontologies represent knowledge as a formal description of a domain of interest. They are widely used in data integration. This paper illustrates an approach for ontology based Big Data integration taking into account their characteristics. Our approach is based on a NOSQL database namely MongoDB and modular ontologies. It follows three steps: wrapping data sources to MongoDB databases, generating local ontologies, composing the local ontologies to get a global one. A tool implementing the generation of the local ontologies is also detailed. © 2016 The Authors. Published by Elsevier B.V.},
  affiliation             = {MIRACL Laboratory, Higher Institute of Computer Science and Multimedia, BP 1030, S Sfax, Tunisia},
  author_keywords         = {Big Data; Modular ontologies; MongoDB; NOSQL; Ontology learning},
  correspondence_address1 = {Abbes, H.; MIRACL Laboratory, Higher Institute of Computer Science and Multimedia, BP 1030, Tunisia; email: abbes.hanen@gmail.com},
  document_type           = {Conference Paper},
  doi                     = {10.1016/j.procs.2016.08.099},
  issn                    = {18770509},
  journal                 = {Procedia Computer Science},
  keywords                = {Data acquisition; Data integration; Database systems; Knowledge based systems, Database management; Formal Description; Modular ontologies; MongoDB; NOSQL; Nosql database; Ontology learning; Ontology-based, Big data},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988864509&doi=10.1016%2fj.procs.2016.08.099&partnerID=40&md5=8a72a07a1106401d5194851a61b730f3},
}

@Article{Fernández2016150,
  author                  = {Fernández, A.M. and Torres, J.F. and Troncoso, A. and Martínez-Álvarez, F.},
  title                   = {Automated spark clusters deployment for big data with standalone applications integration},
  journal                 = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year                    = {2016},
  volume                  = {9868 LNAI},
  pages                   = {150-159},
  issn                    = {03029743},
  note                    = {cited By 2},
  abbrev_source_title     = {Lect. Notes Comput. Sci.},
  abstract                = {The huge amount of data stored nowadays has turned big data analytics into a very trendy research field. Spark has emerged as a very powerful and widely used paradigm for clusters deployment and big data management. However, to get started is still a very tough task, due to the excessive requisites that all nodes must fulfil. Thus, this work introduces a web service specifically designed for an easy and efficient Spark cluster management. In particular, a service with a friendly graphical user interface has been developed to automate the deploying of clusters. Another relevant feature is the possibility of integrating any algorithm into the web service. That is, the user only needs to provide the executable file and the number of required inputs for a proper parametrization. Finally, an illustrative case study is included to show ad hoc algorithms usage (the MLlib implementation for k-means, in this case) across the nodes of the configured cluster. © Springer International Publishing Switzerland 2016.},
  affiliation             = {Division of Computer Science, Universidad Pablo de Olavide, Seville, 41013, Spain},
  author_keywords         = {Algorithms; Automated deployment; Big data; Spark},
  correspondence_address1 = {Martínez-Álvarez, F.; Division of Computer Science, Universidad Pablo de OlavideSpain; email: fmaralv@upo.es},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-319-44636-3_14},
  editor                  = {Barrenechea E., Troncoso A., Gamez J.A., Luaces O., Quintian H., Corchado E., Galar M.},
  isbn                    = {9783319446356},
  keywords                = {Algorithms; Artificial intelligence; Clustering algorithms; Electric sparks; Graphical user interfaces; Information management; User interfaces; Web services; Websites, Automated deployment; Cluster management; Data analytics; Executable files; Parametrizations; Relevant features; Research fields; Standalone applications, Big data},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988643058&doi=10.1007%2f978-3-319-44636-3_14&partnerID=40&md5=c7ac89dded355c6b1760731dc3b97934},
}

@Conference{Su201619,
  author                  = {Su, J.-M. and Erdenebat, N. and Ho, L.-H. and Zhan, Y.-T.},
  title                   = {Integration of Transit Demand and Big Data for Bus Route Design in Taiwan},
  year                    = {2016},
  editor                  = {Tseng P.-Y., Chen C.-H., Lo S.-C., Shon J.Z.},
  pages                   = {19-26},
  publisher               = {American Society of Civil Engineers (ASCE)},
  note                    = {cited By 2},
  abbrev_source_title     = {Bridg. East West: Theor. Pract. Transp. Asia Pac. - Sel. Pap. Proc. Asia Pac. Transp. Dev. Conf. ICTPA Annu. Conf.},
  abstract                = {Local governments in Taiwan and the Ministry of Transportation and Communication actively plan new bus routes to fill the gap of transit services with the aim to increase the public transportation's market sharing rate. The Institute of Transportation have used transit big data to develop the "Transit Service Assessment System (TSAS)" which is used to assist government's evaluation on the performance of transit routes. The objective of this paper is applying TSAS, big data and transit demands data to develop a methodology for planning and designing a cost and service efficient transit network. In this paper, a new bus route generating model is proposed by integrating an existing bus network with real demand data from Hsinchu County. The result of this paper shows that the proposed methodology can increase 12.38% of the service rate and decrease 7.52% costs. © ASCE.},
  affiliation             = {Department of Transportation Technology and Logistic Management, Chung Hua University, 707,Sec.2,WuFu Rd, Hsinchu, 30012, Taiwan; Department of Transportation Technology and Logistic Management, Chung Hua University, China},
  correspondence_address1 = {null},
  document_type           = {Conference Paper},
  doi                     = {10.1061/9780784479810.003},
  isbn                    = {9780784479810},
  journal                 = {Bridging the East and West: Theories and Practices of Transportation in the Asia Pacific - Selected Papers from the Proceedings of the 11th Asia Pacific Transportation Development Conference and the 29th ICTPA Annual Conference},
  keywords                = {Bus transportation; Buses; Data integration; Mass transportation; Transportation; Transportation routes, Assessment system; Generating models; Local government; Planning and designings; Public transportation; Real demand data; Transit networks; Transit services, Big data},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976400551&doi=10.1061%2f9780784479810.003&partnerID=40&md5=77e9b814d66b97d225ee61faee4e034f},
}

@Article{Kedharewsari2016768,
  author                  = {Kedharewsari, K. and Maria Anu, V. and Rajalakshmi, V.},
  title                   = {Integration of big data \& cloud computing to detect black money rotation with range - aggregate queries},
  journal                 = {International Journal of Engineering and Technology},
  year                    = {2016},
  volume                  = {8},
  number                  = {2},
  pages                   = {768-773},
  issn                    = {23198613},
  note                    = {cited By 0},
  abbrev_source_title     = {Intern. J. Eng. Technol.},
  abstract                = {The big data is difficult to be analyzed due to the presence and characteristics of huge amount of data. Hadoop technology plays a key role in analyzing the large scale data. The aggregate queries are executed on more columns concurrently and it is difficult for huge amount of data. This paper is proposing the method in which the fast RAQ is dividing the big data in to autonomous partitions by means of a balanced partition algorithm and later for each partition a local assessment sketch is generated. By the arrival of the range-aggregate query demand the fast RAQ gets the result in a direct manner by shortening local estimate from all partition and then the cooperative results are provided. Thus in fast RAQ technique three tier Architecture is insisted and they are of 1.Extracting the helpful information's from Unstructured Data, 2.Implementation of the big data in Multi system Approach, 3.Application Deployment - Insurance/Banking. This paper is implement for the banking domain process and two major departments are involved in this process and they are 1.To maintain the accounts and for adding new clients the Bank Server is used. To create account in any bank the user have to give their ID proof at the time of registration.2.Account Monitoring Server is used for monitoring every users accounts in various banks and this server is used for retrieving the users who are maintaining and transacting more than Rs 50,000 per annum in various bank accounts by using the similar ID proof is identified by Map Reduce technique. The Online Aggregation is a smart sampling-based method that is performed to provide response to aggregation query by an approximation to the last outcome, with the self-assurance interval which is becoming tighter eventually. It is built into a Map-Reduce-based cloud scheme for analytics of the big data that allows the user to save the money by means of killing the calculation early and to observe the query progress when the enough accuracy is achieved.},
  affiliation             = {Department of Information Technology, Sathyabama University, Chennai, Tamil Nadu, India; Department of Computer Science, Sathyabama University, India},
  author_keywords         = {Fast RAQ; Map reduce; Partition algorithm; Range-aggregate query; Tracking black money},
  correspondence_address1 = {Maria Anu, V.; Department of Information Technology, Sathyabama UniversityIndia; email: Mariaanu18@gmail.com},
  document_type           = {Article},
  language                = {English},
  publisher               = {Engg Journals Publications},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971577307&partnerID=40&md5=68060c95a11c5606ef249a6932eb580d},
}

@Conference{Williams20151103,
  author              = {Williams, J.W. and Cuddihy, P. and McHugh, J. and Aggour, K.S. and Menon, A. and Gustafson, S.M. and Healy, T.},
  title               = {Semantics for Big Data access \& integration: Improving industrial equipment design through increased data usability},
  year                = {2015},
  editor              = {Luo F., Ogan K., Zaki M.J., Haas L., Ooi B.C., Kumar V., Rachuri S., Pyne S., Ho H., Hu X., Yu S., Hsiao M.H.-I., Li J.},
  pages               = {1103-1112},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 4},
  abbrev_source_title = {Proc. - IEEE Int. Conf. Big Data, IEEE Big Data},
  abstract            = {With the advent of Big Data technologies, organizations can efficiently store and analyze more data than ever before. However, extracting maximal value from this data can be challenging for many reasons. For example, datasets are often not stored using human-understandable terms, making it difficult for a large set of users to benefit from them. Further, given that different types of data may be best stored using different technologies, datasets that are closely related may be stored separately with no explicit linkage. Finally, even within individual data stores, there are often inconsistencies in data representations, whether introduced over time or due to different data producers. These challenges are further compounded by frequent additions to the data, including new raw data as well as results produced by large-scale analytics. Thus, even within a single Big Data environment, it is often the case that multiple rich datasets exist without the means to access them in a unified and cohesive way, often leading to lost value. This paper describes the development of a Big Data management infrastructure with semantic technologies at its core to provide a unified data access layer and a consistent approach to analytic execution. Semantic technologies were used to create domain models describing mutually relevant datasets and the relationships between them, with a graphical user interface to transparently query across datasets using domain-model terms. This prototype system was built for GE Power & Water's Power Generation Products Engineering Division, which has produced over 50TB of gas turbine and component prototype test data to date. The system is expected to result in significant savings in productivity and expenditure. © 2015 IEEE.},
  affiliation         = {Knowledge Discovery Lab, GE Global Research, Niskayuna, NY 12309, United States; Combustion Control and Methods, GE Power and Water, Greenville, SC 29615, United States},
  art_number          = {7363864},
  author_keywords     = {big data; data management; domain model; engineering; ontology; semantics; time series data},
  document_type       = {Conference Paper},
  doi                 = {10.1109/BigData.2015.7363864},
  isbn                = {9781479999255},
  journal             = {Proceedings - 2015 IEEE International Conference on Big Data, IEEE Big Data 2015},
  keywords            = {Engineering; Gas turbines; Graphical user interfaces; Information management; Ontology; Query languages; Semantic Web; Semantics; User interfaces, Data representations; Domain model; Industrial equipment design; Large-scale analytics; Management infrastructure; Power generation products; Semantic technologies; Time-series data, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963754870&doi=10.1109%2fBigData.2015.7363864&partnerID=40&md5=1e23c84c2d62911092fe86c094aca87c},
}

@Conference{Ahmed2015339,
  author              = {Ahmed, W. and Fan, L.},
  title               = {Big Data tool integration in physical design process find hidden patterns, predictive analysis and classifying Big Data},
  year                = {2015},
  editor              = {Chen P., Zadeh L.A., Ge N., Wang Y., Tao X., Lu J., Howard N., Zhang B.},
  pages               = {339-345},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Proc. IEEE Int. Conf. Cogn. Informatics Cogn. Comput., ICCI*CC},
  abstract            = {Physical Design (PD) Big Data tool is designed primarily to assist chip design engineers in achieving design optimization. It uses data mining techniques to handle the existing unstructured data repository. The tool extracts the relevant data and loads it into a well-structured database. It also has an archive mechanism that initially creates and then keeps updating an archive repository on a daily basis. The original input to the PD tool is a completely unstructured datasource which are read by the tool using regular expression based data extraction methodology. By doing this, PD tool converts the input data into the structured tables. This undergoes the data cleansing process before being fed into the operational DB. By maintaining an archive repository of this, PD tool also ensures data integrity and data validity. PD tool helps the design engineers to compare, correlate and inter-relate the results of their existing work with the ones done in the past which gives them a clear picture of the progress made and deviations that occurred. Data analysis can be done using various features offered by the tool such as graphical and statistical representation. © 2015 IEEE.},
  affiliation         = {Department of Computer Science, University of Regina, Regina, Canada},
  art_number          = {7259408},
  author_keywords     = {ASIC design process; big data; correlation; escalate precision; hidden pattern; predictive analysis},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICCI-CC.2015.7259408},
  isbn                = {9781467372893},
  journal             = {Proceedings of 2015 IEEE 14th International Conference on Cognitive Informatics and Cognitive Computing, ICCI*CC 2015},
  keywords            = {Correlation methods; Data mining; Design; Information science; Integrated circuits, ASIC design; Design optimization; escalate precision; Hidden patterns; Predictive analysis; Regular expressions; Statistical representations; Structured database, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960863761&doi=10.1109%2fICCI-CC.2015.7259408&partnerID=40&md5=c1931e075d13309fd12104033d0f476a},
}

@Conference{Alodib201541,
  author              = {Alodib, M. and Malik, Z.},
  title               = {A Big Data approach to enhance the integration of Access Control Policies for Web services},
  year                = {2015},
  editor              = {Ito T., Kim Y., Fukuta N.},
  pages               = {41-46},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 5},
  abbrev_source_title = {IEEE/ACIS Int. Conf. Comput. Inf. Sci., ICIS - Proc.},
  abstract            = {Service-oriented Architecture (SoA) is a layered architecture used to organize software resources as services that can be deployed, discovered and combined to produce new services. The interactions between services can be affected in situations where a destination service becomes unavailable. Herein, the Protocol service is introduced as a solution to coordinate interactions between services. The method is then extended to consider the automatic assignment of access control policies by the generation of a new service, called the Access Control Policies (AC-Policies) service, which is linked to the Protocol service. In this context, the Protocol service manages a large amount of data. The analysis of such data sets may help improving the Protocol service performance. Dealing with such a large data sets is referred recently as 'Big Data', is a term related to large set of data that is complicated to be analyzed using traditional applications. One of the most successful implementations of Big Data is the Hadoop Framework. This paper proposes an extension to automate the integration of the Hadoop platform. This aims to breaks individual problems down into multiple subtasks, using a simple programming model (MapReduce). After the analysis is computed, the result is submitted to a Score table linked with the Protocol service. The approach harnesses the capability of Model-Driven Architecture (MDA) to automate the creation, and integration of the architecture. As a proof of concept, the approach is then implemented as a tool. © 2015 IEEE.},
  affiliation         = {Qassim University, Qassim, Buraidah, 51411, Saudi Arabia; Department of Computer Science, Wayne State University, Detroit, MI, United States},
  art_number          = {7166567},
  author_keywords     = {Access Control Policies; Big Data; Cloud Computing; Model Driven Architecture; Web services},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICIS.2015.7166567},
  isbn                = {9781479986798},
  journal             = {2015 IEEE/ACIS 14th International Conference on Computer and Information Science, ICIS 2015 - Proceedings},
  keywords            = {Access control; Cloud computing; Information science; Information services; Integration; Service oriented architecture (SOA); Software architecture; Software design; Web services; Websites, Access control policies; Automatic assignment; Hadoop frameworks; Layered architecture; Model driven architectures; Programming models; Service performance; Software resources, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945302897&doi=10.1109%2fICIS.2015.7166567&partnerID=40&md5=fceaac94482de31cfd54754aaf272ebd},
}

@Book{Talburt20151,
  title                   = {Entity Information Life Cycle for Big Data: Master Data Management and Information Integration},
  publisher               = {Elsevier Inc.},
  year                    = {2015},
  author                  = {Talburt, J.R. and Zhou, Y.},
  isbn                    = {9780128006658; 9780128005378},
  note                    = {cited By 7},
  abbrev_source_title     = {Entity Inf. Life Cycle for Big Data: Master Data Manag. and Inf. Integr.},
  abstract                = {Entity Information Life Cycle for Big Data walks you through the ins and outs of managing entity information so you can successfully achieve master data management (MDM) in the era of big data. This book explains big data's impact on MDM and the critical role of entity information management system (EIMS) in successful MDM. Expert authors Dr. John R. Talburt and Dr. Yinle Zhou provide a thorough background in the principles of managing the entity information life cycle and provide practical tips and techniques for implementing an EIMS, strategies for exploiting distributed processing to handle big data for EIMS, and examples from real applications. Additional material on the theory of EIIM and methods for assessing and evaluating EIMS performance also make this book appropriate for use as a textbook in courses on entity and identity management, data management, customer relationship management (CRM), and related topics. © 2015 Elsevier Inc. All rights reserved.},
  correspondence_address1 = {Talburt, J.R.},
  document_type           = {Book},
  doi                     = {10.1016/C2013-0-18748-X},
  journal                 = {Entity Information Life Cycle for Big Data: Master Data Management and Information Integration},
  keywords                = {Big data; Life cycle; Public relations, Customer relationship management; Distributed processing; Identity management; Information integration; Information life cycle; Information management systems; Master data management; Real applications, Information management},
  language                = {English},
  pages                   = {1-235},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943390108&doi=10.1016%2fC2013-0-18748-X&partnerID=40&md5=a21301b256309a1e3ec98ff3b011cf46},
}

@Article{Knoblock201525,
  author              = {Knoblock, C.A. and Szekely, P.},
  title               = {Exploiting semantics for big data integration},
  journal             = {AI Magazine},
  year                = {2015},
  volume              = {36},
  number              = {1},
  pages               = {25-38},
  issn                = {07384602},
  note                = {cited By 17},
  abbrev_source_title = {AI Mag},
  abstract            = {There is a great deal of interest in big data, focusing mostly on data set size. An equally important dimension of big data is variety, where the focus is to process highly heterogeneous data sets. We describe how we use semantics to address the problem of big data variety. We also describe Karma, a system that implements our approach and show how Karma can be applied to integrate data in the cultural heritage domain. In this use case, Karma integrates data across many museums even though the data sets from different museums are highly heterogeneous. © 2015, Association for the Advancement of Artificial Intelligence. All rights reserved.},
  affiliation         = {University of Southern California (USC), Los Angeles, CA, United States; Information Sciences Institute, University of Southern California, Los Angeles, CA, United States},
  coden               = {AIMAE},
  document_type       = {Article},
  doi                 = {10.1609/aimag.v36i1.2565},
  keywords            = {Data integration; Semantics, Cultural heritages; Data set size; Heterogeneous data, Big data},
  language            = {English},
  publisher           = {AI Access Foundation},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927157942&doi=10.1609%2faimag.v36i1.2565&partnerID=40&md5=5bfb5ea030fddec62dd6f8359a01ec81},
}

@Article{Bolker2015277,
  author                  = {Bolker, J. and Brauckmann, S.},
  title                   = {From experimental zoology to big data: Observation and integration in the study of animal development},
  journal                 = {Journal of Experimental Zoology Part A: Ecological Genetics and Physiology},
  year                    = {2015},
  volume                  = {323},
  number                  = {5},
  pages                   = {277-291},
  issn                    = {19325223},
  note                    = {cited By 1},
  abbrev_source_title     = {J. Exp. Zool. Part A Ecol. Genet. Physiol.},
  abstract                = {The founding of the Journal of Experimental Zoology in 1904 was inspired by a widespread turn toward experimental biology in the 19th century. The founding editors sought to promote experimental, laboratory-based approaches, particularly in developmental biology. This agenda raised key practical and epistemological questions about how and where to study development: Does the environment matter? How do we know that a cell or embryo isolated to facilitate observation reveals normal developmental processes? How can we integrate descriptive and experimental data? R.G. Harrison, the journal's first editor, grappled with these questions in justifying his use of cell culture to study neural patterning. Others confronted them in different contexts: for example, F.B. Sumner insisted on the primacy of fieldwork in his studies on adaptation, but also performed breeding experiments using wild-collected animals. The work of Harrison, Sumner, and other early contributors exemplified both the power of new techniques, and the meticulous explanation of practice and epistemology that was marshaled to promote experimental approaches. A century later, experimentation is widely viewed as the standard way to study development; yet at the same time, cutting-edge "big data" projects are essentially descriptive, closer to natural history than to the approaches championed by Harrison et al. Thus, the original questions about how and where we can best learn about development are still with us. Examining their history can inform current efforts to incorporate data from experiment and description, lab and field, and a broad range of organisms and disciplines, into an integrated understanding of animal development. © 2015 Wiley Periodicals, Inc.},
  affiliation             = {Department of Biological Sciences, University of New Hampshire, Durham, NH, United States; Teaduskeskus, University of Tartu, Tartu, Estonia},
  correspondence_address1 = {Bolker, J.; Department of Biological Sciences, 216 Rudman Hall, 46 College Road, United States; email: jbolker@unh.edu},
  document_type           = {Article},
  doi                     = {10.1002/jez.1924},
  keywords                = {Animalia, animal; animal experiment; biology; developmental biology; history; observation; procedures; publication; zoology, Animal Experimentation; Animals; Computational Biology; Developmental Biology; History, 20th Century; History, 21st Century; Observation; Periodicals as Topic; Zoology},
  language                = {English},
  publisher               = {John Wiley and Sons Inc.},
  pubmed_id               = {25757656},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929616579&doi=10.1002%2fjez.1924&partnerID=40&md5=5f6580e2ee4a43fbaefcb42af73e5b62},
}

@Book{Hashim201559,
  title                   = {Big data and cloud interoperability},
  publisher               = {IGI Global},
  year                    = {2015},
  author                  = {Hashim, A.Y.B.},
  isbn                    = {9781466696501; 1466696494; 9781466696495},
  note                    = {cited By 1},
  abbrev_source_title     = {Manag. Big Data Integr. in the Public Sect.},
  abstract                = {Cloud computing provides access to the high volume of data to individuals and enterprises. Immense data analytics and mobile technologies contain useful knowledge. Data storage, security, and privacy, on the other hand, are the main issues for any organization or enterprises in the business world. Big data processing is within reach due to easy access to cloud architectures and open-source software. Now, interoperability of big data and cloud has become a necessity in this era of data-intensive world. © 2016 by IGI Global. All rights reserved.},
  affiliation             = {Department of Robotics and Automation, Faculty of Manufacturing Engineering, Universiti Teknikal Malaysia Melaka, Malaysia},
  correspondence_address1 = {Hashim, A.Y.B.; Department of Robotics and Automation, Faculty of Manufacturing Engineering, Universiti Teknikal Malaysia MelakaMalaysia},
  document_type           = {Book Chapter},
  doi                     = {10.4018/978-1-4666-9649-5.ch004},
  journal                 = {Managing Big Data Integration in the Public Sector},
  keywords                = {Data handling; Digital storage; Interoperability; Open source software; Open systems; Software engineering, Cloud architectures; Data analytics; Data intensive; Data storage; High volumes; Mobile Technology, Big data},
  language                = {English},
  pages                   = {59-69},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982993872&doi=10.4018%2f978-1-4666-9649-5.ch004&partnerID=40&md5=9cab57623a7573d58bfd6961bd2b283e},
}

@Article{Dolin201575,
  author                  = {Dolin, R.H. and Rogers, B. and Jaffe, C.},
  title                   = {Health level seven interoperability strategy: Big data, Incrementally structured},
  journal                 = {Methods of Information in Medicine},
  year                    = {2015},
  volume                  = {54},
  number                  = {1},
  pages                   = {75-82},
  issn                    = {00261270},
  note                    = {cited By 11},
  abbrev_source_title     = {Methods Inf. Med.},
  abstract                = {Objectives: Describe how the HL7 Clinical Document Architecture (CDA), a foundational standard in US Meaningful Use, contributes to a “big data, incrementally structured” interoperability strategy, whereby data structured incrementally gets large amounts of data flowing faster. We present cases showing how this approach is leveraged for big data analysis.
Methods: To support the assertion that semi-structured narrative in CDA format can be a useful adjunct in an overall big data analytic approach, we present two case studies. The first assesses an organization’s ability to generate clinical quality reports using coded data alone vs. coded data supplemented by CDA narrative. The second leverages CDA to construct a network model for referral management, from which additional observations can be gleaned.
Results: The first case shows that coded data supplemented by CDA narrative resulted in significant variances in calculated performance scores. In the second case, we found that the constructed network model enables the identification of differences in patient characteristics among different re -ferral work flows.
Discussion: The CDA approach goes after data indirectly, by focusing first on the flow of narrative, which is then incrementally structured. A quantitative assessment of whether this approach will lead to a greater flow of data and ultimately a greater flow of structured data vs. other approaches is planned as a future exercise.
Conclusion: Along with growing adoption of CDA, we are now seeing the big data community explore the standard, particularly given its potential to supply analytic engines with volumes of data previously not possible. © Schattauer 2015.},
  affiliation             = {Orange, CA, United States; Apixio, Inc, Advanced Development Department, San Mateo, CA, United States; Health Level Seven International, Del Mar, CA, United States},
  author_keywords         = {Big data; CDA; HL7; Semantic Interoperability},
  coden                   = {MIMCA},
  correspondence_address1 = {Dolin, R.H.United States},
  document_type           = {Article},
  doi                     = {10.3414/ME14-01-0030},
  keywords                = {coding; electronic health record; health level 7; meaningful use criteria; medical record; organization and management; United States, Clinical Coding; Electronic Health Records; Health Level Seven; Meaningful Use; Medical Record Linkage; United States},
  language                = {English},
  publisher               = {Schattauer GmbH},
  pubmed_id               = {25448640},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921283366&doi=10.3414%2fME14-01-0030&partnerID=40&md5=967522b05afe689ecc8eb650b0fbaf90},
}

@Book{Zhou2015241,
  title               = {Organic streams a unified framework for personal big data integration and organization towards social sharing and individualized sustainable use},
  publisher           = {CRC Press},
  year                = {2015},
  author              = {Zhou, X. and Jin, Q.},
  isbn                = {9781482240566; 9781482240559},
  note                = {cited By 1},
  abbrev_source_title = {Big Data: Algorithms, Analytics, and Applications},
  abstract            = {This chapter describes a unified framework for dynamically integrating and meaningfully organizing personal and social Big Data. With the rapid development of emerging computing paradigms, we have been continuously experiencing a change in work, life, playing, and learning in the highly developed information society, which is a kind of seamless integration of the real physical world and cyber digital space. More and more people have been accustomed to sharing their personal contents across the social networks due to the high accessibility of social media along with the increasingly widespread adoption of wireless mobile computing devices. User-generated information has spread more widely and quickly and provided people with opportunities to obtain more knowledge and information than ever before, which leads to an explosive increase of data scale, containing big potential value for individual, business, domestic, and national economy development. Thus, it has become an increasingly important issue to sustainably manage and utilize personal Big Data, in order to mine useful insight and real value to better support information seeking and knowledge discovery. To deal with this situation in the Big Data era, a unified approach to aggregation and integration of personal Big Data from life logs in accordance with individual needs is considered essential and effective, which can benefit the sustainable information sharing and utilization process in the social networking environment. In this chapter, a new concept of organic stream, which is designed as a flexibly extensible data carrier, is introduced and defined to provide a simple but efficient means to formulate, organize, and represent personal Big Data. As an abstract data type, organic streams can be regarded as a logic metaphor, which aims to meaningfully process the raw stream data into an associatively and methodically organized form, but no concrete implementation for physical data structure and stor­age is defined. Under the conceptual model of organic streams, a heuristic method is proposed and applied to extract diversified individual needs from the tremendous amount of social stream data through social media. And an integrated mechanism is developed to aggregate and integrate the relevant data together based on individual needs in a meaningful way, in which personal data can be physically stored and distributed in private personal clouds and logically represented and processed by a set of newly introduced metaphors named heuristic stone, associative drop, and associative ripple the architecture of the system with the foundational modules is described, and the prototype implementation with the experiment’s result is presented to demonstrate the usability and effectiveness of the framework and system. © 2015 by Taylor & Francis Group, LLC.},
  affiliation         = {Faculty of Human Sciences, Waseda University, Tokorozawa-shi, Japan},
  document_type       = {Book Chapter},
  journal             = {Big Data: Algorithms, Analytics, and Applications},
  keywords            = {Abstract data types; Computation theory; Data integration; Data mining; Heuristic methods; Social networking (online); Social sciences computing, Adoption of wireless; Emerging computing paradigm; Information seeking; Information sharing; Information society; Prototype implementations; Seamless integration; Unified framework, Big data},
  language            = {English},
  pages               = {241-255},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013159050&partnerID=40&md5=0a21d435bba29c9dc71fd1855a9a9745},
}

@Conference{Huang2015,
  author              = {Huang, X.Q. and Zhang, K.D. and Chen, C. and Cao, Y.J. and Chen, C.Q.},
  title               = {Study on the integration architecture of electric power big data based on four kinds of integration patterns},
  year                = {2015},
  volume              = {2015},
  number              = {8},
  publisher           = {Institution of Engineering and Technology},
  note                = {cited By 0},
  abbrev_source_title = {IET Semin Dig},
  abstract            = {In this paper, an integration architecture for electric power big data (EPBD) is proposed. As the largest energy transmission system, power system features huge data volume, which is also one of the characteristics of big data. Generally, big data integration pattern includes data federation and data warehouse. Due to the requirements of high reliability, instantaneity and security for power system, common integration patterns for big data cannot meet the need of EPBD integration. Thus four kinds of integration patterns are presented to solve different data range and application targets in this paper. The concept, current research status, development trend, and key techniques used for the four integration patterns are elaborated. Furthermore, a general architecture for integration of EPBD based on these four patterns is proposed, which is further illustrated with an example of a power company.},
  affiliation         = {College of Electrical and Information Engineering, Hunan University, China},
  document_type       = {Conference Paper},
  journal             = {IET Seminar Digest},
  keywords            = {Big data; Data warehouses; Electric power transmission; Electric utilities, Current research status; Data federation; Development trends; Energy-transmission systems; General architectures; High reliability; Integration architecture; Integration patterns, Data integration},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997471447&partnerID=40&md5=4d0c74520e76198ea892830d4a081630},
}

@Conference{Benkaraache2015,
  author              = {Benkaraache, T. and Monino, J.-L. and Salam, G.},
  title               = {Integration of Big Data in the supply chain: To a "smart" supply chain [Intégration du Big Data dans le supply chain : Vers une supply chain « intelligente »]},
  year                = {2015},
  publisher           = {Association Information and Management},
  note                = {cited By 1},
  abbrev_source_title = {AIM - Colloq. l'AIM - Symp. Assoc. Inf. Manag., AIM},
  abstract            = {This article reflects on the management of big data ( Big Data ) and its potential contribution to the performance of the supply chain (SC ), in a context of competitive Intelligence (CI). The aim is to show that the integration of Big Data in the competitive intelligence systems in general, and the SC information systems in particular, carries new sources of competitiveness, but also risks and internal and external the SC. We first focus on the various stages of evolution that changed the SC management techniques, which have guided it towards greater responsiveness and security, before presenting the different dimensions of Big Data and its emergence in CI systems, as well as the opportunities offered by their integration in improving the performance of the Supply Chain.},
  affiliation         = {Laboratoire de Recherche sur L'intelligence Stratégique -LIS, Université Hassan II de Casablanca, Morocco; Laboratoire TRIS, UFR D'Économie, Université Montpellier 1, France; Université Hassan II de Casablanca, Morocco},
  author_keywords     = {Big Data; Competitive Intelligence; Decision; Information; Supply chain},
  document_type       = {Conference Paper},
  journal             = {20th Symposium of the Association Information and Management 2015, AIM 2015},
  keywords            = {Competition; Competitive intelligence; Data integration; Information management; Supply chain management; Supply chains, Decision; Information; Management techniques; New sources, Big data},
  language            = {French},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996549044&partnerID=40&md5=d80831a4783c658bc09461dc8c1e0a35},
}

@Conference{Ng2015183,
  author              = {Ng, P.M.L. and Lo, M.F. and Choy, E.},
  title               = {Improving China's corporate governance within the big data era: Integration of knowledge management and data governance},
  year                = {2015},
  editor              = {Ribiere V., Worasinchai L.},
  volume              = {2015-January},
  pages               = {183-190},
  publisher           = {Academic Conferences and Publishing International Limited},
  note                = {cited By 0},
  abbrev_source_title = {Proc. Int. Conf. Intell. Capital., Knowl. Manage. Org. Learn., ICICKM},
  abstract            = {Several literature examined different ways in improving China's corporate governance such as floating on nontradable shares, executive compensation, strengthening independent board of directors and supervisory board; however, there is a lack of existing research addressing the important role of knowledge management (KM) and data governance in China's corporate governance within the big data era. Knowledge management and data governance have become a major factor for improving corporate governance for international success. Therefore, this study is designed to develop a conceptual framework integrating KM strategy and data governance in improving corporate governance in China. We suggest that a KM-based approach to corporate governance provides a valid perspective. Both KM governance and data governance are indicative in improving corporate governance in China within the big data era. Devising appropriate KM mechanism and data governance helps ensure efficient and sound decision making from board of directors and stakeholders of organizations; minimizing falsification of accounting information among stakeholders.},
  affiliation         = {School of Professional Education and Executive Development, Hong Kong Polytechnic University, China; University of Newcastle, Australia},
  author_keywords     = {Big Data; China; Corporate governance; Data governance; Knowledge management},
  document_type       = {Conference Paper},
  isbn                = {9781910810736},
  issn                = {20489803},
  journal             = {Proceedings of the International Conference on Intellectual Capital, Knowledge Management and Organisational Learning, ICICKM},
  keywords            = {Data integration; Decision making; Industrial management; Information management; Knowledge management, Accounting informations; Board of directors; China; Conceptual frameworks; Corporate governance; Data governances; Executive compensation; Integration of knowledge, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994382312&partnerID=40&md5=c51fb9a11d9bcd294da72c5515f18186},
}

@Book{Aggarwal20151,
  title                   = {Managing big data integration in the public sector},
  publisher               = {IGI Global},
  year                    = {2015},
  author                  = {Aggarwal, A.},
  isbn                    = {9781466696501; 1466696494; 9781466696495},
  note                    = {cited By 1},
  abbrev_source_title     = {Manag. Big Data Integr. in the Public Sect.},
  abstract                = {The era of rapidly progressing technology we live in generates vast amounts of data; however, the challenge exists in understanding how to aggressively monitor and make sense of this data. Without a better understanding of how to collect and manage such large data sets, it becomes increasingly difficult to successfully utilize them. Managing Big Data Integration in the Public Sector is a pivotal reference source for the latest scholarly research on the application of big data analytics in government contexts and identifies various strategies in which big data platforms can generate improvements within that sector. Highlighting issues surrounding data management, current models, and real-world applications, this book is ideally designed for professionals, government agencies, researchers, and non-profit organizations interested in the benefits of big data analytics applied in the public sphere. © 2016 by IGI Global. All rights reserved.},
  affiliation             = {Merrick School of Business, University of Baltimore, United States},
  correspondence_address1 = {Aggarwal, A.; Merrick School of Business, University of BaltimoreUnited States},
  document_type           = {Book},
  doi                     = {10.4018/978-1-4666-9649-5},
  journal                 = {Managing Big Data Integration in the Public Sector},
  keywords                = {Data integration; Information management, Current models; Data analytics; Government agencies; Large datasets; Non profit organizations; Public sector; Reference source; Scholarly research, Big data},
  language                = {English},
  pages                   = {1-337},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982943048&doi=10.4018%2f978-1-4666-9649-5&partnerID=40&md5=66fb24e8491d1846134c931d5b71d859},
}

@Article{Jemal2015430,
  author                  = {Jemal, D. and Faiz, R. and Boukorca, A. and Bellatreche, L.},
  title                   = {MapReduce-DBMS: An integration model for big data management and optimization},
  journal                 = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year                    = {2015},
  volume                  = {9262},
  pages                   = {430-439},
  issn                    = {03029743},
  note                    = {cited By 3},
  abbrev_source_title     = {Lect. Notes Comput. Sci.},
  abstract                = {The data volume and the multitude of sources have an exponential number of technical and application challenges. In the past, Big Data solutions have been presented as a replacement for the Parallel Database Management Systems. However, Big Data solutions can be seen as a complement to a RDBMS for analytical applications, because different problems require complex analysis capabilities provided by both technologies. The aim of his work is to integrate a Big Data solution and a classic DBMS, in a goal of queries optimization. We propose a model for OLAP queries process. Then, we valid the proposed optimized model through experiments showing the gain of the execution cost saved up. © Springer International Publishing Switzerland 2015.},
  affiliation             = {LARODEC, ISG Tunis, University of Tunis, Tunis, Tunisia; LARODEC, IHEC Carthage, University of Carthage, Carthage, Tunisia; LIAS/ISAE-ENSMA Futuroscope, Chasseneuil-du-Poitou, France},
  author_keywords         = {Big data; Cost; Information retrieval; Integration; Mapreduce; OLAP; Optimization; Performance; RDBMS},
  correspondence_address1 = {Jemal, D.; LARODEC, ISG Tunis, University of TunisTunisia},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-319-22852-5_36},
  editor                  = {Hameurlain A., Wagner R., Decker H., Toumani F., Chen Q.},
  isbn                    = {9783319228518},
  keywords                = {Costs; Data integration; Database systems; Expert systems; Information management; Information retrieval; Integration; Optimization, Analytical applications; Exponential numbers; Integration models; Map-reduce; OLAP; Performance; Queries optimization; RDBMS, Big data},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943629714&doi=10.1007%2f978-3-319-22852-5_36&partnerID=40&md5=fa095a2473e83cf69682524921395362},
}

@Article{Li20151300,
  author              = {Li, F. and Li, C. and Wu, L. and Li, J. and Lü, X.},
  title               = {Data integration and services of digital geological mapping based on big data},
  journal             = {Geological Bulletin of China},
  year                = {2015},
  volume              = {34},
  number              = {7},
  pages               = {1300-1308},
  issn                = {16712552},
  note                = {cited By 1},
  abbrev_source_title = {Geol. Bull. China},
  abstract            = {A large number of geological mapping data have been formed from application of digital geological mapping technology. They include spatial data and unstructured data. The problem as to how to provide effective network data-services is an issue that should be resolved urgently. The technology of big data provides a new method for data integration and services. In this paper, the authors selectively analyzed the characteristics of the data formed from digital geological mapping, and investigated the data processing framework of big data based on Geological Survey Information Grid. On such a basis, a method for data management, publishing and service was proposed, in which spatial data and unstructured data are integrated effectively. Experimental results show the feasibility of this method. ©, 2015, Science Press. All right reserved.},
  affiliation         = {School of Earth Sciences and Resources, China University of Geosciences, Beijing, 100083, China; Development and Research Center of China Geological Survey, Beijing, 100037, China; China University of Geosciences, Wuhan, Hubei 430074, China},
  author_keywords     = {Big data; Digital geological mapping; Spatial data; Unstructured data},
  document_type       = {Article},
  keywords            = {data management; data processing; digital map; feasibility study; geological mapping; geological survey; spatial data},
  language            = {Chinese},
  publisher           = {China Geological Survey},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940040211&partnerID=40&md5=d92f72b45ab53f649f7347c390abe083},
}

@Article{Yin20152411,
  author                  = {Yin, X. and Sun, Y.},
  title                   = {Secure and efficient integration of big data for multi-cells based on micro images},
  journal                 = {Security and Communication Networks},
  year                    = {2015},
  volume                  = {8},
  number                  = {14},
  pages                   = {2411-2415},
  issn                    = {19390114},
  note                    = {cited By 1},
  abbrev_source_title     = {Secur. Commun. Networks},
  abstract                = {Information of multi-cells is big data because of the enormous quantities of various cells as well as their parameters and status. To securely and efficiently integrate all the cells' information and trace multi-cells are challenging due to varying number of the multi-cells, as well as the complicacy of the multi-cells' movement. In this paper, an automatic big data integration algorithm based on the optical transfer function is proposed. The experimental results show that the algorithm can securely and efficiently integrate all the cell information and simultaneously track a large quantity of cells. © 2013 John Wiley & Sons, Ltd.},
  affiliation             = {Physics and Electronics Information College, Tianjin Normal University, Tianjin, 300387, China},
  author_keywords         = {Auto-tracing; Data integration; Data secure; Microcells},
  correspondence_address1 = {Yin, X.; Physics and Electronics Information College, Tianjin Normal UniversityChina},
  document_type           = {Article},
  doi                     = {10.1002/sec.778},
  keywords                = {Cells; Cytology; Data integration; Optical transfer function, Auto-tracing; Cell information; Data secure; Integration algorithm; Micro cell; Microimage; Multicell, Big data},
  language                = {English},
  publisher               = {John Wiley and Sons Inc.},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939425441&doi=10.1002%2fsec.778&partnerID=40&md5=9a9585d4de79ac06aad8a431816a3e89},
}

@Conference{Palanimalai2015163,
  author                  = {Palanimalai, S. and Paramasivamb, I.},
  title                   = {AN enterprise oriented view on the cloud integration approaches -hybrid cloud and big data},
  year                    = {2015},
  editor                  = {Vijayakumar V., Neelanarayanan V.},
  volume                  = {50},
  pages                   = {163-168},
  publisher               = {Elsevier B.V.},
  note                    = {cited By 3},
  abbrev_source_title     = {Procedia Comput. Sci.},
  abstract                = {With the recent increase of SaaS providers in the market, enterprises are having difficulties in choosing their right organization's architecture. Subsequently data that exists outside the organization firewall needs to be managed and controlled. In spite of that, there are additional difficulties by BYOD (Bring Your Own Device) polices i.e. within the organization's firewall, when employees want to access the data using any device from anywhere. As a result, IT is now undergoing a major shift in demanding a new architecture, which will have the ability to integrate anything and anywhere. In order to get the seamless connectivity, between the systems and services across the enterprise, and also achieve the benefits of cloud computing, organizations are revolving to build an effective cloud integration strategy. It entails IT organizations to think about various aspects while choosing an organized approach for their application integration, data integration and process integration. The aim of this paper is to present the various cloud integration challenges, key aspects while choosing Integration solutions, and suggest a Hybrid Integration Architecture for various IT aspects to make the integration process much easier. We also present the benefits of handling Big data in Hybrid Cloud environment. © 2015 The Authors.},
  affiliation             = {School of Computer Science and Engineering, Bharathiar University, Coimbatore, India; School of Computing Science and Engineering, VIT University, Vellore, India},
  author_keywords         = {Big data; Cloud; Hybrid; Integration; Platform; Service},
  correspondence_address1 = {Palanimalai, S.; School of Computer Science and Engineering, Bharathiar UniversityIndia; email: Shan.Palanimalai@yahoo.com},
  document_type           = {Conference Paper},
  doi                     = {10.1016/j.procs.2015.04.079},
  issn                    = {18770509},
  journal                 = {Procedia Computer Science},
  keywords                = {Big data; Cloud computing; Clouds; Data handling; Distributed computer systems; Integration, Application integration; Bring your own devices; Hybrid; Integration process; Platform; Process integration; Seamless connectivity; Service, Data integration},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937426142&doi=10.1016%2fj.procs.2015.04.079&partnerID=40&md5=96e62eb307ac70f0e6d8dccb772cb486},
}

@Article{Zhang2015123,
  author              = {Zhang, S.-Z. and Qu, X.-K. and Sun, J.-B.},
  title               = {Data integration and mining based on web big data},
  journal             = {International Journal of Multimedia and Ubiquitous Engineering},
  year                = {2015},
  volume              = {10},
  number              = {6},
  pages               = {123-130},
  issn                = {19750080},
  note                = {cited By 0},
  abbrev_source_title = {Int. J. Multimedia Ubiquitous Eng.},
  abstract            = {As the revolution of Web 2.0 technology, more and more novel service industries, such as social network, web of things and mobile internet emerge. The data of Web explosive growth is called the “big data”, which is hottest. Because of the great value of big data of Web, how to achieve the Web data and how to mine and utilize it, the two are paid attention by an increasing number of researchers. Under the big data circumstance, the Web data is characterized by huge scale, various kinds and high-speed bitstream. Therefore, we can investigate, further, the Web data mining, integration, interpretation and analysis. Simultaneously, Web data mining and integration still confront challenges consist of data scale, data variety, data timeliness and protection of privacy. © 2015 SERSC.},
  affiliation         = {College of Computer and Communication Engineering, Zhengzhou University of Light Industry, Zhengzhou, 450002, China},
  author_keywords     = {Big data; Integration and mining; Web data},
  document_type       = {Article},
  doi                 = {10.14257/ijmue.2015.10.6.12},
  keywords            = {Data integration; Data mining; Social networking (online); Social sciences computing; World Wide Web, Explosive growth; Mobile Internet; Protection of privacy; Service industries; Web 2.0 Technologies; Web data; Web data mining; Web of things, Big data},
  language            = {English},
  publisher           = {Science and Engineering Research Support Society},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936746259&doi=10.14257%2fijmue.2015.10.6.12&partnerID=40&md5=eafb6dd89fa7fc48bfa81f6d79be023e},
}

@Conference{Idris2015244,
  author              = {Idris, M. and Hussain, S. and Ahmad, M. and Lee, S.},
  title               = {Big Data service engine (BISE): Integration of big data technologies for human centric wellness data},
  year                = {2015},
  pages               = {244-248},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 6},
  abbrev_source_title = {Int. Conf. Big Data Smart Comput., BIGCOMP},
  abstract            = {The advancement in new technologies and their data generation at substantial rate gave birth to the Big Data and requires a robust platform to capture, retrieve, store, and process it. Data generated by Human centric services and applications such as sensors, healthcare applications, social networks, and smart-phones need to be collected and processed to provide in-depth knowledge. In this paper, we propose Hadoop Distributed File System (HDFS) as convergence platform where all these multi-structured data is stored and use Hadoop No-SQL solutions to build warehouse for applications real time access to the data. We manage users clinical, personalized, and feedback data to provide clinical, physical, social, and mental health monitoring platform. We implement a Big Data service engine which provides storage services to health monitoring systems and analytics services to visualize and monitor clinical information, physical activities and emotions performed by the users. Our prototype system successfully integrates various technology platforms and provide centralized health monitoring system. © 2015 IEEE.},
  affiliation         = {Department of Computer Engineering, Kyung Hee University, South Korea},
  art_number          = {7072838},
  author_keywords     = {BigData; Cloud; Hadoop; Healthcare; MapReduce},
  document_type       = {Conference Paper},
  doi                 = {10.1109/35021BIGCOMP.2015.7072838},
  isbn                = {9781479973033},
  journal             = {2015 International Conference on Big Data and Smart Computing, BIGCOMP 2015},
  keywords            = {Clouds; Digital storage; Engines; File organization; Health; Health care; Monitoring; Smartphones; Telephone circuits, Clinical information; Hadoop; Hadoop distributed file system (HDFS); Health care application; Health monitoring system; Map-reduce; Services and applications; Various technologies, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928128968&doi=10.1109%2f35021BIGCOMP.2015.7072838&partnerID=40&md5=175e6627ba5b539665b9b06100e37aae},
}

@Conference{Christen20143,
  author                  = {Christen, P.},
  title                   = {Privacy aspects in big data integration: Challenges and opportunities},
  year                    = {2014},
  pages                   = {3-10},
  publisher               = {Association for Computing Machinery, Inc},
  note                    = {cited By 1},
  abbrev_source_title     = {PSBD - Proc. Int. Workshop Priv. Secur. Big Data, co-located CIKM},
  abstract                = {Big Data projects often require data from several sources to be integrated before they can be used for analysis. Once data have been integrated, they allow more detailed analysis that would otherwise not be possible. Accordingly, recent years have seen an increasing interest in techniques that facilitate the integration of data from diverse sources [2, 3]. Whenever data about individuals, or otherwise sensitive data, are to be integrated across organizations, privacy and confidentiality have to be considered. Domains where privacy preservation during data integration is of importance include business collaborations, health research, national censuses, the social sciences, crime and fraud detection, and homeland security [1]. Increasingly, applications in these domains require data from diverse sources (both internal and external to an organization) to be integrated. Consequently, in the past decade, various techniques have been developed that aim to facilitate data integration without revealing any private or confidential information about the databases and records that are integrated [4]. These techniques either provably prevent leakage of any private information, or they provide some empirical numerical measure of the risk of disclosure of private information. In the first part of this presentation we provide a background on data integration, and illustrate the importance of preserving privacy during data integration with several application scenarios. We then given an overview of the main concepts and techniques that have been developed to facilitate data integration in such ways that no private or confidential information is being revealed. We focus on privacy-preserving record linkage (PPRL), where so far most research has been conducted [4]. We describe the basic protocols used in PPRL, and several key technologies employed in these protocols. Finally, we discuss the challenges privacy poses to data integration in the era of Big Data, and we discuss directions and opportunities in this research area. Copyright © 2014 ACM.},
  affiliation             = {Research School of Computer Science, College of Engineering and Computer Science, Australian National University, Canberra, ACT 0200, Australia},
  author_keywords         = {Data matching; Multi-party; Privacy techniques; Privacy-preserving record linkage; Scalability},
  correspondence_address1 = {Christen, P.; Research School of Computer Science, College of Engineering and Computer Science, Australian National UniversityAustralia; email: peter.christen@anu.edu.au},
  document_type           = {Conference Paper},
  doi                     = {10.1145/2663715.2669615},
  isbn                    = {9781450315838},
  journal                 = {PSBD 2014 - Proceedings of the 1st International Workshop on Privacy and Secuirty of Big Data, co-located with CIKM 2014},
  keywords                = {Big data; Data handling; Data privacy; National security; Risk assessment; Scalability, Application scenario; Business collaboration; Confidential information; Data matching; Multi-party; Privacy preservation; Privacy preserving record linkages; Private information, Data integration},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978699235&doi=10.1145%2f2663715.2669615&partnerID=40&md5=0c8c0052b6987024d518340118a3c8f8},
}

@Article{Ma'ayan2014450,
  author              = {Ma'ayan, A. and Rouillard, A.D. and Clark, N.R. and Wang, Z. and Duan, Q. and Kou, Y.},
  title               = {Lean Big Data integration in systems biology and systems pharmacology},
  journal             = {Trends in pharmacological sciences},
  year                = {2014},
  volume              = {35},
  number              = {9},
  pages               = {450-460},
  issn                = {18733735},
  note                = {cited By 41},
  abbrev_source_title = {Trends Pharmacol. Sci.},
  abstract            = {Data sets from recent large-scale projects can be integrated into one unified puzzle that can provide new insights into how drugs and genetic perturbations applied to human cells are linked to whole-organism phenotypes. Data that report how drugs affect the phenotype of human cell lines and how drugs induce changes in gene and protein expression in human cell lines can be combined with knowledge about human disease, side effects induced by drugs, and mouse phenotypes. Such data integration efforts can be achieved through the conversion of data from the various resources into single-node-type networks, gene-set libraries, or multipartite graphs. This approach can lead us to the identification of more relationships between genes, drugs, and phenotypes as well as benchmark computational and experimental methods. Overall, this lean 'Big Data' integration strategy will bring us closer toward the goal of realizing personalized medicine. Copyright © 2014 Elsevier Ltd. All rights reserved.},
  affiliation         = {Department of Pharmacology and Systems Therapeutics, Icahn School of Medicine at Mount Sinai, Systems Biology Center New York (SBCNY), One Gustave L. Levy Place, Box 1215, New York, NY 10029, USA. Electronic address: avi.maayan@mssm.edu; Department of Pharmacology and Systems Therapeutics, Icahn School of Medicine at Mount Sinai, Systems Biology Center New York (SBCNY), One Gustave L. Levy Place, Box 1215, New York, NY 10029, USA; Department of Pharmacology and Systems Therapeutics, Icahn School of Medicine at Mount Sinai, Systems Biology Center New York (SBCNY), One Gustave L. Levy Place, Box 1215, New York, NY 10029, USA; Department of Pharmacology and Systems Therapeutics, Icahn School of Medicine at Mount Sinai, Systems Biology Center New York (SBCNY), One Gustave L. Levy Place, Box 1215, New York, NY 10029, USA; Department of Pharmacology and Systems Therapeutics, Icahn School of Medicine at Mount Sinai, Systems Biology Center New York (SBCNY), One Gustave L. Levy Place, Box 1215, New York, NY 10029, USA; Department of Pharmacology and Systems Therapeutics, Icahn School of Medicine at Mount Sinai, Systems Biology Center New York (SBCNY), One Gustave L. Levy Place, Box 1215, New York, NY 10029, USA},
  author_keywords     = {data integration; network analysis; network pharmacology; side-effect prediction; systems pharmacology; target prediction},
  document_type       = {Review},
  doi                 = {10.1016/j.tips.2014.07.001},
  keywords            = {animal; data mining; factual database; human; pharmacology; systems biology, Animals; Data Mining; Databases, Factual; Humans; Pharmacology; Systems Biology},
  language            = {English},
  pubmed_id           = {25109570},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961371413&doi=10.1016%2fj.tips.2014.07.001&partnerID=40&md5=9a4871bf3ddc44b784ad6c223834147c},
}

@Conference{Xiong2014245,
  author              = {Xiong, J. and Liu, Y. and Liu, W.},
  title               = {Ontology-based integration and sharing of big data educational resources},
  year                = {2014},
  pages               = {245-248},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 3},
  abbrev_source_title = {Proc. - Web Inf. Syst. Appl. Conf., WISA},
  abstract            = {In the era of big data, massive educational resources are stored on the internet and mobile networks. However, most of these resources are heterogeneous and decentralized, they have different format. The resources are designed for humans to read and not understandable to the machine. Their low level sharing and reuse make them difficult to acquire. How to access the resources the users need quickly and efficiently and take advantage of them is a serious problem. In order to solve the problem, an ontology-based integration educational resources framework and sharing strategies are proposed. Using the advantages of ontological semantics these educational resources can be annotated semantically, so that the computer can understand and deal with the marked information. The ontology-based integration and sharing strategies can improve the recall and precision of the educational resources retrieval. © 2014 IEEE.},
  affiliation         = {School of Computer and Information Engineering, Anyang Normal University, Anyang, China; Dept. of Third Government Division, Neusoft Group Ltd, Jinan, China},
  art_number          = {7058020},
  author_keywords     = {Big data; Educational resources; Information retrieval; Ontology; Semantic integration},
  document_type       = {Conference Paper},
  doi                 = {10.1109/WISA.2014.51},
  isbn                = {9781479957262},
  journal             = {Proceedings - 11th Web Information System and Application Conference, WISA 2014},
  keywords            = {Data integration; Education; Information retrieval; Integration; Ontology; Semantics, Educational resource; Ontology-based integrations; Recall and precision; Semantic integration; Sharing strategies, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946686904&doi=10.1109%2fWISA.2014.51&partnerID=40&md5=10a513be847ec9b5ccd224154e33de85},
}

@Conference{Kadadi201438,
  author              = {Kadadi, A. and Agrawal, R. and Nyamful, C. and Atiq, R.},
  title               = {Challenges of data integration and interoperability in big data},
  year                = {2014},
  editor              = {Chang W., Huan J., Cercone N., Pyne S., Honavar V., Lin J., Hu X.T., Aggarwal C., Mobasher B., Pei J., Nambiar R.},
  pages               = {38-40},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 15},
  abbrev_source_title = {Proc. - IEEE Int. Conf. Big Data, IEEE Big Data},
  abstract            = {The enormous volumes of data created and maintained by industries, research institutions are on the verge of outgrowing its infrastructure. The advancements in the organization's work flow include data storage, data management, data maintenance, data integration, and data interoperability. Among these levels, data integration and data interoperability can be the two major focus areas for the organizations which tend to implement advancements in their workflow. Overall, data integration and data interoperability influence the organization's performance. The data integration and data interoperability are complex challenges for the organizations deploying big data architectures due to the heterogeneous nature of data used by them. Therefore, it requires a comprehensive approach to negotiate the challenges in integration and interoperability. This paper focuses on the challenges of data integration and data interoperability in big data. © 2014 IEEE.},
  affiliation         = {Department of Computer Systems Technology, North Carolina A and T State University, Greensboro, NC, United States; University of Arkansas at Pine Bluff, Pine Bluff, AR, United States},
  art_number          = {7004486},
  author_keywords     = {Data Integration; Data Interoperability},
  document_type       = {Conference Paper},
  doi                 = {10.1109/BigData.2014.7004486},
  isbn                = {9781479956654},
  journal             = {Proceedings - 2014 IEEE International Conference on Big Data, IEEE Big Data 2014},
  keywords            = {Big data; Digital storage; Information management; Interoperability; Societies and institutions, Data architectures; Data interoperability; Data maintenance; Data storage; Focus areas; Research institutions; Work-flows, Data integration},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988298991&doi=10.1109%2fBigData.2014.7004486&partnerID=40&md5=cc7ca4a4e4e6916451dce3d0996ca688},
}

@Article{Shen2014,
  author                  = {Shen, B. and Teschendorff, A.E. and Zhi, D. and Xia, J.},
  title                   = {Biomedical data integration, modeling, and simulation in the era of big data and translational medicine},
  journal                 = {BioMed Research International},
  year                    = {2014},
  volume                  = {2014},
  issn                    = {23146133},
  note                    = {cited By 3},
  abbrev_source_title     = {BioMed Res. Int.},
  affiliation             = {Center for Systems Biology, Soochow University, P.O. Box 206, Suzhou, 215006, China; Cancer Institute, University College London, 72 Huntley Street, London, WC1E 6BT, United Kingdom; Department of Biostatistics, University of Alabama at Birmingham, Birmingham, AL 35294, United States; Institute of Health Sciences, Anhui University, Hefei, 230601, China},
  art_number              = {731546},
  correspondence_address1 = {Shen, B.; Center for Systems Biology, Soochow University, P.O. Box 206, China},
  document_type           = {Editorial},
  doi                     = {10.1155/2014/731546},
  keywords                = {biomedicine; China; clinical study; data analysis; data processing; Editorial; information technology; medical informatics; molecular imaging; simulation; support vector machine; translational research; biology; human; procedures; statistics; translational research, Computational Biology; Humans; Medical Informatics; Statistics as Topic; Translational Medical Research},
  language                = {English},
  publisher               = {Hindawi Publishing Corporation},
  pubmed_id               = {25147813},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934991550&doi=10.1155%2f2014%2f731546&partnerID=40&md5=814ba7f8a1dde6d949ed78b78915979f},
}

@Conference{Bansal2014522,
  author                  = {Bansal, S.K.},
  title                   = {Towards a Semantic Extract-Transform-Load (ETL) framework for big data integration},
  year                    = {2014},
  editor                  = {Chen P., Chen P., Jain H.},
  pages                   = {522-529},
  publisher               = {Institute of Electrical and Electronics Engineers Inc.},
  note                    = {cited By 32},
  abbrev_source_title     = {Proc. - IEEE Int. Congr. Big Data, BigData Congr.},
  abstract                = {Big Data has become the new ubiquitous term used to describe massive collection of datasets that are difficult to process using traditional database and software techniques. Most of this data is inaccessible to users, as we need technology and tools to find, transform, analyze, and visualize data in order to make it consumable for decision-making. One aspect of Big Data research is dealing with the Variety of data that includes various formats such as structured, numeric, unstructured text data, email, video, audio, stock ticker, etc. Managing, merging, and governing a variety of data is the focus of this paper. This paper proposes a semantic Extract-Transform-Load (ETL) framework that uses semantic technologies to integrate and publish data from multiple sources as open linked data. This includes - creation of a semantic data model to provide a basis for integration and understanding of knowledge from multiple sources, creation of a distributed Web of data using Resource Description Framework (RDF) as the graph data model, extraction of useful knowledge and information from the combined data using SPARQL as the semantic query language. © 2014 IEEE.},
  affiliation             = {Dept. of Engineering and Computing Systems, Arizona State University, Mesa, AZ, United States},
  art_number              = {6906824},
  author_keywords         = {Big data; Data integration; Ontology; Semantic technolgies},
  correspondence_address1 = {Bansal, S.K.; Dept. of Engineering and Computing Systems, Arizona State UniversityUnited States},
  document_type           = {Conference Paper},
  doi                     = {10.1109/BigData.Congress.2014.82},
  isbn                    = {9781479950577},
  journal                 = {Proceedings - 2014 IEEE International Congress on Big Data, BigData Congress 2014},
  keywords                = {Data integration; Decision making; Ontology; Query languages; Query processing; Semantic Web; Semantics, Extract transform loads; Graph data models; Resource description framework; Semantic data model; Semantic query language; Semantic technologies; Software techniques; Unstructured texts, Big data},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923917788&doi=10.1109%2fBigData.Congress.2014.82&partnerID=40&md5=f04f52d494341d4bf17f32c814ee665d},
}

@Conference{Pombo201466,
  author              = {Pombo, N. and Garcia, N. and Felizardo, V. and Bousson, K.},
  title               = {Big data reduction using RBFNN: A predictive model for ECG waveform for eHealth platform integration},
  year                = {2014},
  pages               = {66-70},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 8},
  abbrev_source_title = {IEEE Int. Conf. e-Health Netw., Appl. Serv., Healthcom},
  abstract            = {The main challenge of big data processing includes the extraction of relevant information, from a high dimensionality of a wide variety of medical data by enabling analysis, discovery and interpretation. These data are a useful tool for helping to understand disease and to formulate predictive models in different areas and support different tasks, such as triage, evaluation of treatment, and monitoring. In this paper, a case study based on a predictive model using the radial basis function neural network (RBFNN) combined with a filtering technique aiming the estimation of electrocardiogram (ECG) waveform is presented. The proposed method revealed it suitability to support health care professionals on clinical decisions and practices. © 2014 IEEE.},
  affiliation         = {Instituto de Telecomunicações, Covilhã, Portugal; Department of Computer Science, University of Beira Interior, Covilhã, Portugal; ALLab - Assisted Living Computing and Telecommunications Laboratory, Covilhã, Portugal; Universidade Lusófona de Humanidades e Tecnologias, Lisbon, Portugal; LAETA-UBI/AEROG, Department of Aerospace Sciences, University of Beira Interior, Covilhã, Portugal},
  art_number          = {7001815},
  author_keywords     = {big data; clinical decision support system; ECG; radial basis function neural network},
  document_type       = {Conference Paper},
  doi                 = {10.1109/HealthCom.2014.7001815},
  isbn                = {9781479966448},
  journal             = {2014 IEEE 16th International Conference on e-Health Networking, Applications and Services, Healthcom 2014},
  keywords            = {Data handling; Data mining; Decision support systems; eHealth; Electrocardiography; Functions; Radial basis function networks, Clinical decision support systems; Filtering technique; Health care professionals; High dimensionality; Platform integrations; Predictive modeling; Predictive models; Radial basis function neural networks, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921751695&doi=10.1109%2fHealthCom.2014.7001815&partnerID=40&md5=10a99fe89dc86d5a62b5dd1709484128},
}

@Article{Kejriwal2014521,
  author                  = {Kejriwal, M.},
  title                   = {Populating entity name systems for big data integration},
  journal                 = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year                    = {2014},
  volume                  = {8797},
  pages                   = {521-528},
  issn                    = {03029743},
  note                    = {cited By 5},
  abbrev_source_title     = {Lect. Notes Comput. Sci.},
  abstract                = {An Entity Name System (ENS) is a thesaurus for entities. An ENS is a fundamental component of data integration systems, serving instance matching needs across multiple data sources. Populating an ENS in support of co-referencing Linked Open Data (LOD) is a Big Data problem. Viable solutions to the long-standing Entity Resolution (ER) problem are required, meeting specific requirements of heterogeneity, scalability and automation. In this thesis, we propose to develop and implement algorithms for an ER system that address the three key criteria. Preliminary results demonstrate potential system feasibility. © Springer International Publishing Switzerland 2014.},
  affiliation             = {University of Texas at Austin, United States},
  author_keywords         = {Data integration; Entity name system; Entity resolution},
  correspondence_address1 = {Kejriwal, M.; University of Texas at AustinUnited States},
  document_type           = {Conference Paper},
  editor                  = {Mika P., Tudorache T., Bernstein A., Groth P., Goble C., Welty C., Vrandecic D., Noy N., Knoblock C., Janowicz K.},
  isbn                    = {9783319119144},
  keywords                = {Entity name system; Entity resolutions, Data integration},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910025894&partnerID=40&md5=d43f8b851b5313883f90fac30500ad3a},
}

@Article{Xiangsheng201422,
  author                  = {Xiangsheng, K.},
  title                   = {Big data x-learning resources integration and processing in cloud environments},
  journal                 = {International Journal of Emerging Technologies in Learning},
  year                    = {2014},
  volume                  = {9},
  number                  = {5},
  pages                   = {22-26},
  issn                    = {18688799},
  note                    = {cited By 3},
  abbrev_source_title     = {Int. J. Emerg. Technol. Learn.},
  abstract                = {The cloud computing platform has good flexibility characteristics, more and more learning systems are migrated to the cloud platform. Firstly, this paper describes different types of educational environments and the data they provide. Then, it proposes a kind of heterogeneous learning resources mining, integration and processing architecture. In order to integrate and process the different types of learning resources in different educational environments, this paper specifically proposes a novel solution and massive storage integration algorithm and conversion algorithm to the heterogeneous learning resources storage and management cloud environments.},
  affiliation             = {Department of Computer Engineering, Xinxiang University, Xinxiang, China},
  author_keywords         = {Educational data mining; Learning resource; Mapreduce; Newsql; Nosql},
  correspondence_address1 = {Xiangsheng, K.; Department of Computer Engineering, Xinxiang UniversityChina},
  document_type           = {Article},
  doi                     = {10.3991/ijet.v9i5.3783},
  keywords                = {Digital storage; Distributed computer systems; Integration, Educational data mining; Learning resource; Map-reduce; Newsql; Nosql, Big data},
  language                = {English},
  publisher               = {Kassel University Press GmbH},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907698430&doi=10.3991%2fijet.v9i5.3783&partnerID=40&md5=6ad96eb75f9f3fec2b45475673fad6f1},
}

@Article{Sun2014936,
  author                  = {Sun, D.},
  title                   = {Big data learning resources integration and processing in cloud environments},
  journal                 = {Journal of Chemical and Pharmaceutical Research},
  year                    = {2014},
  volume                  = {6},
  number                  = {5},
  pages                   = {936-943},
  issn                    = {09757384},
  note                    = {cited By 0},
  abbrev_source_title     = {J. Chem. Pharm. Res.},
  abstract                = {This paper discusses about educational data integration and processing and how it can be used to improve the functional activities of business of education through students, teachers and the way classes are arranged. A key contribution of this paper is the description of a wide array of course resources, e.g., virtual machines, sample projects, and in-class exercises, and how these resources support the learning outcomes and enables a hands-on experience with Big Data technologies. © 2014, Journal of Chemical and Pharmaceutical Research. All rights reserved.},
  affiliation             = {North China University of Water Resources and Electric Power, Zhengzhou, China},
  author_keywords         = {Educational Data Mining; Learning resource; Map Reduce; X-learning},
  correspondence_address1 = {Sun, D.; North China University of Water Resources and Electric PowerChina},
  document_type           = {Article},
  keywords                = {Cloud environments; Educational data mining; Learning resource; Map-reduce; X-learning, architecture; Article; computer language; computer system; data base; data mining; data processing; decision making; education; environment; hadoops distributed file system; integration; learning; machine learning; structured query language},
  language                = {English},
  publisher               = {Journal of Chemical and Pharmaceutical Research},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907099572&partnerID=40&md5=871c9e08b252bdc62f503d16c9033091},
}

@Article{Rahm2014,
  author                  = {Rahm, E.},
  title                   = {Discovering product counterfeits in online shops: A big data integration challenge},
  journal                 = {Journal of Data and Information Quality},
  year                    = {2014},
  volume                  = {5},
  number                  = {1-2},
  issn                    = {19361955},
  note                    = {cited By 4},
  abbrev_source_title     = {J. Data Inf. Qual.},
  affiliation             = {University of Leipzig, Germany},
  art_number              = {3},
  correspondence_address1 = {Rahm, E.; University of LeipzigGermany},
  document_type           = {Article},
  doi                     = {10.1145/2629605},
  language                = {English},
  publisher               = {Association for Computing Machinery},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907031312&doi=10.1145%2f2629605&partnerID=40&md5=a687ecfc2a627cf3812836a104a35580},
}

@Conference{Gastaldi2014,
  author                  = {Gastaldi, M.},
  title                   = {Integration of mobile, big data, sensors, and social media: Impact on daily life and business},
  year                    = {2014},
  publisher               = {IEEE Computer Society},
  note                    = {cited By 4},
  abbrev_source_title     = {IST-Africa Conf. Exhib., IST-Africa},
  abstract                = {This paper provides a critical analysis of the impact of advanced technologies on our daily lives. It is contended that the integration of four key drivers (mobiles, data, sensors and social media) has a profound impact on society and human interaction on the social as well as the business scene. Whilst this impact has been intrusive, in that integration of these four key drivers eliminates the natural boundaries of privacy, it has also been beneficial in socioeconomic terms. These benefits are discussed from the perspective of the medical (mobile health) and business marketing (right time experiences) disciplines. Moreover, other business benefits from the use of these technologies have also been discussed in this paper. It is envisioned that this discursive paper will lead to an enlightenment within the continent and deepen the appreciation of integrative technologies. This paper asserts that these drivers, as stellar examples of best practice within the fields of medical and business marketing, can lead to similar innovations in other service industries. © 2014 IIMC.},
  affiliation             = {Evonue Digital, Kalimaye Rd, Black River, Flic en Flac - 90508, Mauritius},
  art_number              = {6880670},
  author_keywords         = {big data; contextual marketing; hyper personalised marketing; internet of things; marketing; mobile health; mobile technologies; privacy; quantified self; right time experiences; sensors; social media; social media marketing; wearable devices},
  correspondence_address1 = {Gastaldi, M.; Evonue Digital, Kalimaye Rd, Black River, Flic en Flac - 90508, Mauritius; email: mg@evonuedigital.com},
  document_type           = {Conference Paper},
  doi                     = {10.1109/ISTAFRICA.2014.6880670},
  isbn                    = {9781905824441},
  journal                 = {2014 IST-Africa Conference and Exhibition, IST-Africa 2014},
  keywords                = {Commerce; Data privacy; Integration; Internet of things; Marketing; Sensors, Mobile health; Mobile Technology; quantified self; right time experiences; Social media; Social media marketings; Wearable devices, Big data},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906748458&doi=10.1109%2fISTAFRICA.2014.6880670&partnerID=40&md5=2fc89cc053b1adf0aa04857f2cb4aeee},
}

@Conference{Bohlouli2014612,
  author              = {Bohlouli, M. and Merges, F. and Fathi, M.},
  title               = {Knowledge integration of distributed enterprises using cloud based big data analytics},
  year                = {2014},
  pages               = {612-617},
  publisher           = {IEEE Computer Society},
  note                = {cited By 4},
  abbrev_source_title = {IEEE Int. Conf. Electro Inform. Technol.},
  abstract            = {An efficient and adaptive centralization of disparate knowledge sources is a key factor for the success of knowledge management systems (KMS) in distributed heterogeneous enterprises such as healthcare and production systems with large scale and disparate knowledge sources. Professional end users of such systems (e.g. physicians and production engineers) should have nearly real-time access to the records to provide relevant decisions without any difficulty of dealing with IT systems. Analysis and reasoning of professional end users' feedback lead helpful knowledge bases which can be used for future decision making situations such as diagnostics and predictions. This paper represents an overview of the cloud computing based conceptual framework for the integration of distributed knowledge sources in large scale heterogeneous enterprises such as grouped hospitals, clinic chains, production systems, supply chains and etc. The NoSQL database is used for providing a scalable data analytics. This framework facilitates accessible, efficient and always available knowledge bases for collaborative systems and reduces redundancy and costs by sharing the knowledge between individuals and experts. Three different application scenarios will be used to test and evaluate the efficiency of the proposed framework. Distributed product design and development, healthcare knowledge integration and providing readability in drug leaflets are target application domains of this research. © 2014 IEEE.},
  affiliation         = {Faculty of Science and Engineering, University of Siegen, Siegen, Germany},
  art_number          = {6871835},
  author_keywords     = {Cloud Computing; Healthcare Knowledge Management; Knowledge Integration; Secure Knowledge Centralization},
  document_type       = {Conference Paper},
  doi                 = {10.1109/EIT.2014.6871835},
  isbn                = {9781479947744},
  issn                = {21540357},
  journal             = {IEEE International Conference on Electro Information Technology},
  keywords            = {Big data; Cloud computing; Health care; Knowledge based systems; Knowledge management; Supply chains, Application scenario; Collaborative systems; Conceptual frameworks; Distributed knowledge; Knowledge integration; Knowledge management system; Product design and development; Secure Knowledge Centralization, Distributed database systems},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906568898&doi=10.1109%2fEIT.2014.6871835&partnerID=40&md5=ced4f4306c26a1a29e26e0524615bf09},
}

@Conference{Jamil201462,
  author                  = {Jamil, H.M.},
  title                   = {Mapping abstract queries to big data web resources for on-the-fly data integration and information retrieval},
  year                    = {2014},
  pages                   = {62-67},
  publisher               = {IEEE Computer Society},
  note                    = {cited By 3},
  abbrev_source_title     = {Proc Int Conf Data Eng},
  abstract                = {The emergence of technologies such as XML, web services and cloud computing have helped, the proliferation of databases and their diversity pose serious barriers to meaningful information extraction from these 'big databases'. Research in intention recognition has also progressed substantially, yet very little has been done to recognize query intents to search, select, map and extract responses from such enormous pools of candidate databases. Query mapping becomes truly complicated particularly in scientific databases where tools and functions are needed to interpret the database contents, semantics of which are usually hidden inside the functions. In this paper, we present a declarative meta-language, called BioVis, using which biologists potentially are able to express their 'intentional queries' with the expectation that a mapping function μ is able to accurately understand the meaning of the queries and map them to the underlying resources appropriately. We show that such a function is technically feasible if we can design a schema mapping function that can tailor itself according to a knowledgebase and recognize entities in schema graphs. We offer this idea as a possible research problem for the community to address. © 2014 IEEE.},
  affiliation             = {Department of Computer Science, University of Idaho, Moscow, ID, United States},
  art_number              = {6818304},
  correspondence_address1 = {Jamil, H.M.; Department of Computer Science, University of Idaho, Moscow, ID, United States; email: jamil@uidaho.edu},
  document_type           = {Conference Paper},
  doi                     = {10.1109/ICDEW.2014.6818304},
  isbn                    = {9781479934805},
  issn                    = {10844627},
  journal                 = {Proceedings - International Conference on Data Engineering},
  keywords                = {Database systems; Mapping; Query processing; Semantics; Technical presentations; Web services, Database contents; Intention recognition; Knowledge base; Mapping functions; Meta language; Research problems; Schema mappings; Scientific database, Big data},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901784944&doi=10.1109%2fICDEW.2014.6818304&partnerID=40&md5=4fa1b86247e41bf6f4a6d28c6da5461e},
}

@Conference{Williams201468,
  author              = {Williams, K. and Wu, J. and Choudhury, S.R. and Khabsa, M. and Giles, C.L.},
  title               = {Scholarly big data information extraction and integration in the CiteSeerχ digital library},
  year                = {2014},
  pages               = {68-73},
  publisher           = {IEEE Computer Society},
  note                = {cited By 15},
  abbrev_source_title = {Proc Int Conf Data Eng},
  abstract            = {CiteSeerχ is a digital library that contains approximately 3.5 million scholarly documents and receives between 2 and 4 million requests per day. In addition to making documents available via a public Website, the data is also used to facilitate research in areas like citation analysis, co-author network analysis, scalability evaluation and information extraction. The papers in CiteSeerχ are gathered from the Web by means of continuous automatic focused crawling and go through a series of automatic processing steps as part of the ingestion process. Given the size of the collection, the fact that it is constantly expanding, and the multiple ways in which it is used both by the public to access scholarly documents and for research, there are several big data challenges. In this paper, we provide a case study description of how we address these challenges when it comes to information extraction, data integration and entity linking in CiteSeer χ. We describe how we: aggregate data from multiple sources on the Web; store and manage data; process data as part of an automatic ingestion pipeline that includes automatic metadata and information extraction; perform document and citation clustering; perform entity linking and name disambiguation; and make our data and source code available to enable research and collaboration. © 2014 IEEE.},
  affiliation         = {Information Sciences and Technology, Pennsylvania State University, University Park, PA 16802, United States; Computer Science and Engineering, Pennsylvania State University, University Park, PA 16802, United States},
  art_number          = {6818305},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICDEW.2014.6818305},
  isbn                = {9781479934805},
  issn                = {10844627},
  journal             = {Proceedings - International Conference on Data Engineering},
  keywords            = {Big data; Computer aided network analysis; Digital libraries; Information retrieval; Research; Technical presentations, Automatic processing; Citation analysis; Co-author networks; Data challenges; Focused crawling; Multiple source; Name disambiguation; Scalability evaluation, Data mining},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901755944&doi=10.1109%2fICDEW.2014.6818305&partnerID=40&md5=6dce5955710329375bd7e414b708816a},
}

@Conference{Nimmagadda2013148,
  author                  = {Nimmagadda, S.L. and Dreher, H.V.},
  title                   = {Big-data integration methodologies for effective management and data mining of petroleum digital ecosystems},
  year                    = {2013},
  pages                   = {148-153},
  note                    = {cited By 6},
  abbrev_source_title     = {IEEE Int. Conf. Digit. Ecosyst. Technol.},
  abstract                = {Petroleum industries' big data characterize heterogeneity and they are often multidimensional in nature. In the recent past, explorers narrate petroleum system, as an ecosystem, in which elements and processes are constantly interacted and communicated each other. Exploration is one of the key super-type data dimensions of petroleum ecosystem, (including seismic dimension), exhibiting high degree of heterogeneity, sequence identity and structural similarity; this is especially the case for, elements and processes that are unique to petroleum systems of South East Asia. Existing approaches of petroleum data organizations have limitations in capturing and integrating petroleum systems data. An alternative method uses ontologies and does not rely on keywords or similarity metrics. The conceptual framework of petroleum ontology (PO) is to promote reuse of concepts and a set of algebraic operators for querying petroleum ontology instances. This ontology-based fine-grained multidimensional data structuring adapts to warehouse metadata modeling. The data integration process facilitates to metadata models, which are deduced for Indonesian sedimentary basins, and is useful for data mining and subsequent data interpretation including geological knowledge mapping. © 2013 IEEE.},
  affiliation             = {PTS, Schlumberger, Moscow, Russian Federation; School of Information Systems, CBS, Curtin University, Perth, Australia},
  art_number              = {6611345},
  author_keywords         = {data fusion; data integration; data mining; Data warehousing; ontologies; petroleum bearing sedimentary basin},
  correspondence_address1 = {PTS, Schlumberger, Moscow, Russian Federation},
  document_type           = {Conference Paper},
  doi                     = {10.1109/DEST.2013.6611345},
  isbn                    = {9781479907861},
  issn                    = {21504938},
  journal                 = {IEEE International Conference on Digital Ecosystems and Technologies},
  keywords                = {Conceptual frameworks; Data interpretation; Effective management; Integration process; Multidimensional data; Petroleum ecosystems; Sedimentary basin; Structural similarity, Data fusion; Data integration; Data mining; Data warehouses; Embedded systems; Ontology; Petroleum deposits; Petroleum prospecting; Settling tanks, Ecosystems},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885820157&doi=10.1109%2fDEST.2013.6611345&partnerID=40&md5=520d3135e19bc6110dd36f1451d7151a},
}

@Conference{Larsen2013,
  author                  = {Larsen, T.},
  title                   = {Cross-platform aviation analytics using big-data integration methods},
  year                    = {2013},
  note                    = {cited By 5},
  abbrev_source_title     = {Integr. Commun., Navig. Surveill. Conf., ICNS},
  abstract                = {MasFlight's data warehouse and analysis methods provide a valuable example for others attempting to solve cloud based analytics of aviation data sets • masFlight's hybrid architecture, consolidating secure data feeds in on-premises server installations and feeding structured data into the cloud for distribution, addresses the unique format, security and scale requirements of the industry • masFlight's method is well suited for airline performance review, competitive benchmarking, airport operations and schedule design, and has demonstrated value in addressing real-world problems in airline and airport operations as well as government applications. © 2013 IEEE.},
  affiliation             = {4833 Rugby Avenue, Bethesda, MD 20814, United States},
  art_number              = {6548678},
  correspondence_address1 = {Larsen, T.4833 Rugby Avenue, Bethesda, MD 20814, United States; email: tulinda@masflight.com},
  document_type           = {Conference Paper},
  doi                     = {10.1109/ICNSurv.2013.6548678},
  isbn                    = {9781467362511},
  issn                    = {21554943},
  journal                 = {Integrated Communications, Navigation and Surveillance Conference, ICNS},
  keywords                = {Airport operations; Analysis method; Cross-platform; Hybrid architectures; Integration method; Performance reviews; Real-world problem; Structured data, Aviation; Benchmarking; Data warehouses; Electronic data interchange, Airport security},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883504954&doi=10.1109%2fICNSurv.2013.6548678&partnerID=40&md5=d195e973f1f8237242525362f9062a32},
}

@Book{Haav2013245,
  title               = {Semantic data interoperability: The key problem of big data},
  publisher           = {CRC Press},
  year                = {2013},
  author              = {Haav, H.-M. and Küngas, P.},
  isbn                = {9781466578388; 9781466578371},
  note                = {cited By 2},
  abbrev_source_title = {Big Data Computing},
  abstract            = {Data-intensive applications (social media sites, e-commerce, e-government, e-health, e-science, etc.) are common in our society. They utilize and generate huge volumes of data of different kinds. For example, according to the recent report on Big Data by McKinsey Global Institute, enterprises worldwide stored more than 7 exabytes and consumers stored more than 6 exabytes of new data in 2010 (Manyika et al. 2011). The report also refers to the fact that volume of data created globally is expected to grow exponentially in forthcoming years. As a consequence, the “Big Data” problem has emerged. © 2014 by Taylor & Francis Group, LLC.},
  affiliation         = {Institute of Cybernetics, Tallinn University of Technology, Tallinn, Estonia; Zaporozhye National University, Zaporozhye, Ukraine},
  document_type       = {Book Chapter},
  doi                 = {10.1201/b16014},
  journal             = {Big Data Computing},
  language            = {English},
  pages               = {245-269},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986290936&doi=10.1201%2fb16014&partnerID=40&md5=18b0d4a535d07697fab2274b6bc3e01d},
}

@Conference{Wang2013383,
  author              = {Wang, M. and Nie, T. and Shen, D. and Kou, Y. and Yu, G.},
  title               = {Intelligent similarity joins for big data integration},
  year                = {2013},
  pages               = {383-388},
  publisher           = {IEEE Computer Society},
  note                = {cited By 3},
  abbrev_source_title = {Proc. Web Inf. Syst. Appl. Conf., WISA},
  abstract            = {With the increasing amount of data, the record linkage has become a challenge for big data integration. Similarity join is an efficient approach to address the record linkage, but it is hardly achieved by the single node environment. In this paper, we propose a framework based on MapReduce for set similarity join. The techniques of framework improve the efficiency from two aspects: reducing candidate pairs and load balance. In reducing candidate pairs, we propose algorithms that combines multiple filtering principles to reduce the amount of candidate pairs. It includes length filter, prefix filter and position filter. The techniques for load balance are used to address the skew data and decrease the replication transfer volume. Experimental results on real dataset show that our approaches can achieve the speed-up over previous algorithms on big data. © 2013 IEEE.},
  affiliation         = {College of Information Science and Engineering, Northeastern University, Shenyang, China},
  art_number          = {6778670},
  author_keywords     = {load balance; MapReduce; prefix filter; similarity join},
  document_type       = {Conference Paper},
  doi                 = {10.1109/WISA.2013.79},
  journal             = {Proceedings - 2013 10th Web Information System and Application Conference, WISA 2013},
  keywords            = {Algorithms; World Wide Web, Big datum; Load balance; Map-reduce; prefix filter; Record linkage; Set-similarity joins; Similarity join; Transfer volumes, Data integration},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899087799&doi=10.1109%2fWISA.2013.79&partnerID=40&md5=72d16be17904f37252f107fde6660fc1},
}

@Conference{Knoblock201328,
  author              = {Knoblock, C.A. and Szekely, P.},
  title               = {Semantics for big data integration and analysis},
  year                = {2013},
  volume              = {FS-13-04},
  pages               = {28-31},
  publisher           = {AI Access Foundation},
  note                = {cited By 5},
  abbrev_source_title = {AAAI Fall Symp. Tech. Rep.},
  abstract            = {Much of the focus on big data has been on the problem of processing very large sources. There is an equally hard problem of how to normalize, integrate, and transform the data from many sources into the format required to run large-scale analysis and visualization tools. We have previously developed an approach to semi-automatically mapping diverse sources into a shared domain ontology so that they can be quickly combined. In this paper we describe our approach to building and executing integration and restructuring plans to support analysis and visualization tools on very large and diverse datasets. Copyright © 2013, Association for the Advancement of Artificial Intelligence. All rights reserved.},
  affiliation         = {University of Southern California, Information Sciences Institute, Department of Computer Science, 4676 Admiralty Way, Marina del Rey, CA 90292, United States},
  document_type       = {Conference Paper},
  isbn                = {9781577356424},
  journal             = {AAAI Fall Symposium - Technical Report},
  keywords            = {Semantics; Tools; Visualization, Big datum; Domain ontologies; Hard problems; Large-scale analysis; Restructuring plan; Support analysis; Visualization tools, Data visualization},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898846943&partnerID=40&md5=121e9677da1feb31022a1fcf74fcb209},
}

@Conference{Cruz201319,
  author              = {Cruz, I.F. and Ganesh, V.R. and Mirrezaei, S.I.},
  title               = {Semantic extraction of geographic data from web tables for big data integration},
  year                = {2013},
  pages               = {19-26},
  publisher           = {Association for Computing Machinery},
  note                = {cited By 6},
  abbrev_source_title = {Proc. Workshop Geogr. Inf. Retr., GIR},
  abstract            = {There are millions of web tables with geographic data that are pertinent for big data integration in a variety of domain applications, such as urban sustainability, transportation networks, policy studies, and public health. These tables, however, are heterogeneous in structure, concepts, and metadata. One of the challenges in semantically extracting geographic data is the need to resolve these heterogeneities so as to uncover a conceptual hierarchy, metadata associated with instances, and geographic information|corresponding respectively to ontologies, elements that we call features, and cell values that can be used to identify geographic coordinates. In this paper, we present an architecture with methods to: (1) extract feature-rich web tables; (2) identify features; (3) construct a schema and instances using RDF; (4) perform geocoding. Preliminary experiments led to high accuracy in table identification and feature naming even when compared to manual evaluation.},
  affiliation         = {Department of Computer Science, ADVIS Lab, University of Illinois, Chicago, United States},
  author_keywords     = {Geocoding; Geographic data; GIS; Information extraction; Semantic data integration; Spatial databases; Web tables},
  document_type       = {Conference Paper},
  doi                 = {10.1145/2533888.2533939},
  isbn                = {9781450322416},
  journal             = {Proceedings of the 7th Workshop on Geographic Information Retrieval, GIR 2013},
  keywords            = {Data integration; Data mining; Information retrieval; Metadata, Geo coding; Geographic data; Semantic data; Spatial database; Web tables, Geographic information systems},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893937921&doi=10.1145%2f2533888.2533939&partnerID=40&md5=98a5906429f5e41f596457c0a9f4f07e},
}

@Conference{Qin2012716,
  author                  = {Qin, X. and Wang, H. and Li, F. and Zhou, B. and Cao, Y. and Li, C. and Chen, H. and Zhou, X. and Du, X. and Wang, S.},
  title                   = {Beyond simple integration of RDBMS and MapReduce - Paving the way toward a unified system for big data analytics: Vision and progress},
  year                    = {2012},
  pages                   = {716-725},
  note                    = {cited By 8},
  abbrev_source_title     = {Proc. - Int. Conf. Cloud Green Comput. Int. Conf. Soc. Comput. Its Appl., CGC/SCA},
  abstract                = {MapReduce has shown vigorous vitality and penetrated both academia and industry in recent years. MapReduce not only can be used as an ETL tool, it can do even much more. The technique has been applied to SQL summation, OLAP, data mining, machine learning, information retrieval, multimedia data processing, science data processing etc. Basically MapReduce is a general purpose parallel computing framework for large dataset processing. A big data analytics ecosystem built around MapReduce is emerging alongside the traditional one built around RDBMS. The objectives of RDBMS and MapReduce, as well as the ecosystems built around them, overlap much really, in some sense they do the same thing and MapReduce can accomplish more works, such as graph processing, which RDBMS can not handle well. RBDMS enjoys high performance of relational data processing, which MapReduce needs to catch up. The authors envision that the two techniques are fusing into a unified system for big data analytics. With the ongoing endeavor to build up the system, much of the groundwork has been laid while some critical issues are still unresolved, we try to identify some of them. Two of our works as well as experiment results are presented, one is applying a hierarchical encoding to star schema data in Hadoop for high performance of OLAP processing, another is leveraging the natural three copies of HDFS blocks to exploit different data layouts to speed up queries in a OLAP workload, a cost model is used to route user queries to different data layouts. © 2012 IEEE.},
  affiliation             = {Ministry of Education Key Lab. of Data Engineering and Knowledge Engineering (RUC), Beijing, 100872, China; Sa Shi-Xuan Big Data Management and Analytics Research Center (Sino-Australia), Beijing, 100872, China; School of Information, Renmin University of China, Beijing, 100872, China; EMC Labs. China, 100084, China},
  art_number              = {6382895},
  author_keywords         = {Big Data Analytics; MapReduce; OLAP; RDBMS; Unified System; Vision},
  correspondence_address1 = {Qin, X.; Ministry of Education Key Lab. of Data Engineering and Knowledge Engineering (RUC), Beijing, 100872, China; email: qxp1990@sina.com},
  document_type           = {Conference Paper},
  doi                     = {10.1109/CGC.2012.39},
  isbn                    = {9780769548647},
  journal                 = {Proceedings - 2nd International Conference on Cloud and Green Computing and 2nd International Conference on Social Computing and Its Applications, CGC/SCA 2012},
  keywords                = {Big datum; Map-reduce; OLAP; RDBMS; Unified system, Data processing; Ecosystems; Multiprocessing systems; Parallel architectures; Vision, Data integration},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874625360&doi=10.1109%2fCGC.2012.39&partnerID=40&md5=be2d8d35f42388aa77d41ec3bb9d3573},
}

@Article{Praneenararat2012,
  author                  = {Praneenararat, T. and Takagi, T. and Iwasaki, W.},
  title                   = {Integration of interactive, multi-scale network navigation approach with Cytoscape for functional genomics in the big data era.},
  journal                 = {BMC genomics},
  year                    = {2012},
  volume                  = {13 Suppl 7},
  issn                    = {14712164},
  note                    = {cited By 10},
  abbrev_source_title     = {BMC Genomics},
  abstract                = {The overwhelming amount of network data in functional genomics is making its visualization cluttered with jumbling nodes and edges. Such cluttered network visualization, which is known as "hair-balls", is significantly hindering data interpretation and analysis of researchers. Effective navigation approaches that can always abstract network data properly and present them insightfully are hence required, to help researchers interpret the data and acquire knowledge efficiently. Cytoscape is a de facto standard platform for network visualization and analysis, which has many users around the world. Apart from its core sophisticated features, it easily allows for extension of the functionalities by loading extra plug-ins. We developed NaviClusterCS, which enables researchers to interactively navigate large biological networks of ~100,000 nodes in a "Google Maps-like" manner in the Cytoscape environment. NaviClusterCS rapidly and automatically identifies biologically meaningful clusters in large networks, e.g., proteins sharing similar biological functions in protein-protein interaction networks. Then, it displays not all nodes but only preferable numbers of those clusters at any magnification to avoid creating the cluttered network visualization, while its zooming and re-centering functions still enable researchers to interactively analyze the networks in detail. Its application to a real Arabidopsis co-expression network dataset illustrated a practical use of the tool for suggesting knowledge that is hidden in large biological networks and difficult to be obtained using other visualization methods. NaviClusterCS provides interactive and multi-scale network navigation to a wide range of biologists in the big data era, via the de facto standard platform for network visualization. It can be freely downloaded at http://navicluster.cb.k.u-tokyo.ac.jp/cs/ and installed as a plug-in of Cytoscape.},
  affiliation             = {Department of Computational Biology, University of Tokyo, Kashiwa, Chiba 277-8568, Japan},
  correspondence_address1 = {Praneenararat, T.email: thanet@cb.k.u-tokyo.ac.jp},
  document_type           = {Article},
  doi                     = {10.1186/1471-2164-13-S7-S24},
  keywords                = {Arabidopsis; article; biology; cluster analysis; computer interface; computer program; factual database; gene regulatory network; genetics; genomics; Internet; metabolism, Arabidopsis; Cluster Analysis; Computational Biology; Databases, Factual; Gene Regulatory Networks; Genomics; Internet; Software; User-Computer Interface},
  language                = {English},
  pubmed_id               = {23281970},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878776716&doi=10.1186%2f1471-2164-13-S7-S24&partnerID=40&md5=5c53dfda1d3c9deefd2eda742b9d005d},
}

@Article{Chaturvedi2019,
  author                  = {Chaturvedi, K. and Kolbe, T.H.},
  title                   = {Towards establishing cross-platform interoperability for sensors in smart cities},
  journal                 = {Sensors (Switzerland)},
  year                    = {2019},
  volume                  = {19},
  number                  = {3},
  issn                    = {14248220},
  note                    = {cited By 0},
  abbrev_source_title     = {Sensors},
  abstract                = {Typically, smart city projects involve complex distributed systems having multiple stakeholders and diverse applications. These applications involve a multitude of sensor and IoT platforms for managing different types of timeseries observations. In many scenarios, timeseries data is the result of specific simulations and is stored in databases and even simple files. To make well-informed decisions, it is essential to have a proper data integration strategy, which must allow working with heterogeneous data sources and platforms in interoperable ways. In this paper, we present a new lightweight web service called InterSensor Service allowing to simply connect to multiple IoT platforms, simulation specific data, databases, and simple files and retrieving their observations without worrying about data storage and the multitude of different APIs. The service encodes these observations “on-the-fly” according to the standardized external interfaces such as the OGC Sensor Observation Service and OGC SensorThings API. In this way, the heterogeneous observations can be analyzed and visualized in a unified way. The service can be deployed not only by the users to connect to different sources but also by providers and stakeholders to simply add further interfaces to their platforms realizing interoperability according to international standards. We have developed a Java-based implementation of the InterSensor Service, which is being offered free as open source software. The service is already being used in smart city projects and one application for the district Queen Elizabeth Olympic Park in London is shown in this paper. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.},
  affiliation             = {Technical University of Munich, Arcisstrasse 21, Munich, 80333, Germany},
  art_number              = {562},
  author_keywords         = {Internet of things; Interoperability; OGC standards; Sensor web enablement; Sensors; Smart cities},
  correspondence_address1 = {Chaturvedi, K.; Technical University of Munich, Arcisstrasse 21, Germany; email: kanishk.chaturvedi@tum.de},
  document_type           = {Article},
  doi                     = {10.3390/s19030562},
  keywords                = {Application programming interfaces (API); Data integration; Digital storage; Interoperability; Open source software; Sensors; Simulation platform; Smart city; Web services, Complex distributed system; Heterogeneous data sources; Heterogeneous observations; International standards; Multiple stakeholders; OGC Standards; Sensor observation services; Sensor web enablement, Internet of things},
  language                = {English},
  publisher               = {MDPI AG},
  pubmed_id               = {30700027},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060922032&doi=10.3390%2fs19030562&partnerID=40&md5=c7551b545f40f2d1325de500ad5cdeb5},
}

@Conference{Granda2019375,
  author              = {Granda, F. and Azpilicueta, L. and Vargas-Rosales, C. and Lopez-Iturri, P. and Aguirre, E. and Falcone, F.},
  title               = {Integration of Wireless Sensor Networks in Intelligent Transportation Systems within Smart City Context},
  year                = {2019},
  pages               = {375-376},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {IEEE Antennas Propag. Soc. Int. Symp. USNC/URSI Natl. Radio Sci. Meet., APSURSI - Proc.},
  abstract            = {The use of Vehicular Ad Hoc Networks has been exponentially growing in the last few years. Because of that, it is highly important to conduct previous radio propagation analysis when deploying vehicle-to-vehicle (V2V) or vehicle-to-infrastructure (V2I) networks in urban scenarios, for Intelligent Transportation System (ITS) applications. In this work, the radio wave characterization for an urban infrastructure wireless communication system has been assessed for different frequencies. Two different realistic scenarios in which traffic lights, vehicles, people, buildings, vegetation and urban environment, have been implemented in an in-house 3D Ray Launching code. Results provide radio planning information before the deployment of Wireless Sensor Networks in terms of coverage, capacity and energy efficiency of the network. © 2018 IEEE.},
  affiliation         = {Tecnologico de Monterrey, School of Engineering and Sciences, Monterrey, Mexico; Electrical and Electronic Engineering Dept., Universidad de Las Fuerzas Armadas ESPE, Sangolquí, Ecuador; Electrical and Electronic Engineering Dept., Public University of Navarre, Pamplona, Spain},
  art_number          = {8608746},
  author_keywords     = {3D Ray launching; urban infrastructure; V2I; V2V; wireless networks},
  document_type       = {Conference Paper},
  doi                 = {10.1109/APUSNCURSINRSM.2018.8608746},
  isbn                = {9781538671023},
  journal             = {2018 IEEE Antennas and Propagation Society International Symposium and USNC/URSI National Radio Science Meeting, APSURSI 2018 - Proceedings},
  keywords            = {Energy efficiency; Intelligent systems; Intelligent vehicle highway systems; Mobile telecommunication systems; Radio waves; Smart city; Urban transportation; Vehicles; Vehicular ad hoc networks; Wireless networks, 3d ray launchings; Different frequency; Intelligent transportation systems; Propagation analysis; Urban infrastructure; Vehicle to infrastructure (V2I); Vehicle to vehicles; Wireless communication system, Wireless sensor networks},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061920867&doi=10.1109%2fAPUSNCURSINRSM.2018.8608746&partnerID=40&md5=e565337dbc3182e631e2c824d571b82e},
}

@Article{Brutti201925,
  author                  = {Brutti, A. and de Sabbata, P. and Frascella, A. and Gessa, N. and Ianniello, R. and Novelli, C. and Pizzuti, S. and Ponti, G.},
  title                   = {Smart city platform specification: A modular approach to achieve interoperability in smart cities},
  journal                 = {Internet of Things},
  year                    = {2019},
  pages                   = {25-50},
  issn                    = {21991073},
  note                    = {cited By 1},
  abbrev_source_title     = {Internet Things},
  abstract                = {The development of our cities towards the Smart City paradigm is one of the challenges facing today’s society. This means, among other things, continuously developing and adopting ICT technologies in order to create platforms on which governments, businesses and citizens can communicate and work together and providing the necessary connections between the networks (of people, businesses, technologies, infrastructures, energy and spaces) that are the base for the services of the city. The incredible vastness and diversity of applications that are emerging in this context generates an enormous amount of data of different types and from heterogeneous sources to be shared and exchanged. In this article we propose an approach and describe a methodology and a modular and scalable multi-layered ICT platform to address the problem of cross-domain interoperability in the context of Smart City applications. © Springer International Publishing AG, part of Springer Nature 2019.},
  affiliation             = {Italian National Agency for New Technologies (ENEA), Rome, 00196, Italy; Department of Computer Science and Engineering (DISI), University of Bologna, Bologna, 40126, Italy},
  author_keywords         = {Interoperability; Smart city; Specifications},
  correspondence_address1 = {Pizzuti, S.; Italian National Agency for New Technologies (ENEA)Italy; email: stefano.pizzuti@enea.it},
  document_type           = {Book Chapter},
  doi                     = {10.1007/978-3-319-96550-5_2},
  language                = {English},
  publisher               = {Springer International Publishing},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051749396&doi=10.1007%2f978-3-319-96550-5_2&partnerID=40&md5=a64a50e347e6500517884f8b57b1d17b},
}

@Conference{Anindra201843,
  author              = {Anindra, F. and Warnars, H.L.H.S. and Min, D.M.},
  title               = {Smart City Implementation Modelling in Indonesia with Integration Platform Approach},
  year                = {2018},
  pages               = {43-48},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 1},
  abbrev_source_title = {Proc. Int. Conf. Inf. Manag. Technol., ICIMTech},
  abstract            = {Doing development using Smart City approach has become a necessity. The complexity of the problems facing the government requires a smart solution. Implementation problems of smart city still found in Indonesia, until now still needed a new breakthrough to speed up the implementation process. This paper presents the Integration Platform approach to be an alternative solution for the Smart City implementation model. This open platform concept leverages existing technology resources and applications for shared use. The contribution of this paper is to provide a new alternative solution for policy holders and decisions in government in making smart strategic plans in order to improve the quality of society and public services. © 2018 IEEE.},
  affiliation         = {Computer Science Department, Bina Nusantara University, BINUS Graduate Program-Doctor of Computer Science, Jakarta, 11480, Indonesia; Department of Digital Management, Graduate School of Korea University Seoul, South Korea},
  art_number          = {8528141},
  author_keywords     = {collaboration; implementation model; integration platform; smart city; smart city implementation},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICIMTech.2018.8528141},
  isbn                = {9781538658215},
  journal             = {Proceedings of 2018 International Conference on Information Management and Technology, ICIMTech 2018},
  keywords            = {Information management; Integration, Alternative solutions; collaboration; Implementation models; Implementation process; Integration platform; Public services; Smart solutions; Technology resources, Smart city},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058279425&doi=10.1109%2fICIMTech.2018.8528141&partnerID=40&md5=72c3bb7cd5622d4b4bd30a6348139f58},
}

@Conference{Zabasta201881,
  author              = {Zabasta, A. and Kunicina, N. and Kondratjevs, K. and Patlins, A. and Ribickis, L. and Delsing, J.},
  title               = {MQTT Service Broker for Enabling the Interoperability of Smart City Systems},
  year                = {2018},
  editor              = {Quintal F., Dias F.M.},
  pages               = {81-87},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Energy Sustain. Small Dev. Econ., ES2DE - Proc.},
  abstract            = {Smart city offers a concept of interconnection of modern digital technologies in the context of a city that provides a solution to enhance the quality and performance of urban services. However, interconnection of the Smart city systems still is a challenging process due to incompatibility of systems that apply a plenty of appropriate technical solutions and protocols that cause collaboration between automation devices such as sensors, actuators, controllers. Introduction of Internet-of-Things (IoT) provides promising opportunities to develop new services and integrate different application domains. The Arrowhead Framework aims to apply Service Oriented Architecture to the embedded systems' world. This research is focused on the one of the Arrowhead Framework core systems - Event Handler. This system supports the handling of events, and enriches service-oriented applications with the capabilities of interacting via the publish/subscribe paradigm. We implemented the Event Handler system as a MQTT enabled service broker, and deployed data flow programming tool Node-RED for wiring together divergent hardware devices and nodes, and APIs for online services. A case study of the service broker implemented for control of utilities systems in urban environment is presented and discussed. © 2018 IEEE.},
  affiliation         = {Institute of Industrial Electronics and Electrical Engineering, Riga Technical University, Riga, Latvia; Dept. of Computer Science, Space and Electrical Engineering, Lulea University of Technology, Lulea, Sweden},
  art_number          = {8494341},
  author_keywords     = {Arrowhead Framework core systems; automation; MQTT broker; Smart city systems; SOA; utilities},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ES2DE.2018.8494341},
  isbn                = {9781538680919},
  journal             = {Energy and Sustainability in Small Developing Economies, ES2DE 2018 - Proceedings},
  keywords            = {Automation; Embedded systems; Information services; Internet of things; Service oriented architecture (SOA); Smart city; Sustainable development, Core systems; Dataflow programming; Digital technologies; Internet of Things (IOT); MQTT broker; Service oriented application; Technical solutions; utilities, Interoperability},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056813009&doi=10.1109%2fES2DE.2018.8494341&partnerID=40&md5=5d16ffa7d51f84b386a8792360dd4922},
}

@Conference{Sguglio2018,
  author              = {Sguglio, A. and Arcuri, N. and Bruno, R.},
  title               = {Integration of Social Science in Engineering Research for Smart Cities. the Italian Case of the RES NOVAE Project},
  year                = {2018},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Proc. - IEEE Int. Conf. Environ. Electr. Eng. IEEE Ind. Commer. Power Syst. Europe, EEEIC/I CPS Europe},
  abstract            = {In this paper, the evaluation of the advancement in the analysis and interpretation of the urban sustainability, starting from the transformations involving the current city structural models (building characteristics and distribution, transport network, green areas and water management, the public space systems) and the implementation of suitable systemic planning programs for their management, is carried out. The article specifically analyzes the Italian project RES NOVAE, where the profitable partnership between research, training and interdisciplinary work in the context of the energy transition is encouraging the participation and involvement of citizens in the vision and definition of their Smart City. All these aspects were investigated in a situation in which training, research, technological and social innovation transit through different perspectives of analysis, providing new models of interpretation and application of urban sustainability. © 2018 IEEE.},
  affiliation         = {Energetic and Management Engineering Department, DIMEG-University of Calabria, Arcavacata di Rende (CS), Mechanical, Italy},
  art_number          = {8493774},
  author_keywords     = {demonstrators; Energy fluxes; innovation; interdisciplinary; Smart Cities},
  document_type       = {Conference Paper},
  doi                 = {10.1109/EEEIC.2018.8493774},
  isbn                = {9781538651858},
  journal             = {Proceedings - 2018 IEEE International Conference on Environment and Electrical Engineering and 2018 IEEE Industrial and Commercial Power Systems Europe, EEEIC/I and CPS Europe 2018},
  keywords            = {Smart city; Sustainable development; Urban transportation; Water management, Building characteristics; demonstrators; Energy fluxes; Energy transitions; interdisciplinary; Interdisciplinary work; Social innovations; Urban sustainability, Engineering research},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056552548&doi=10.1109%2fEEEIC.2018.8493774&partnerID=40&md5=57004cc407cda3faac195040048fcee6},
}

@Article{Pradhan2018163,
  author              = {Pradhan, M. and Suri, N. and Fuchs, C. and Bloebaum, T.H. and Marks, M.},
  title               = {Toward an Architecture and Data Model to Enable Interoperability between Federated Mission Networks and IoT-Enabled Smart City Environments},
  journal             = {IEEE Communications Magazine},
  year                = {2018},
  volume              = {56},
  number              = {10},
  pages               = {163-169},
  issn                = {01636804},
  note                = {cited By 0},
  abbrev_source_title = {IEEE Commun Mag},
  abstract            = {The emergence of smart city initiatives in many areas of the world has led to rapid development and proliferation of Internet of Things (IoT) technologies. Successful deployments of IoT have resulted in the military looking at the impacts and benefits of IoT, both for directly leveraging IoT within the military environment as well as to interface with smart city environments for urban operations such as humanitarian assistance and disaster response. This article describes some of the outcomes of the NATO IST-147 Research Task Group that was established to explore the military applications of IoT. Within the NATO context, the concept of federated mission networks (FMNs) enables coalition partners to plan, prepare, establish, use, and terminate mission networks in support of federated operations. In this article, we propose an architecture and data model to enable interoperability between FMN and IoT networks in smart city environments. We review the various bottlenecks involved for such an environment and how a reference implementation can be set up to allow multiple partners to exchange data for sharing resources and provide better situational awareness. The concepts discussed reuse and improvise upon the existing NATO and commercial IoT standards for faster adoption. Finally, open research challenges are discussed as future research directions. © 1979-2012 IEEE.},
  affiliation         = {Institute of Technical Education and Research, Bhubaneswar, India; U.S. Army Research Laboratory, United States; University of Bonn, Germany; Norwegian Defence Research Establishment, Norway; Faculty of Electronics and Information Technology, Warsaw University of Technology, Poland},
  art_number          = {8493137},
  coden               = {ICOMD},
  document_type       = {Article},
  doi                 = {10.1109/MCOM.2018.1800305},
  keywords            = {Interoperability; Military applications; Network architecture; Smart city, Coalition partners; Future research directions; Humanitarian assistances; Internet of Things (IOT); Military environment; Reference implementation; Research challenges; Situational awareness, Internet of things},
  language            = {English},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055326941&doi=10.1109%2fMCOM.2018.1800305&partnerID=40&md5=3fbc35429459e01cdc74798d44c390ec},
}

@Conference{Mikhaylov2018,
  author                  = {Mikhaylov, K. and Stusek, M. and Masek, P. and Petrov, V. and Petajajarvi, J. and Andreev, S. and Pokorny, J. and Hosek, J. and Pouttu, A. and Koucheryavy, Y.},
  title                   = {Multi-RAT LPWAN in Smart Cities: Trial of LoRaWAN and NB-IoT Integration},
  year                    = {2018},
  volume                  = {2018-May},
  publisher               = {Institute of Electrical and Electronics Engineers Inc.},
  note                    = {cited By 1},
  abbrev_source_title     = {IEEE Int Conf Commun},
  abstract                = {The landscape of the contemporary IoT radio access technologies (RATs) is excessively diverse, especially when it comes to such a complex environment as Smart City. On the one hand, this diversity offers operators sufficient flexibility to select the most appropriate RAT for their target application. On the other hand, it becomes a severe limiting factor leading to high level of uncertainty for the IoT device vendors, who need to decide, which technology to support in their hardware. In this paper, we consider the provisioning of the low-power wide area network (LPWAN) devices supporting multiple RATs. First, we briefly discuss the parameters of several potential radio technologies as well as analyze the pros and cons of combining them in a single device. Next, we prototype a real-life device capable of communicating via two perspective LPWAN technologies, namely, LoRaWAN and NB-IoT, and report on the initial results of its performance evaluation. These confirm the feasibility of instrumenting dual-mode devices as well as reveal several important aspects related to the development of multi-radio IoT equipment and its performance. In our view, due to their higher flexibility, reliability, and dependability, the devices such as the one developed can be beneficial for various Smart City applications, with smart energy grids and road traffic control being only two of many examples. © 2018 IEEE.},
  affiliation             = {Centre for Wireless Communications, University of Oulu, Oulu, Finland; Department of Telecommunications, Brno University of Technology, Brno, Czech Republic; Peoples' Friendship University of Russia (RUDN University), Moscow, Russian Federation; Laboratory of Electronics and Communications Engineering, Tampere University of Technology, Tampere, Finland},
  art_number              = {8422979},
  correspondence_address1 = {Mikhaylov, K.; Centre for Wireless Communications, University of OuluFinland; email: konstantin.mikhaylov@oulu.fi},
  document_type           = {Conference Paper},
  doi                     = {10.1109/ICC.2018.8422979},
  isbn                    = {9781538631805},
  issn                    = {15503607},
  journal                 = {IEEE International Conference on Communications},
  keywords                = {Low power electronics; Rats; Smart city; Traffic control; Wide area networks, Complex environments; Dual-mode devices; Performance evaluations; Radio access technologies; Radio technologies; Road traffic control; Smart city applications; Target application, Internet of things},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051442564&doi=10.1109%2fICC.2018.8422979&partnerID=40&md5=c020ef8536382ae5cd11a0d7307a67c7},
}

@Conference{Brutti2018434,
  author              = {Brutti, A. and Frascella, A. and Gessa, N. and De Sabbata, P. and Novelli, C.},
  title               = {Interoperability in the smart city: A semantic approach for merging flexibility with strictness},
  year                = {2018},
  pages               = {434-439},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Proc. - IEEE Int. Conf. Smart Comput., SMARTCOMP},
  abstract            = {The Smart City paradigm is nowadays the main reference for a sustainable and efficient development of our cities. This development requires the creation of ICT infrastructures and applications for the management of the wide amount of data related to many different sectors like Energy, Transport, Safety, Governance, and many others. Thus, the ability to communicate and exchange data is critical for the realization of Smart City. The risk on the other side is the emerging, from different actors, of a plethora of isolated and closed software solutions not able to communicate each other and to collaborate. In this article we present our semantic approach to enable interoperability between cross-domain Smart City applications. It is the result of a path that applied theoretical principles of interoperability to real requirements and opportunities detected in Smart City scenarios. © 2018 IEEE.},
  affiliation         = {ENEA, Bologna, Italy},
  art_number          = {8421399},
  author_keywords     = {Data format; Interoperability; Ontology; Smart city; Specifications},
  document_type       = {Conference Paper},
  doi                 = {10.1109/SMARTCOMP.2018.00042},
  isbn                = {9781538647059},
  journal             = {Proceedings - 2018 IEEE International Conference on Smart Computing, SMARTCOMP 2018},
  keywords            = {Interoperability; Ontology; Semantics; Specifications, Cross-domain; Data format; ICT infrastructures; Semantic approach; Smart city applications; Software solution, Smart city},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051554432&doi=10.1109%2fSMARTCOMP.2018.00042&partnerID=40&md5=1c439c661cb0ca6dea0a1112ac550f36},
}

@Conference{Pradhan2018129,
  author              = {Pradhan, M. and Fuchs, C. and Johnsen, F.T.},
  title               = {A survey of applicability of military data model architectures for smart city data consumption and integration},
  year                = {2018},
  volume              = {2018-January},
  pages               = {129-134},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 2},
  abbrev_source_title = {IEEE World Forum Internet Things, WF-IoT - Proc.},
  abstract            = {The demographic patterns show a rapid influx of human populations to the cities owing to financial, social, medical and other factors. To accommodate the unprecedented rise in population, city administrations around the world are looking for appropriate solutions to cope with the rising challenges. One of the approaches is to make the cities smarter and thus improving the organization, administration and availability of services and resources. In such a Smart City, a large spectrum of deployed sensors and smart objects record, analyse and exchange data. The collected information is processed, forwarded and analyzed in order to implement applications and services that alleviate the city's organization and management or provide additional benefit to the inhabitants. Also with the growing population, it becomes more complex to protect and serve the city's inhabitants and their assets in cases of emergency and adversities such as natural disasters, terrorist and insurgent attacks. In these cases, an existing Smart City infrastructure can greatly assist emergency forces like relief units or supporting military forces by providing the data it already has. In order to incorporate the additional data of the Smart City into the situational picture of the operational forces, suitable points of integration have to be defined and implemented. In this paper, we examine whether existing data models used in the military domain are suitable to integrate the additional Smart City data into the military information domain. In particular, we focus on standardized data models and distribution methods used in federated mission networking within NATO. This ensures a high compatibility to existing situational awareness and information processing applications that are used by the different NATO nations. © 2018 IEEE.},
  affiliation         = {Fraunhofer Institute for Communication, Information Processing and Ergonomics FKIE, Wachtberg, Germany; Norwegian Defence Research Establishment (FFI), Kjeller, Norway},
  author_keywords     = {CitySDK; Interoperability; IoT; MIP; NGVA; SensorML; Sentilo; Smart City},
  document_type       = {Conference Paper},
  doi                 = {10.1109/WF-IoT.2018.8355226},
  isbn                = {9781467399449},
  journal             = {IEEE World Forum on Internet of Things, WF-IoT 2018 - Proceedings},
  keywords            = {Disasters; Internet of things; Interoperability; Population dynamics; Smart city, CitySDK; Information domains; NGVA; Organization and management; Processing applications; SensorML; Sentilo; Situational awareness, Data integration},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050389194&doi=10.1109%2fWF-IoT.2018.8355226&partnerID=40&md5=f7c38a25f0ba933b329e174b224650d0},
}

@Article{Praharaj201835,
  author                  = {Praharaj, S. and Han, J.H. and Hawken, S.},
  title                   = {Urban innovation through policy integration: Critical perspectives from 100 smart cities mission in India},
  journal                 = {City, Culture and Society},
  year                    = {2018},
  volume                  = {12},
  pages                   = {35-43},
  issn                    = {18779166},
  note                    = {cited By 11},
  abbrev_source_title     = {City Cult. Soc.},
  abstract                = {Smart cities commentary often highlights the technological and entrepreneurial aspects of the city. But, the dimensions of local policy and politics is surprisingly little debated. Mega cities in the rapidly urbanising economies develop a plethora of urban policies and plans cultivated by various state and local agencies. These are often overlapping or conflicting and as a result do not produce desired outcomes. Prospective smart cities tend to add a new layer of plan and devise extra institutional instrument in to this already complex environment. We challenge this idea of smart cities being another stand-alone initiative and explore how integration of plans and unification of smart city visions with the overarching city development goals can better support effective urban transformation and local innovation. This research addresses the complex planning and governance mechanisms in the world's fastest growing economy – India - which has initiated an ambitious mission to transform 100 urban areas across the country into “smart cities”. The federal program involves the provision of centrally devised guidelines for smart city development. These combined with local level policy and institutional initiatives in designated smart cities in India shape a multiplicity of policies and programs. A two-level case study is presented in this paper as a critical polemic on this policy landscape. Investigation along these lines provide opportunities for identification of underlying patterns and challenges of smart city developments in India. The paper concludes with a series of recommendations for building sound smart city policy frameworks in emerging economies. © 2017 Elsevier Ltd},
  affiliation             = {Faculty of Built Environment, University of New South Wales, Sydney, NSW 2052, Australia},
  author_keywords         = {100 smart cities mission; Policy integration; Smart cities; Sustainable smart cities reference framework},
  correspondence_address1 = {Praharaj, S.; Faculty of Built Environment, University of New South WalesAustralia; email: sarbeswar.praharaj0905@gmail.com},
  document_type           = {Article},
  doi                     = {10.1016/j.ccs.2017.06.004},
  language                = {English},
  publisher               = {Elsevier Ltd},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021289314&doi=10.1016%2fj.ccs.2017.06.004&partnerID=40&md5=0f4d76a0dada4a880031827ed1150f9a},
}

@Article{Frascella201856,
  author              = {Frascella, A. and Brutti, A. and Gessa, N. and De Sabbata, P. and Novelli, C. and Burns, M. and Bhatt, V. and Ianniello, R. and He, L.},
  title               = {A minimum set of common principles for enabling smart city interoperability},
  journal             = {TECHNE},
  year                = {2018},
  volume              = {SpecialSeries1},
  pages               = {56-61},
  issn                = {22390243},
  note                = {cited By 1},
  abbrev_source_title = {Techne},
  abstract            = {The current investments for smart infrastructure development in cities result in the proliferation of self-consistent and closed applications (often called "silos"), which provide services with strong vertical integration but without ease of mutual horizontal integration. This paper investigates the state of several initiatives addressing this problem. It arrives at a proposal for diminishing and, ideally, breaking down these silos. This vision can be achieved by introducing the idea of building Smart Cities on a common set of architectural principles, Pivotal Points of Interoperability (PPI), and by applying these principles to the definition of a set of open Smart City Platform Specifications. © 2018 Firenze University Press.},
  affiliation         = {Italian National Agency for New Technologies, Energy and Sustainable Economic Development, ENEA, Bologna, Italy; National Institute of Standards and Technology, Gaithersburg, United States; United States Green Building Council, Washington, DC, United States; Department of Computer Science and Engineering, University of Bologna, Italy},
  author_keywords     = {Interoperability; Smart City; Standard},
  document_type       = {Review},
  doi                 = {10.13128/Techne-22739},
  language            = {English},
  publisher           = {Firenze University Press},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056580911&doi=10.13128%2fTechne-22739&partnerID=40&md5=1cf18ada2ea972bd950de776f4d90b8d},
}

@Article{Rech201864,
  author                  = {Rech, A. and Pistauer, M. and Steger, C.},
  title                   = {Increasing Interoperability Between Heterogeneous Smart City Applications},
  journal                 = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year                    = {2018},
  volume                  = {11226 LNCS},
  pages                   = {64-74},
  issn                    = {03029743},
  note                    = {cited By 0},
  abbrev_source_title     = {Lect. Notes Comput. Sci.},
  abstract                = {Due to the increasing need for networked systems we can observe a rapid advance of IT-solutions in various sectors. However, most of the developed systems are custom-tailored solutions for specific problems and application areas, leaving us with a set of diverse frameworks. The resulting jungle of heterogeneous systems makes it difficult to find common interfaces for interconnecting the underlying businesses with each other, especially in regard to Smart City concepts. We envision a new paradigm shift towards “Smart City as a service” fueled by increased interoperability between different services with an additional emphasis on privacy-preserving data processing. This would contribute to a new level of connectivity between the environment, service providers, and people, facilitating our daily activities and enhancing the level of trust of the users. In order to achieve interoperability in the context of smart, connected cities, we propose the design of a generic, platform-independent novel architecture for interconnecting heterogeneous systems, their services, and user pools. © 2018, Springer Nature Switzerland AG.},
  affiliation             = {CISC Semiconductor GmbH, Klagenfurt, 9020, Austria; Graz University of Technology, Graz, 8010, Austria},
  author_keywords         = {Connected services; Data privacy; Interoperability; Smart City},
  correspondence_address1 = {Rech, A.; CISC Semiconductor GmbHAustria; email: a.rech@cisc.at},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-030-02738-4_6},
  editor                  = {Guerrieri A., Jung J.J., Fortino G., Sun J., Xiang Y.},
  isbn                    = {9783030027377},
  keywords                = {Data privacy; Distributed computer systems; Smart city, Connected service; Different services; Heterogeneous systems; Novel architecture; Platform independent; Privacy preserving; Smart city applications; Tailored Solutions, Interoperability},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055636962&doi=10.1007%2f978-3-030-02738-4_6&partnerID=40&md5=34dd13308ef35719d3ce431f096b2f02},
}

@Article{Lodato2018,
  author                  = {Lodato, T. and French, E. and Clark, J.},
  title                   = {Open government data in the smart city: Interoperability, urban knowledge, and linking legacy systems},
  journal                 = {Journal of Urban Affairs},
  year                    = {2018},
  issn                    = {07352166},
  note                    = {cited By 0; Article in Press},
  abbrev_source_title     = {J. Urban Aff.},
  abstract                = {Open government data (OGD) promise to reveal new insights and inform governance decisions related to changing populations, departmental operations, and economic drivers. Yet, where OGD figure prominently in the vision of a smart city, OGD are, in fact, scarce. From production and distribution practices to file types, organizational structure, and repositories, large quantities of potential OGD remain as legacy data trapped in incumbent systems. This article confronts the challenges of legacy data through a constructivist analysis of data wrangling (i.e., converting data into useful formats). The analysis illustrates that wrangling legacy data is more than a rote technical activity. Our findings suggest that smart governance in practice depends on the ways in which social, organizational, and institutional strategies cope with technical change. Further, our research demonstrates that wrangling legacy data is not a discrete problem to overcome but an operating condition defining the rapidly changing landscape of smart governance. © 2018, © 2018 Urban Affairs Association.},
  affiliation             = {Georgia Institute of Technology, United States},
  correspondence_address1 = {Clark, J.; School of Public Policy, Georgia Institute of Technology, 685 Cherry Street, United States; email: jennifer.clark@gatech.edu},
  document_type           = {Article in Press},
  doi                     = {10.1080/07352166.2018.1511798},
  language                = {English},
  publisher               = {Taylor and Francis Ltd.},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055249095&doi=10.1080%2f07352166.2018.1511798&partnerID=40&md5=48d3aa726c49928c34ae08981a8d504e},
}

@Article{Kolyvakis2018146,
  author                  = {Kolyvakis, P. and Mader, C. and Kiritsis, D.},
  title                   = {Semantic interoperability and open IoT APIs for smart cities applications},
  journal                 = {IFIP Advances in Information and Communication Technology},
  year                    = {2018},
  volume                  = {536},
  pages                   = {146-154},
  issn                    = {18684238},
  note                    = {cited By 0},
  abbrev_source_title     = {IFIP Advances in Information and Communication Technology},
  abstract                = {As the percentage of the total population living in urban regions is increasing, new challenges for the cities of the future arise. Smart Cities emerged as a solution to these challenges building on the strength of intelligent information, communication technologies and Internet of Things. In this work, we discuss the importance of semantic technologies as well as open IoT APIs for the future Smart Cities applications. Through an illustrative application, we demonstrate that both of the aforementioned technologies ease the computational burden of implementation, foster programming sustainability and create the necessary conditions so as to rapidly harness the available information and extract knowledge out of it. At the same time, the application’s implementation lies in accordance with the latest IoT architectural recommendations such as Visual Programming interfaces for Service Composition, conformance with Big Data technologies and the latest IoT programming paradigms. © 2018, IFIP International Federation for Information Processing.},
  affiliation             = {École Polytechnique Fédérale de Lausanne (EPFL), Lausanne, Switzerland; Fraunhofer Institute for Intelligent Analysis and Information Systems (IAIS), St. Augustin, Germany},
  author_keywords         = {Open APIs; Semantic interoperability; Smart cities applications},
  correspondence_address1 = {Kolyvakis, P.; École Polytechnique Fédérale de Lausanne (EPFL)Switzerland; email: prodromos.kolyvakis@epfl.ch},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-319-99707-0_19},
  editor                  = {von Cieminski G., Lee G.M., Kiritsis D., Moon I., Park J.},
  isbn                    = {9783319997063},
  keywords                = {Big data; Computer programming; Industrial management; Interoperability; Semantics; Smart city, Big data technologies; Communication technologies; Computational burden; Intelligent information; Open APIs; Programming paradigms; Semantic interoperability; Semantic technologies, Internet of things},
  language                = {English},
  publisher               = {Springer New York LLC},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053277420&doi=10.1007%2f978-3-319-99707-0_19&partnerID=40&md5=c239765367bb3cc69bbce032b2bab8e9},
}

@Article{Peoples201838,
  author                  = {Peoples, C.},
  title                   = {A Standardizable Network Architecture Supporting Interoperability in the Smart City Internet of Things},
  journal                 = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
  year                    = {2018},
  volume                  = {242},
  pages                   = {38-45},
  issn                    = {18678211},
  note                    = {cited By 0},
  abbrev_source_title     = {Lect. Notes Inst. Comput. Sci. Soc. Informatics Telecommun. Eng.},
  abstract                = {An increase of 2.5 billion people is expected in urban areas by 2050, when 66% of the world population will reside here. It is therefore reasonable to assume a parallel growth in the smart city Internet of Things (IoT). A challenge, however, is presented in the interoperability between the devices deployed, limited due to the ad hoc and proprietary ways which systems have been rolled out to date. A standardized network infrastructure specific to the IoT can work towards resolving the challenges. This approach to operation, however, raises questions with regard to how an architecture may support different devices and applications simultaneously, and additionally be extensible to accommodate applications and devices not available at the time of the framework’s development. In this paper, these questions are explored, and an IoT infrastructure which accommodates the interoperability communication constraints and challenges today is proposed. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.},
  affiliation             = {Ulster University, Cromore Road, Coleraine, BT52 1SA, United Kingdom},
  author_keywords         = {Context data; Internet of Things (IoT) interoperability; Network protocols; Quality of Service (QoS); Smart city; Standardization},
  correspondence_address1 = {Peoples, C.; Ulster University, Cromore Road, United Kingdom; email: c.peoples@ulster.ac.uk},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-319-93797-7_5},
  editor                  = {Palau C.E., Cuppens N., Cuppens F., Gabillon A., Fortino G., Guerrieri A., Chaouchi H.},
  isbn                    = {9783319937960},
  keywords                = {Interoperability; Network architecture; Network protocols; Quality of service; Smart city; Standardization, Communication constraints; Context data; Internet of Things (IOT); Network infrastructure; Parallel growth; Urban areas; World population, Internet of things},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051059059&doi=10.1007%2f978-3-319-93797-7_5&partnerID=40&md5=29cf3cb843a84f71fd6053716e93cf86},
}

@Article{Alam2018,
  author                  = {Alam, M. and Moroni, D. and Pieri, G. and Tampucci, M. and Gomes, M. and Fonseca, J. and Ferreira, J. and Leone, G.R.},
  title                   = {Corrigendum: Real-time smart parking systems integration in distributed ITS for smart cities (Journal of Advanced Transportation (2018) 2018 (1485652) DOI: 10.1155/2018/1485652)},
  journal                 = {Journal of Advanced Transportation},
  year                    = {2018},
  volume                  = {2018},
  issn                    = {01976729},
  note                    = {cited By 0},
  abbrev_source_title     = {J Adv Transp},
  abstract                = {In the article titled "Real-Time Smart Parking Systems Integration in Distributed ITS for Smart Cities" [1], Dr. Giuseppe Riccardo Leone was missing from the authors' list. Dr. Leone partially contributed in the designing of the study and mainly in the preparation, programming, and execution of the algorithms regarding the field trials and tests. He contributed in obtaining and analyzing the data. He corrected authors' list is shown above and updated in place. © 2018 Muhammad Alam et al.},
  affiliation             = {Instituto de Telecomunicações, Universidade de Aveiro, Portugal; Institute of Information Science and Technologies, National Research Council of Italy, Pisa, Italy; Micro I/O, Sistemas Electrónicos, Lda, Aveiro, Portugal},
  art_number              = {3437278},
  coden                   = {JATRD},
  correspondence_address1 = {Pieri, G.; Institute of Information Science and Technologies, National Research Council of ItalyItaly; email: gabriele.pieri@isti.cnr.it},
  document_type           = {Erratum},
  doi                     = {10.1155/2018/3437278},
  language                = {English},
  publisher               = {Hindawi Limited},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059955742&doi=10.1155%2f2018%2f3437278&partnerID=40&md5=6569c3740f87e7785779905d624d0f3b},
}

@Article{Ferraris2018,
  author                  = {Ferraris, A. and Belyaeva, Z. and Bresciani, S.},
  title                   = {The role of universities in the Smart City innovation: Multistakeholder integration and engagement perspectives},
  journal                 = {Journal of Business Research},
  year                    = {2018},
  issn                    = {01482963},
  note                    = {cited By 0; Article in Press},
  abbrev_source_title     = {J. Bus. Res.},
  abstract                = {During the past decades cities may have finally shaped the demand for “smart” and sustainable innovations calling for deep stakeholders' integration and engagement within Smart City Projects (SCPs). In this context, Universities are often involved with different tasks, but their stakeholder engagement and integrator role is still unclear. This paper aims to fulfill this gap on the role of Universities in SCPs utilising bottom-up collected quantitative and qualitative data. We found positive trend in University integrator role applying a mixed two-step methodology based on online survey of University students and interviews with decision-making stakeholders involved in SCPs (business, state, entrepreneurs and academia) in Italy and Russia. Our findings suggest significant new insights useful to reapply the mediating role of Universities and to highlight some newly arising opportunities in stakeholder engagement. At the same time, we propose related practical implications in the field of entrepreneurship and innovation defining further directions under the lens of multistakeholder management. © 2018 Elsevier Inc.},
  affiliation             = {Department of Management, University of Torino, Italy; Research Fellow of the Laboratory for International and Regional Economics, Graduate School of Economics and Management, Ural Federal University, Russian Federation; Graduate School of Economics and Management, Ural Federal University, Russian Federation},
  author_keywords         = {Smart City; Smart City projects; Stakeholder engagement; Stakeholder management; Students' perceptions; Triple Helix; University; University role},
  coden                   = {JBRED},
  correspondence_address1 = {Ferraris, A.; Department of Management, University of TorinoRussian Federation; email: alberto.ferraris@unito.it},
  document_type           = {Article in Press},
  doi                     = {10.1016/j.jbusres.2018.12.010},
  language                = {English},
  publisher               = {Elsevier Inc.},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057623314&doi=10.1016%2fj.jbusres.2018.12.010&partnerID=40&md5=208c13e3c5e47b508fe045dab10329ba},
}

@Conference{Cecílio2018416,
  author                  = {Cecílio, J. and Caldeira, F. and Wanzeller, C.},
  title                   = {CityMii - An integration and interoperable middleware to manage a Smart City},
  year                    = {2018},
  editor                  = {Shakshuki E., Yasar A.},
  volume                  = {130},
  pages                   = {416-423},
  publisher               = {Elsevier B.V.},
  note                    = {cited By 0},
  abbrev_source_title     = {Procedia Comput. Sci.},
  abstract                = {Modern cities are supported by multiple heterogeneous IT systems deployed and managed by distinct agents. In general, those systems use old, dependent and non-standardized technologies, which make them legacy and incompatible systems. As smart cities are moving toward a fully centralized management approach, the lack of integration among systems raises several problems. Since they are independent, it is not easy to correlate information from different systems and put it together to work in order to achieve application goals. The collaboration among different systems enables an agent to offer new functionalities (services or just information about the city) that cannot be provided by any of these systems working as individual entities. The goal of this paper is to propose an integration middleware to support the management of Smart Cities in a dynamic, transparent and scalable way. The proposed middleware intends to support interoperability among different systems operating in a city. © 2018 The Authors. Published by Elsevier B.V.},
  affiliation             = {University of Lisbon, Lisbon, Portugal; University of Coimbra, Coimbra, Portugal; Polytechnic Institute of Viseu, Viseu, Portugal},
  author_keywords         = {Integration; Interoperability; Middleware; Smart Cities},
  correspondence_address1 = {Cecílio, J.; University of LisbonPortugal; email: jmcecilio@fc.ul.pt},
  document_type           = {Conference Paper},
  doi                     = {10.1016/j.procs.2018.04.062},
  issn                    = {18770509},
  journal                 = {Procedia Computer Science},
  keywords                = {Integration; Legacy systems; Middleware; Smart city, Centralized management; Incompatible systems; Integration middlewares; IT system, Interoperability},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051251606&doi=10.1016%2fj.procs.2018.04.062&partnerID=40&md5=a0c51a3082a440c0e7769b3ff6c7922d},
}

@Article{Tonev2018289,
  author                  = {Tonev, K. and Kappe, S. and Krahtova, P. and Wicaksono, H. and Ovtcharova, J.},
  title                   = {District-scale data integration by leveraging semantic web technologies: A case in smart cities},
  journal                 = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year                    = {2018},
  volume                  = {10697 LNCS},
  pages                   = {289-292},
  issn                    = {03029743},
  note                    = {cited By 0},
  abbrev_source_title     = {Lect. Notes Comput. Sci.},
  abstract                = {Technologies of the Semantic Web stack promise to alleviate some of the challenges related to data integration on a massive scale and high level of heterogeneity. This paper explores their application in the smart cities domain with a focus on energy efficient districts. We develop an ontology grounded in several well-established vocabularies to leverage their shared semantics and facilitate data interoperability and we apply the developed ontology to integrate state-of-the-art energy simulation facilities into a general district-level monitoring framework. © Springer International Publishing AG 2018.},
  affiliation             = {Karlsruhe Institute of Technology, Institute for Information Management in Engineering, Zirkel 2, Karlsruhe, Germany},
  author_keywords         = {Building energy simulation; Ontology alignment; Semantic data integration; Smart cities},
  correspondence_address1 = {Kappe, S.; Karlsruhe Institute of Technology, Institute for Information Management in Engineering, Zirkel 2, Germany; email: simon.kappe@kit.edu},
  document_type           = {Conference Paper},
  editor                  = {Ciuciu I., Vidal M., Debruyne C., Panetto H., Bollen P., Meersman R., Weichhart G.},
  isbn                    = {9783319738048},
  keywords                = {Application programs; Energy efficiency; Interoperability; Ontology; Semantic Web; Smart city, Building energy simulations; Data interoperability; Energy simulation; Monitoring frameworks; Ontology alignment; Semantic data; Semantic Web technology; State of the art, Data integration},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045332385&partnerID=40&md5=fbc08bd25c7500a63bfd823f428da45f},
}

@Conference{Ahn2017984,
  author              = {Ahn, J.-Y. and Lee, H.-W. and Huh, J.-D. and Hwang, D.J.},
  title               = {A composite structure of ICT for smart city: Integration infrastructure and collaboration platform},
  year                = {2017},
  volume              = {2017-December},
  pages               = {984-989},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Int. Conf. Inf. Commun. Technol. Converg.: ICT Converg. Technolo. Lead. Fourth Ind. Revolut., ICTC},
  abstract            = {The urban development vision that is 'smart city' is fast becoming a target of modern cities. However, it is hard to find a novel reference model and structural framework to help with the effective and efficient realization of such a vision. This paper puts forward a smart city structural framework in an attempt to address this problem. The suggested framework is based upon two distinctive modelling approaches to design ICT functions to plan a smart city, which in turn is derived from a general model of city spaces and infrastructures. Two modelling approaches are compared by its pros and cons, to combine selectively the promising features together with to derive a novel architecture of ICT function structure for a smart city. A composite model derived through the combinatorial work supports not only the planning of a smart city at a manageable level of granularity (infrastructures) but also the handling of heterogeneous management issues (cross governance and collaboration) to provide convergence services of a smart city. © 2017 IEEE.},
  affiliation         = {Hyperconnectivity Source Research Department, ETRI, Yusung, Deajeon, South Korea; Media Research Department, ETRI, Yusung, Deajeon, South Korea; Dept. of Information and Communication, SungKyunKwan University, Suwon, South Korea},
  author_keywords     = {city infrastructure; collaboration platform; interoperability; smart city; trust interworking},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICTC.2017.8190832},
  isbn                = {9781509040315},
  journal             = {International Conference on Information and Communication Technology Convergence: ICT Convergence Technologies Leading the Fourth Industrial Revolution, ICTC 2017},
  keywords            = {Interoperability; Urban growth, city infrastructure; Collaboration platforms; Composite modeling; Convergence services; Function structures; Interworking; Novel architecture; Structural frameworks, Smart city},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046892376&doi=10.1109%2fICTC.2017.8190832&partnerID=40&md5=23e448c1eb28c645fcd834763e25c13d},
}

@Article{Robert2017,
  author                  = {Robert, J. and Kubler, S. and Kolbe, N. and Cerioni, A. and Gastaud, E. and Främling, K.},
  title                   = {Open IoT ecosystem for enhanced interoperability in smart cities-example of métropole de lyon},
  journal                 = {Sensors (Switzerland)},
  year                    = {2017},
  volume                  = {17},
  number                  = {12},
  issn                    = {14248220},
  note                    = {cited By 9},
  abbrev_source_title     = {Sensors},
  abstract                = {The Internet of Things (IoT) has promised a future where everything gets connected. Unfortunately, building a single global ecosystem of Things that communicate with each other seamlessly is virtually impossible today. The reason is that the IoT is essentially a collection of isolated “Intranets of Things”, also referred to as “vertical silos”, which cannot easily and efficiently interact with each other. Smart cities are perhaps the most striking examples of this problem since they comprise a wide range of stakeholders and service providers who must work together, including urban planners, financial organisations, public and private service providers, telecommunication providers, industries, citizens, and so forth. Within this context, the contribution of this paper is threefold: (i) discuss business and technological implications as well as challenges of creating successful open innovation ecosystems, (ii) present the technological building blocks underlying an IoT ecosystem developed in the framework of the EU Horizon 2020 programme, (iii) present a smart city pilot (Heat Wave Mitigation in Métropole de Lyon) for which the proposed ecosystem significantly contributes to improving interoperability between a number of system components, and reducing regulatory barriers for joint service co-creation practices. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.},
  affiliation             = {Interdisciplinary Center for Security, Reliability and Trust, University of Luxembourg, 29 Avenue J.F. Kennedy, Luxembourg, Luxembourg; Université de Lorraine, CRAN, UMR 7039, 2 Avenue de la forêt de Haye, Vandoeuvre-lès-Nancy CEDEX, 54516, France; CNRS, CRAN, UMR 7039, France; Direction de l’Innovation Numérique et Systèmes d’Information Métropole de Lyon, 20 rue du Lac, CS 33569, Lyon CEDEX 3, 69505, France; School of Science and Technology, Aalto University, P.O. Box 15500, Aalto, 00076, Finland},
  art_number              = {2844},
  author_keywords         = {API economy; Business ecosystem; Communication standards; Internet of Things; Interoperability; Open innovation; Semantic web; Smart city},
  correspondence_address1 = {Robert, J.; Interdisciplinary Center for Security, Reliability and Trust, University of Luxembourg, 29 Avenue J.F. Kennedy, Luxembourg; email: jeremy.robert@uni.lu},
  document_type           = {Article},
  doi                     = {10.3390/s17122849},
  keywords                = {Ecology; Ecosystems; Innovation; Internet service providers; Interoperability; Semantic Web; Smart city, API economy; Business ecosystem; Communication standards; Internet of thing (IOT); Open innovation; Regulatory barriers; System components; Telecommunication providers, Internet of things},
  language                = {English},
  publisher               = {MDPI AG},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037739919&doi=10.3390%2fs17122849&partnerID=40&md5=996cff26999c0a2e21991b17c88349be},
}

@Conference{Ceuca20171,
  author              = {Ceuca, E. and Tulbure, A.},
  title               = {Home automation for increasing the quality of life and integration with the smart city},
  year                = {2017},
  volume              = {2017-January},
  pages               = {1-4},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Proc. Int. Conf. Electron., Comput. Artif. Intell., ECAI},
  abstract            = {The municipality of Alba Iulia intend to manage the energy needed for promoting a decent level of life, and in the same time avoiding waste of energy. The approach is part of the ample project through which the municipality wants to turn Alba Iulia into "Smart City". The main objective of reducing CO2 emissions up to 24% until 2020 relative to the amount of emissions evaluated for the reference year 2008, need sustained involvement for the reduction of emissions in private homes. This paper presents the experimental case study performed in "1 DECEMBRIE 1918" University for simulate and measure the power consumption in one residential area. © 2017 IEEE.},
  affiliation         = {Department of Applied Electronics, 1 December 1918 University, Alba Iulia, Romania},
  author_keywords     = {Energy measurment; Home automation; Quality of life; Smart city},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ECAI.2017.8166440},
  isbn                = {9781509064571},
  journal             = {Proceedings of the 9th International Conference on Electronics, Computers and Artificial Intelligence, ECAI 2017},
  keywords            = {Artificial intelligence, Home automation; Measurment; Quality of life; Reducing co2 emissions; Reduction of emissions; Residential areas, Smart city},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043312406&doi=10.1109%2fECAI.2017.8166440&partnerID=40&md5=7438e06681102a6f6d46bf01a3dd1bdf},
}

@Conference{Rodrigues2017227,
  author              = {Rodrigues, D.O. and Boukerche, A. and Silva, T.H. and Loureiro, A.A.F. and Villas, L.A.},
  title               = {SMAFramework urban data integration framework for mobility analysis in smart cities},
  year                = {2017},
  volume              = {2017-November},
  pages               = {227-236},
  publisher           = {Association for Computing Machinery, Inc},
  note                = {cited By 2},
  abbrev_source_title = {MSWiM - Proc. ACM Int. Conf. ModelL., Anal.s Simul. Wirel. Mob. Syst.},
  abstract            = {Smart cities emerge as a topic to cover how the technology of information and communication can be used in the urban centers to monitor its dynamics and allow the improvement of services for the citizens. In these urban centers, different methodologies are used in order to collect data and provide them to applications. These data come from several heterogeneous sources, thus there is an effort to integrate and standardize them before their use. Also, a significant amount of this data has spatio-temporal annotations, which may be used to analyze the city dynamics, such as the mobility flow. Due to these characteristics of the data generated in urban centers, and also the possibilities brought by their use and analyses, this work presents a novel approach to collect, integrate and perform some analysis tasks in mobility data from smart cities. Thus, the SMAFramework can analyze mobility patterns based on a Multi-Aspect Graph (MAG) data structure. To show the potential of the framework, it is proposed a method to analyze the saptio-temporal correlation between data from two different data sources in the same city. Real data collected from social media and a taxi system of the city of New York are used to evaluate this method. The obtained results allowed to understand some of the applicabilities of the framework and also provided some insights on how to use the framework to resolve specific problems when analyzing mobility in urban environments. © 2017 ACM.},
  affiliation         = {University of Campinas, Campinas, Brazil; University of Ottawa, Ottawa, Canada; School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, Canada; Dept. of Informatics, Federal University of Technology of Paraná, Curitiba, Brazil; Dept of Computer Science, Federal University of Minas Gerais, Belo Horizonte, Brazil; Institute of Computing, University of Campinas, Campinas, Brazil},
  author_keywords     = {Big Data; Mobility Analysis; Smart Cities; Urban Data},
  document_type       = {Conference Paper},
  doi                 = {10.1145/3127540.3127569},
  isbn                = {9781450351645},
  journal             = {MSWiM 2017 - Proceedings of the 20th ACM International Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems},
  keywords            = {Data integration; Smart city; Taxicabs, Heterogeneous sources; Information and communication; Integration frameworks; Mobility analysis; Specific problems; Temporal correlations; Urban Data; Urban environments, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052762202&doi=10.1145%2f3127540.3127569&partnerID=40&md5=7596a8e7b4cf0c575c58bb3fda21c5e1},
}

@Article{Lu2017186,
  author                  = {Lu, W.},
  title                   = {Research on the construction of coastal regional smart cities in the process of Jing-jin-ji integration},
  journal                 = {Boletin Tecnico/Technical Bulletin},
  year                    = {2017},
  volume                  = {55},
  number                  = {18},
  pages                   = {186-193},
  issn                    = {0376723X},
  note                    = {cited By 0},
  abbrev_source_title     = {Boletin Tecnico},
  abstract                = {With the application of Internet of things, cloud computing, optical network and other advanced technologies in urban planning, smart city has become a new form of future city development. In this paper, the author analyse the construction of coastal regional smart cities in the process of jing-jin-ji integration. Coastal area has its unique advantages in building smart city with its favourable location, strong economic strength and innovative ideas. From the spatial layout of the jing-jin-ji smart city pilot work, the first batch of pilot projects is concentrated in the regional centre or the coastal zone. By analysing the technical application of the intelligent city, the author puts forward the corresponding design method of smart city, and the smart city should be combined with the view of sustainable development.},
  affiliation             = {Hebei University of Environmental Engineering, Hebei Qinhuangdao, China},
  author_keywords         = {Coastal areas; Information platform; Internet of things; Smart city; Spatial distribution},
  correspondence_address1 = {Lu, W.; Hebei University of Environmental EngineeringChina},
  document_type           = {Article},
  keywords                = {Coastal zones; Distributed computer systems; Internet of things; Spatial distribution; Urban growth, Advanced technology; Coastal area; Economic strength; Information platform; Innovative ideas; Regional centres; Spatial layout; Technical applications, Smart city},
  language                = {English},
  publisher               = {Universidad Central de Venezuela},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038862522&partnerID=40&md5=eb4da6f4776be2c537793be28b5ca666},
}

@Conference{Sharma2017,
  author              = {Sharma, A. and Acharya, S. and Rajaraman, V. and Ramesh, R. and Babu, A. and Amrutur, B.},
  title               = {Poster abstract: Schemas for IoT interoperability for smart cities},
  year                = {2017},
  editor              = {Eskicioglu R.},
  volume              = {2017-January},
  publisher           = {Association for Computing Machinery, Inc},
  note                = {cited By 0},
  abbrev_source_title = {BuildSys - Proc. ACM Int. Conf. Syst. Energy-Efficient Built Environ.},
  abstract            = {One of the key aspects of smart city ecosystem is enabling easy collection and exchange of data to develop new applications. Providing good, open API’s for smart city middleware along with standar-dising the data schemas will be vital for application and device ecosystem to evolve. In this paper we present the resource catalog component of the middleware along with a framework to develop data schemas for IoT devices. Using data schemas one can provide meta-data which enables effective use of the device data. © 2017 Copyright held by the owner/author(s).},
  affiliation         = {RBCCPS, IISc, Bangalore, India},
  document_type       = {Conference Paper},
  doi                 = {10.1145/3137133.3141466},
  isbn                = {9781450354769},
  journal             = {BuildSys 2017 - Proceedings of the 4th ACM International Conference on Systems for Energy-Efficient Built Environments},
  keywords            = {Application programming interfaces (API); Ecosystems; Internet of things; Middleware; Smart city, Device data; Iot devices; New applications; Open API, Energy efficiency},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050457174&doi=10.1145%2f3137133.3141466&partnerID=40&md5=2ea8025af3e9b497ed1feecf586be79a},
}

@Conference{Souza2017,
  author              = {Souza, A. and Pereira, J. and Oliveira, J. and Trindade, C. and Cavalcante, E. and Cacho, N. and Batista, T. and Lopes, F.},
  title               = {A data integration approach for smart cities: The case of natal},
  year                = {2017},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 5},
  abbrev_source_title = {Int. Smart Cities Conf., ISC2},
  abstract            = {Making cities smarter is usually achieved through Information and Communication Technology (ICT)-intensive solutions, which can be employed to collect and analyze large amounts of information generated by several sources, such as sensor networks, traffic systems, and citizens' devices. However, integrating different technologies and information to build smart city applications and services remain a challenge as different sources of heterogeneous data need to be considered. These data can be also enriched with geospatial information, thereby generating cross-sector value-Added information while contributing to better planning actions in the urban space. In this context, we introduce a data integration approach upon Smart Geo Layers, a geospatial-based data middleware aimed to unify data provided by several sources in smart city environments. Along with geo-graphical information regarding the city physical space, Smart Geo Layers provides aggregation, visualization, and data analysis functionalities. In this paper, we describe the Smart Geo Layers middleware, its implementation, and its application through an urban planning application within the smart city initiative of Natal, Brazil. © 2017 IEEE.},
  affiliation         = {Federal University of Rio Grande Do Norte (UFRN), Natal, Brazil},
  art_number          = {8090820},
  author_keywords     = {data middleware; FIWARE; geospatial information; smart cities; urban planning},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ISC2.2017.8090820},
  isbn                = {9781538625231},
  journal             = {2017 International Smart Cities Conference, ISC2 2017},
  keywords            = {Data integration; Data visualization; Middleware; Sensor networks; Urban planning, FIWARE; Geo-spatial informations; Graphical information; Heterogeneous data; Information and Communication Technologies; Integration approach; Planning applications; Value-added information, Smart city},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039949326&doi=10.1109%2fISC2.2017.8090820&partnerID=40&md5=6b06153b25dcf99307a79c4cfcf20b84},
}

@Conference{Ma2017,
  author              = {Ma, Z. and Lu, D. and Liu, Q. and Wang, J. and Xiong, Z.},
  title               = {City-Eyes: A multi-source data integration basec smart city analysis system},
  year                = {2017},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 1},
  abbrev_source_title = {IEEE Int. Symp. World Wirel., Mob. Multimed. Networks, WoWMoM - Conf.},
  abstract            = {The project named after City-Eyes is based on the HBASE big data analyzing platform and the real-time-display technology with H5/CSS3, which could analyze data and result dynamically. The project is devoted to designing the online city-data-analyzing platform, with interacting in real time, filtering, analyzing and displaying data. In the view of filtering, we sample Wuxi and collect much information, including phone signaling, railway, airports, Weibo, population mobility and etc. Moreover, we write enough data mining scripts for varieties of data to extract the value of them. In the view of analyzing, we build an efficient analyzing model, which divides the task into two parts, which includes the front end and the back end. The back end is focusing on compressing data and extracting valid information by clustering the data streams. At the same time, the front-end applies the real-time-display technology to provide an interactive and nice-looking data visualizing solution for our users [1]. In the view of displaying, we come up with various solutions from two angles for every variety of data: 'distribution and network'. With svg/canvas animation tech, the data can be mixed into the map and display itself dynamically [2]. © 2017 IEEE.},
  affiliation         = {School of Computer Science and Information Technology, Beijing Jiaotong University, Beijing, 100044, China; School of Computer Science and Engineering, Beihang University, Beijing, 100191, China},
  art_number          = {7974332},
  document_type       = {Conference Paper},
  doi                 = {10.1109/WoWMoM.2017.7974332},
  isbn                = {9781538627228},
  journal             = {18th IEEE International Symposium on A World of Wireless, Mobile and Multimedia Networks, WoWMoM 2017 - Conference},
  keywords            = {Big data; Data integration; Display devices; Information filtering; Population statistics; Smart city, Analysis system; Analyzing models; Data stream; Front end; Multi-source data integrations; Real time; Real time display, Data mining},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027590474&doi=10.1109%2fWoWMoM.2017.7974332&partnerID=40&md5=7a7c4bc7367a323fc619eb4c0729be2d},
}

@Conference{Auger201788,
  author              = {Auger, A. and Exposito, E. and Lochin, E.},
  title               = {IQAS: An integration platform for QoI assessment as a service for smart cities},
  year                = {2017},
  pages               = {88-93},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 2},
  abbrev_source_title = {IEEE World Forum Internet Things, WF-IoT},
  abstract            = {While reducing costs and improving sustainability, a common goal for Smart Cities is to become more 'liveable' for their citizens. By taking advantage of new information sources offered by the Internet of Things (IoT), cities can rely on sensing platforms to improve their service offer. These sensing platforms, however, raise new research challenges, in particular regarding Quality of Information (QoI). To cope with this issue, common platforms generally provide quality-oriented internal mechanisms. Nevertheless, the configuration of such platforms is complex, especially for Smart City stakeholders that may have various skill levels and different areas of expertise. As a result, QoI assessment is often delegated to end applications where developers have to implement their own adaptation mechanisms. This paper proposes and describes iQAS, an integration platform for QoI Assessment as a Service for Smart Cities. iQAS is autonomic, extensible and configurable, allowing Smart City stakeholders to collaboratively assess and improve (when possible) QoI in real-time. While the platform development is at its early stages, we illustrate within a concrete case study the need for QoI assessment and the benefits to implement adaptation mechanisms. © 2016 IEEE.},
  affiliation         = {Institut Supérieur de l'Aéronautique et de l'Espace (ISAE-SUPAERO), Université de Toulouse, Toulouse Cedex 4, 31055, France; Laboratoire Informatique de l'Université de Pau et des Pays de l'Adour (LIUPPA), France},
  art_number          = {7845400},
  author_keywords     = {Autonomic Computing; Cloud; integration platform; Internet of Things; Quality of Information; Smart City},
  document_type       = {Conference Paper},
  doi                 = {10.1109/WF-IoT.2016.7845400},
  isbn                = {9781509041305},
  journal             = {2016 IEEE 3rd World Forum on Internet of Things, WF-IoT 2016},
  keywords            = {Clouds; Integration; Internet of things, Adaptation mechanism; Autonomic Computing; Information sources; Integration platform; Internet of thing (IOT); Platform development; Quality of information; Quality of informations (QoI), Smart city},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015215154&doi=10.1109%2fWF-IoT.2016.7845400&partnerID=40&md5=d1c84d6ae1511854c7ad966144a166df},
}

@Conference{Lamb2017536,
  author              = {Lamb, B. and Peery, J. and Grubbs, M. and O’Keeffe, P. and Walden, V.},
  title               = {Urbanova: Integration of smart city sensors and air quality modeling in a western US city},
  year                = {2017},
  editor              = {Castelli S.T., Di Sabatino S., Brattich E.},
  volume              = {2017-October},
  pages               = {536-540},
  publisher           = {Hungarian Meteorological Service},
  note                = {cited By 0},
  abbrev_source_title = {HARMO - Int. Conf. Harmon. Atmos. Dispers. Model. Regul. Purp., Proc.},
  abstract            = {Urbanova is a consortium of university, city, public utility companies and other urban partners focused on the development of smart city technologies to promote community and individual well-being and health in an area located near central Spokane, WA, USA. This portion of the Spokane urban area exhibits a gradient of landuse types encompassing a modern university district, a growing commercial area, and low-to-medium income residential neighborhoods. This urban area is bisected by the I-90 freeway and a major railroad line along with a network of busy arterial and surface streets. In this paper, we describe the initial deployment of a network of smart sensors for air quality and related parameters and use results from this network to inform a high resolution urban modeling system: ENVI-Met. The initial sensors include measurements of CO2, PM2.5, temperature, humidity, and pressure using novel, inexpensive small sensors deployed in smart streetlights. In this paper, the urban computational fluid dynamics model, ENVI-Met is used with sensor data for PM2.5 to estimate roadway PM emissions. This is a first step toward an integrated, multi-scale measurement and modeling system for Urbanova including more than a dozen sensors, a research grade reference monitoring site, the AIRPACT air quality forecast system operating with 4 km and 1.3 km grid sizes, and high resolution WRF-Urban modeling. © 2018 Hungarian Meteorological Service. All Rights Reserved.},
  affiliation         = {Laboratory for Atmospheric Research, Washington State University, Pullman, WA, United States; Willamette University, Salem, OR, United States},
  author_keywords     = {Air quality; PM2.5; Roadway emissions; Smart cities; Urban modeling},
  document_type       = {Conference Paper},
  journal             = {HARMO 2017 - 18th International Conference on Harmonisation within Atmospheric Dispersion Modelling for Regulatory Purposes, Proceedings},
  keywords            = {Air quality; Atmospheric humidity; Atmospheric movements; Computational fluid dynamics; Public utilities; Smart city, Air quality forecasts; Air quality modeling; Computational fluid dynamics modeling; Initial deployments; PM2.5; Residential neighborhoods; Roadway emissions; Urban model, Urban growth},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047202767&partnerID=40&md5=db700594a7d63322d20a8494e4b438e4},
}

@Conference{Elbanhawy2017185.1,
  author                  = {Elbanhawy, E.Y.},
  title                   = {Mummy, i need a wee! the integration of space syntax, internet of things (IoT), and self tracking technologies to design for pedestrians in smart cities},
  year                    = {2017},
  editor                  = {Heitor T., Serra M., Bacharel M., Cannas da Silva L., Silva J.P.},
  pages                   = {185.1-185.6},
  publisher               = {Instituto Superior Tecnico, Departamento de Engenharia Civil, Arquitetura e Georrecursos},
  note                    = {cited By 0},
  abbrev_source_title     = {Proc. - Int. Space Syntax Symp.},
  abstract                = {City and town planners are accounting for Internet of Things (IoT) at different scales of applications. Planning for pedestrians has attracted practitioners and researchers overarching different domains and addressing various problems. This paper explores the re-use of selftracking technology to have a human-centric planning for pedestrian whilst integrating this with the urban layer and agent-based modelling (ABM) technique. This study is a part of an on going research; it presents a part of its overall methodology to obtain interim findings. We focus on the comfort qualities the pedestrian demands in the walking pathway and in particular when they are walking with a child. An ABM is proposed to represent the phenomenon and analyse it. This study covers the development of the model, emphasizing how it would reflect the integration of the re-use of self-tracking technology and the syntactic measures to assist with planning for pedestrian in smart cities. The outcome of the research should interest city planners and make a concrete business case that would interest technology providers.},
  affiliation             = {Open University, United Kingdom},
  author_keywords         = {Agent-based modelling; Design for pedestrian; Location-allocation problem; Self-tracking; Spatiotemporal; Walkability},
  correspondence_address1 = {Elbanhawy, E.Y.; Open UniversityUnited Kingdom; email: eiman.elbanhawy@open.ac.uk},
  document_type           = {Conference Paper},
  isbn                    = {9789729899447},
  journal                 = {Proceedings - 11th International Space Syntax Symposium, SSS 2017},
  keywords                = {Autonomous agents; Computational methods; Planning; Smart city; Syntactics, Agent-based modelling; Location allocation problem; Self-tracking; Spatiotemporal; Walkability, Internet of things},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031110060&partnerID=40&md5=d8a3b4c417a19d6c912be77523434f6d},
}

@Conference{Brenna2017,
  author              = {Brenna, M. and Foiadelli, F. and Longo, M. and Zaninelli, D.},
  title               = {A study of the integration of Distributed Generation and EVs in smart cities},
  year                = {2017},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 1},
  abbrev_source_title = {Int. Conf. Electr. Electron. Technol. Automot.},
  abstract            = {Nowadays, the transition to a more sustainable energy and transport system is necessary. This work faces this theme at a district level, considering a residential neighborhood of a big metropolitan area and proposing a model for a Smart Residential District. The optimum quantities of installed power are calculated thanks to an optimization procedure based on a Genetic Algorithm: A non-deterministic technique allowing to reach the global optimum in a fast way and without strong computational efforts. © 2017 AEIT.},
  affiliation         = {Department of Energy Politecnico D Milano, I-Milano, Italy},
  art_number          = {7993226},
  author_keywords     = {Distributed generation; electric vehicles; genetic algorithm; smart cities},
  document_type       = {Conference Paper},
  doi                 = {10.23919/EETA.2017.7993226},
  isbn                = {9788887237269},
  journal             = {2017 International Conference of Electrical and Electronic Technologies for Automotive},
  keywords            = {Distributed power generation; Electric vehicles; Genetic algorithms; Housing; Optimization, Computational effort; Deterministic technique; Metropolitan area; Optimization procedures; Residential districts; Residential neighborhoods; Sustainable energy; Transport systems, Smart city},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030844223&doi=10.23919%2fEETA.2017.7993226&partnerID=40&md5=46c6a865a9115bd13ff800a839459161},
}

@Article{Karaköse2017,
  author                  = {Karaköse, M. and Yetiş, H.},
  title                   = {A cyberphysical system based mass-customization approach with integration of industry 4.0 and smart city},
  journal                 = {Wireless Communications and Mobile Computing},
  year                    = {2017},
  volume                  = {2017},
  issn                    = {15308669},
  note                    = {cited By 8},
  abbrev_source_title     = {Wireless Commun. Mobile Comput.},
  abstract                = {Smart city is a city which is designed to meet the people’s demands. In addition to use of sources efficiently, trends of people are also a need that smart city should meet. Buying personalized products in a cheap and fast way is a demand of people of today. Mass customization, which is defined as the personalization of products, achieves making the tailor-made products cheaper. In this study, we propose a new approach for mass customization with the integration of smart retail and smart production. With removing the operators and actualizing the progress autonomously, it is aimed to reduce the waiting time of customers. Because less waiting time means that there are more mass-customization customers, and this is expected to increase the popularity of mass customization. Thus, reducing wastes and increasing productivity are aimed. This study also constitutes the infrastructure that enables a production system to autonomously perform all stages from order to delivery. With the given scenarios, challenges and advantages of desired approach are discussed. © 2017 Mehmet Karaköse and Hasan Yetiş.},
  affiliation             = {Department of Computer Engineering, Fırat University, Elazığ, Turkey},
  art_number              = {1058081},
  correspondence_address1 = {Yetiş, H.; Department of Computer Engineering, Fırat UniversityTurkey; email: h.yetis@firat.edu.tr},
  document_type           = {Article},
  doi                     = {10.1155/2017/1058081},
  keywords                = {Computer aided manufacturing; Embedded systems; Sales, Cyber physical systems (CPSs); Mass customization; New approaches; Personalizations; Personalized products; Production system; Reducing waste; Tailor-made products, Smart city},
  language                = {English},
  publisher               = {Hindawi Limited},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029871799&doi=10.1155%2f2017%2f1058081&partnerID=40&md5=60ee4fd40013b9470145cf4933367d3b},
}

@Conference{Yamamura20171462,
  author                  = {Yamamura, S. and Fan, L. and Suzuki, Y.},
  title                   = {Assessment of Urban Energy Performance through Integration of BIM and GIS for Smart City Planning},
  year                    = {2017},
  editor                  = {Osmond P., Ding L., Fiorito F.},
  volume                  = {180},
  pages                   = {1462-1472},
  publisher               = {Elsevier Ltd},
  note                    = {cited By 17},
  abbrev_source_title     = {Procedia Eng.},
  abstract                = {Smart city has been becoming nowadays a very popular topic that not only in developed countries but also in developing countries. There are variety of definitions for smart city in different fields and regions. Generally, it aims for a sustainable city development through the optimal management of the resources and potential, offering a comprehensively higher quality life to the citizens. The planning of area energy system is one of the most important issues, which is related to the energy generation, the energy consumption by facilities, transportation system, and any other city infrastructures. Especially for Japan, one of the countries facing the complex issues of an aging society, disaster management and energy dependency need a new methodologies for optimal urban energy planning that integrates all information from these sectors. Smart city with highly developed information and communications technology (ICT) is considered as such an important approach. To encourage the smart city concept in Japan, this paper proposes a "GIS-BIM" based urban energy planning system to access the optimal technical and policy solution for readjust city infrastructure beyond the integrated analysis. Firstly, it introduces the concept of Japanese smart city which covers from urban planning to infrastructure. Secondly, the research proposes a GIS-BIM based urban energy planning system including the database construction and analysis by GIS, the optimal energy system design aided by BIM and 3D visualization with user-friendly interface. Finally, center of Tokyo is adopted as a case study, suggesting the potential to access the optimal technical and policy solution. © 2017 The Authors. Published by Elsevier Ltd.},
  affiliation             = {Nikken Sekkei Research Institute, Mitsuwa Ogawamachi Bldg. 3F, 3-7-1 Kanda Ogawamachi, Chiyoda-ku, Tokyo, 101-0052, Japan},
  author_keywords         = {Building information modeling (BIM); Geographic information system (GIS); Smart city; urban energy planning},
  correspondence_address1 = {Yamamura, S.; Nikken Sekkei Research Institute, Mitsuwa Ogawamachi Bldg. 3F, 3-7-1 Kanda Ogawamachi, Japan; email: yamamura@nikken.jp},
  document_type           = {Conference Paper},
  doi                     = {10.1016/j.proeng.2017.04.309},
  issn                    = {18777058},
  journal                 = {Procedia Engineering},
  keywords                = {Architectural design; Developing countries; Disaster prevention; Disasters; Energy utilization; Geographic information systems; Sustainable development; Three dimensional computer graphics; Urban growth, Building Information Model - BIM; Database construction; Disaster management; Information and communications technology; Integrated analysis; Transportation system; Urban energy planning; User friendly interface, Smart city},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020552993&doi=10.1016%2fj.proeng.2017.04.309&partnerID=40&md5=9a0c94e3009cb5e9cc796d1afd3210dd},
}

@Conference{Lopes2016,
  author              = {Lopes, F. and Loss, S. and Mendes, A. and Batista, T. and Lea, R.},
  title               = {SoS-centric Middleware Services for Interoperability in Smart Cities Systems},
  year                = {2016},
  publisher           = {Association for Computing Machinery, Inc},
  note                = {cited By 4},
  abbrev_source_title = {Proc. Int. Workshop Smart, SmartCities},
  abstract            = {Modern cities are supported by many IT systems managed by distinct public and private agents. Such legacy systems are often incompatible since, in general, they use old, dependent and nonstandardised technologies. This results in an environment in which there is no interoperability among smart city systems, preventing richer and more interesting applications to be used by citizens, companies, and city administration. An alternative to solve the lack of interoperability is the adoption of a System-of- Systems (SoS) approach. A SoS is a set of independent and heterogeneous constituent systems that interoperate to accomplish a global mission. The collaboration among such constituent systems enables a SoS to offer new functionalities that cannot be provided by any of these systems working as individual entities. The goal of this paper is to propose SoS-centric middleware services to support the management and execution of SoS in Smart Cities environments in a dynamic, transparent and scalable way. The proposed services, once integrated into a smart city platform, support interoperability among different systems operating in a city. Moreover, this paper also presents a motivational case study to make it clear the issues that must be addressed when multiple independent systems are brought together to provide a new Smart City service or application. © 2016 Association for Computing Machinery.},
  affiliation         = {Metropole Digital Institute, Federal University of Rio Grande Do Norte, Natal, Brazil; Department of Computing and Applied Mathematics, Federal University of Rio Grande Do Norte, Natal, Brazil; School of Computing and Communications, Lancaster University, United Kingdom},
  art_number          = {a4},
  author_keywords     = {Interoperability; Middleware; Smart Cities; System-of-Systems (SoS)},
  document_type       = {Conference Paper},
  doi                 = {10.1145/3009912.3009917},
  isbn                = {9781450346672},
  journal             = {Proceedings of the 2nd International Workshop on Smart, SmartCities 2016},
  keywords            = {Legacy systems; Middleware; System of systems; Systems engineering, Global missions; Independent systems; IT system; Middleware services; OR applications; Smart cities, Interoperability},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009461106&doi=10.1145%2f3009912.3009917&partnerID=40&md5=98ee4ae25caa117f4d7b6316c0df06fc},
}

@Article{Ahlgren201652,
  author              = {Ahlgren, B. and Hidell, M. and Ngai, E.C.-H.},
  title               = {Internet of Things for Smart Cities: Interoperability and Open Data},
  journal             = {IEEE Internet Computing},
  year                = {2016},
  volume              = {20},
  number              = {6},
  pages               = {52-56},
  issn                = {10897801},
  note                = {cited By 33},
  abbrev_source_title = {IEEE Internet Comput},
  abstract            = {The Internet of Things (IoT) has become a promising technology for addressing societal challenges by connecting smart devices and leveraging Big Data analytics to create smart cities worldwide. As the IoT scales up, it's important to provide interoperability among different devices. Yet current simple standard protocols lack sufficient openness and interoperability. IoT for smart cities needs to guarantee the accessibility of open data and cloud services to allow industries and citizens to develop new services and applications. Here, the authors provide a case study of the GreenIoT platform in Uppsala, Sweden, to demonstrate the idea of interoperability and open data for smart cities. © 1997-2012 IEEE.},
  affiliation         = {SICS Swedish ICT, Sweden; KTH Royal Institute of Technology, Sweden; Uppsala University, Sweden},
  art_number          = {7781549},
  author_keywords     = {Big Data; cloud computing; Internet of Things; Internet/Web technologies; interoperability; IoT; open data; open systems; smart cities},
  coden               = {IICOF},
  document_type       = {Article},
  doi                 = {10.1109/MIC.2016.124},
  keywords            = {Big data; Cloud computing; Distributed computer systems; Interoperability; Open systems, Cloud services; Data analytics; Internet of thing (IOT); New services; Open datum; Smart cities; Smart devices; Standard protocols, Internet of things},
  language            = {English},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007470973&doi=10.1109%2fMIC.2016.124&partnerID=40&md5=22790993d96cb886ac5368930bd7ca1d},
}

@Article{Palomar2016,
  author                  = {Palomar, E. and Chen, X. and Liu, Z. and Maharjan, S. and Bowen, J.},
  title                   = {Component-based modelling for scalable smart city systems interoperability: A case study on integrating energy demand response systems},
  journal                 = {Sensors (Switzerland)},
  year                    = {2016},
  volume                  = {16},
  number                  = {11},
  issn                    = {14248220},
  note                    = {cited By 3},
  abbrev_source_title     = {Sensors},
  abstract                = {Smart city systems embrace major challenges associated with climate change, energy efficiency, mobility and future services by embedding the virtual space into a complex cyber-physical system. Those systems are constantly evolving and scaling up, involving a wide range of integration among users, devices, utilities, public services and also policies. Modelling such complex dynamic systems’ architectures has always been essential for the development and application of techniques/tools to support design and deployment of integration of new components, as well as for the analysis, verification, simulation and testing to ensure trustworthiness. This article reports on the definition and implementation of a scalable component-based architecture that supports a cooperative energy demand response (DR) system coordinating energy usage between neighbouring households. The proposed architecture, called refinement of Cyber-Physical Component Systems (rCPCS), which extends the refinement calculus for component and object system (rCOS) modelling method, is implemented using Eclipse Extensible Coordination Tools (ECT), i.e., Reo coordination language. With rCPCS implementation in Reo, we specify the communication, synchronisation and co-operation amongst the heterogeneous components of the system assuring, by design scalability and the interoperability, correctness of component cooperation. © 2016 by the authors; licensee MDPI, Basel, Switzerland.},
  affiliation             = {School of Computing and Digital Technology, Birmingham City University, Birmingham, B4 7XG, United Kingdom; Department of Computer Science, University of Illinois at Urbana-Champaign, Champaign, IL 61801, United States; Centre for Research and Innovation in Software Engineering, Southwest University, Chongqing, 400700, China; Networks Department, Simula Research Laboratory, Fornebu, 1364, Norway; School of Engineering, London South Bank University, London, SE1 0AA, United Kingdom},
  art_number              = {1810},
  author_keywords         = {Component system interoperability and coordination; Component-based architecture design; Cooperative demand response; Scalable modelling; Smart city system modelling},
  correspondence_address1 = {Palomar, E.; School of Computing and Digital Technology, Birmingham City UniversityUnited Kingdom; email: esther.palomar@bcu.ac.uk},
  document_type           = {Article},
  doi                     = {10.3390/s16111810},
  keywords                = {Calculations; Climate change; Computer architecture; Embedded systems; Energy efficiency; Energy management; Integration testing; Modeling languages, Component systems; Component-based architecture; Demand response; Scalable Modelling; System modelling, Interoperability},
  language                = {English},
  publisher               = {MDPI AG},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994753052&doi=10.3390%2fs16111810&partnerID=40&md5=3459e85f844fb6c07628accddfa97967},
}

@Article{Horng2016861,
  author                  = {Horng, G.-J. and Cheng, S.-T.},
  title                   = {Using Intelligent Vehicle Infrastructure Integration for Reducing Congestion in Smart City},
  journal                 = {Wireless Personal Communications},
  year                    = {2016},
  volume                  = {91},
  number                  = {2},
  pages                   = {861-883},
  issn                    = {09296212},
  note                    = {cited By 1},
  abbrev_source_title     = {Wireless Pers Commun},
  abstract                = {This paper proposes a novel cognitive cellular automata (CA) approach to traffic management that can adapt to immediate requirements, be applied for use in cross-area car societies, enhance system performance, and decrease traffic congestion problems. We propose a mechanism that operates in a cognitive radio mode to increase the channel-reuse rate and decrease the allocation of redundant channels. This approach provides the advantage of a heterogeneous communication interface based on cognitive mechanisms that recognize different transmission modulation modes. The receiver gets messages through different transmission modulation modes. In this work, we postulate vehicles connecting to traffic congestion computing centers by vehicle-to-roadside communications within a car society. Roadside units serve each road segment, and we suppose that every car has a navigation device. We propose an innovative congestion-reduction mechanism that provides directions to a vehicle’s navigation device after the driver sets the origin location and the destination. This mechanism calculates the congestion status of the upcoming road segment. By tracking the status of road segments from a point of origin to a destination, our proposed mechanism can handle cross-area car societies. The current study evaluates this approach’s performance by conducting computer simulations. Simulation results reveal the strengths of the proposed CA mechanism in terms of increased lifetime and increased congestion-avoidance for urban vehicular networks. © 2016, Springer Science+Business Media New York.},
  affiliation             = {Department of Computer Science and Information Engineering, Southern Taiwan University of Science and Technology, Tainan, Taiwan; Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan},
  author_keywords         = {Car society; Cellular automata; Traffic congestion; Urban vehicular network; Vehicle to roadside},
  coden                   = {WPCOF},
  correspondence_address1 = {Horng, G.-J.; Department of Computer Science and Information Engineering, Southern Taiwan University of Science and TechnologyTaiwan; email: grojium@gmail.com},
  document_type           = {Article},
  doi                     = {10.1007/s11277-016-3501-8},
  keywords                = {Cellular automata; Cognitive radio; Modulation; Roads and streets; Roadsides; Transportation; Vehicle to roadside communications; Vehicle to vehicle communications; Vehicles, Cognitive mechanisms; Congestion avoidance; Congestion reduction; Heterogeneous communication; Navigation devices; Transmission modulation; Urban vehicular networks; Vehicle-infrastructure integrations, Traffic congestion},
  language                = {English},
  publisher               = {Springer New York LLC},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979211212&doi=10.1007%2fs11277-016-3501-8&partnerID=40&md5=c882261d2216ce77d80e297733b21814},
}

@Article{Dumas2016447,
  author                  = {Dumas, P.},
  title                   = {A European perspective of the development of deep geothermal in urban areas: Smart thermal grids, geothermal integration into smart cities},
  journal                 = {Geomechanik und Tunnelbau},
  year                    = {2016},
  volume                  = {9},
  number                  = {5},
  pages                   = {447-450},
  issn                    = {18657362},
  note                    = {cited By 1},
  abbrev_source_title     = {Geomech. Tunnelbau},
  abstract                = {The future of our energy supply systems is moving towards Smart Cities and Smart Rural Communities, where the integration of combined technologies using renewable energy sources reduces environmental impact and offers citizens a better quality of life. Geothermal has a particularly important role in smart electricity and thermal grids, since it can deliver both heating and cooling, and electricity. Shallow geothermal, using heat pumps, is a key energy source for smart energy systems. It provides solutions for the future energy system by coupling smart thermal and electricity grids with underground thermal storage and by providing reliable and affordable heating and cooling supply to both urban and rural areas. As these technologies can be installed in grid and off-grid heating and cooling systems, they perfectly fit the new smart cities and rural communities approach. In addition, there is also an important role for shallow geothermal energy in connection with and management of smart electricity grids. Geothermal heat pumps can provide demand response services, thereby contributing to grid stabilisation, whilst Underground Thermal Energy Storage (UTES) is an excellent storage solution. Shallow geothermal technologies will be utilised in the next generation of district heating: Smart Thermal Grids. © 2016 Ernst & Sohn Verlag für Architektur und technische Wissenschaften GmbH & Co. KG, Berlin},
  affiliation             = {European Geothermal Energy Council, Place du champ de mars 2, Brussels, 1050, Belgium},
  author_keywords         = {Geothermal energy - Geothermie; smart thermal grids; Sustainability - Nachhaltigkeit; underground thermal energy storage; UTES},
  correspondence_address1 = {Dumas, P.; European Geothermal Energy Council, Place du champ de mars 2, Belgium; email: p.dumas@egec.org},
  document_type           = {Article},
  doi                     = {10.1002/geot.201600030},
  keywords                = {Cooling; Cooling systems; Electric energy storage; Electric power transmission networks; Energy storage; Environmental impact; Environmental technology; Geothermal energy; Geothermal heat pumps; Heat pump systems; Heat storage; Heating; Renewable energy resources; Rural areas; Sustainable development; Thermal energy, Energy supply system; Heating and cooling systems; Renewable energy source; Shallow geothermal energies; Smart energy systems; smart thermal grids; Urban and rural areas; UTES, Smart power grids},
  language                = {English},
  publisher               = {Wilhelm Ernst and Sohn},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990187391&doi=10.1002%2fgeot.201600030&partnerID=40&md5=4bcaf52aef20cb8313abe1e3661c9674},
}

@Conference{Villanueva-Rosales2016,
  author              = {Villanueva-Rosales, N. and Garnica-Chavira, L. and Larios, V.M. and Gómez, L. and Aceves, E.},
  title               = {Semantic-enhanced living labs for better interoperability of smart cities solutions},
  year                = {2016},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 3},
  abbrev_source_title = {IEEE Int. Smart Cities Conf.: Improv. Citizens Qual. Life, ISC2 - Proc.},
  abstract            = {The use of standards (e.g., JSON) by partner institutions (UDG and UTEP) facilitated the semantic annotation of sensor data generated by UDG Living Lab. The terms chosen to annotate data include widely-used vocabularies in the areas of Linked Data (e.g., PROV), sensors data (e.g., SSN) and IoT (e.g., IoT vocabulary) for reusability and interoperability purposes. Current work includes the publication of annotated JSON files as open data and the creation of application-specific vocabularies10 to provide higher granularity in our descriptions. © 2016 IEEE.},
  affiliation         = {Department of Computer Science, Cyber-ShARE Center, University of Texas at El Paso, El Paso, TX, United States; Smart Cities Innovation Center, CUCEA, University of Guadalajara, Zapopan, Mexico},
  art_number          = {07580775},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ISC2.2016.07580775},
  isbn                = {9781509018451},
  journal             = {IEEE 2nd International Smart Cities Conference: Improving the Citizens Quality of Life, ISC2 2016 - Proceedings},
  keywords            = {Internet of things; Interoperability; Reusability, Application specific; Linked datum; Open datum; Partner institutions; Semantic annotations; Sensor data; Sensors data; Smart cities, Semantics},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994172765&doi=10.1109%2fISC2.2016.07580775&partnerID=40&md5=1ce43a4ba8f6d2794545507349e85990},
}

@Article{Orłowski201659,
  author                  = {Orłowski, C. and Ziółkowski, A. and Orłowski, A. and Kapłański, P. and Sitek, T. and Pokrzywnicki, W.},
  title                   = {Model of an integration bus of data and ontologies of smart cities processes},
  journal                 = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year                    = {2016},
  volume                  = {9990 LNCS},
  pages                   = {59-75},
  issn                    = {03029743},
  note                    = {cited By 0},
  abbrev_source_title     = {Lect. Notes Comput. Sci.},
  abstract                = {This paper presents a model of an integration bus used in the design of Smart Cities system architectures. The model of such a bus becomes necessary when designing high-level architectures, within which the silo processes of the organization should be seen from the perspective of its ontology. For such a bus to be used by any city, a generic solution was proposed which can be implemented as a whole or in part depending on the requirements posed by those cities with respect to the construction of such buses. The work is divided into four main parts. The first part presents a model of high-level architectural design processes, using ontologies and a data integration bus, which constitutes the generalized experiences of the authors drawn from the design processes of Smart Cities systems. The second part contains a description of the environment in which Smart Cities systems are developed, illustrated with two guidelines and the implementation processes of these guidelines. In the third part, two components of that environment are identified: the data integration bus and the ontologies of city processes. This is done to demonstrate how Smart Cities systems are designed and to show the processes of the permeation of data and the ontologies of city processes in the creation of a high-level architecture. The fourth section contains a description of how the proposed model is applied in the construction of a common integration bus for data and ontologies. The paper summary presents recommendations concerning the applicability of the proposed model. © Springer-Verlag GmbH Germany 2016.},
  affiliation             = {WSB University in Gdańsk, Gdańsk, Poland; Gdansk University of Technology, Gdańsk, Poland; Staples Advantage Poland SP. Z O.O, Gdańsk, Poland},
  author_keywords         = {Ontologies; Ontology driven architecture; Smart cities},
  correspondence_address1 = {Orłowski, C.; WSB University in GdańskPoland; email: corlowski@wsb.gda.pl},
  document_type           = {Article},
  doi                     = {10.1007/978-3-662-53580-6_5},
  keywords                = {Architecture; Buses; Ontology, Design process; Generic solutions; High level architecture; Implementation process; Smart cities; System architectures; Two-component, Data integration},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988965810&doi=10.1007%2f978-3-662-53580-6_5&partnerID=40&md5=51c39503e4877f8600abd7e54cd0a2a7},
}

@Conference{Brizzi2016,
  author              = {Brizzi, P. and Bonino, D. and Musetti, A. and Krylovskiy, A. and Patti, E. and Axling, M.},
  title               = {Towards an ontology driven approach for systems interoperability and energy management in the smart city},
  year                = {2016},
  editor              = {Nizetic S., Milanovic Z., Patrono L., Solic P., Perkovic T.},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 7},
  abbrev_source_title = {Int. Multidiscip. Conf. Comput. Energy Sci., SpliTech},
  abstract            = {Modern Information and Communication Technologies are definitely a key factor to develop the green and sustainable applications that the so-called 'smart city' needs. Effective management of resources, gathering and interpreting data as well as ecological considerations are prerequisites to turn such a vision into reality. The European FP7 project DIMMER address these issues by providing a flexible Internet of Thing platform for application development and data integration, exploiting information about buildings, energy distribution grids and user behaviors. Among those applications, the possibility to real-time access and aggregate information about building environmental characteristics and energy consumption enables the optimization of energy management and control, as well as the user's awareness about, which is the scope of the DIMMER project. The paper will describe the ontology-driven approach, as well as the actual design, exploited to model the physical world within the context of this project, adding a special emphasis on the state of art research in the field of energy profiling. © 2016 University of Split, FESB.},
  affiliation         = {Istituto Superiore Mario Boella (ISMB), Torino, Italy; D'Appolonia, Genova, Italy; Fraunhofer FIT, Sankt Augustin, Germany; Politecnico di Torino, Torino, Italy; CNet Svenska AB, Danderyd, Sweden},
  art_number          = {7555948},
  author_keywords     = {Dimmer; Energy profile; Internet of Things; Ontology; Smart City},
  document_type       = {Conference Paper},
  doi                 = {10.1109/SpliTech.2016.7555948},
  isbn                = {9789532900637},
  journal             = {2016 International Multidisciplinary Conference on Computer and Energy Science, SpliTech 2016},
  keywords            = {Behavioral research; Data integration; Energy management; Energy utilization; Internet; Internet of things; Interoperability; Ontology, Application development; Dimmer; Energy profile; Environmental characteristic; Information and Communication Technologies; Management and controls; Smart cities; Systems interoperability, Information management},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988864325&doi=10.1109%2fSpliTech.2016.7555948&partnerID=40&md5=c21b11547d0e888d67155760098bc32e},
}

@Conference{Ahn2016337,
  author              = {Ahn, J.-Y. and Lee, J.S. and Kim, H.J. and Hwang, D.J.},
  title               = {Smart city interoperability framework based on city infrastructure model and service prioritization},
  year                = {2016},
  volume              = {2016-August},
  pages               = {337-342},
  publisher           = {IEEE Computer Society},
  note                = {cited By 4},
  abbrev_source_title = {Int. Conf. Ubiquitous Future Netw., ICUFN},
  abstract            = {The urban development vision that is 'smart city' is fast becoming a target of modern cities. However, it is hard to find a general reference architecture and interoperability standards to help with the effective realization of such a vision. This paper sets o ut to do two things: first, we look to develop a general model of city structure, and then we suggest a smart city interoperability framework based on it. For the city model two modeling skills were applied; infrastructure-oriented modeling of a system and the value flows within the system. The skills support modeling of a city at a manageable level of granularity and the handling of emerging ICT functions of smart city at the same level, an infrastructure. Derived high level architecture model of a smart city integration is general enough to use for the development of interoperability framework of smart city. A process of selecting preferable smart city services is formulated, aiming to enhance the effectiveness of interoperability framework; it is necessary effort, since smart city is on a convergence technology that should be leaded by the virtue of the convergence, the effectiveness of innovation. Based on both researches on the infrastructure-oriented modeling of a city and service prioritization, we developed a smart city interoperability framework conforming to a practical ICT infrastructure system as an efficient and effective vehicle of smart city realization. © 2016 IEEE.},
  affiliation         = {Protocol Engineering Center, ETRI, Deajeon, South Korea; Dept. of Information and Communication, SungKyunKwan University, Suwon, South Korea},
  art_number          = {7537044},
  author_keywords     = {City Infrastructure; Interoperability Framework; IT convergence; Smart city},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICUFN.2016.7537044},
  isbn                = {9781467399913},
  issn                = {21658528},
  journal             = {International Conference on Ubiquitous and Future Networks, ICUFN},
  keywords            = {Network architecture; Urban growth, City Infrastructure; Convergence technologies; High level architecture; Infrastructure modeling; Interoperability framework; IT convergence; Reference architecture; Smart cities, Interoperability},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983287749&doi=10.1109%2fICUFN.2016.7537044&partnerID=40&md5=494f87d4c54d5ba372eea3df6f07d813},
}

@Conference{Gyrard2016796,
  author              = {Gyrard, A. and Serrano, M.},
  title               = {Connected smart cities: Interoperability with SEG 3.0 for the internet of things},
  year                = {2016},
  editor              = {Jara A.J., Takizawa M., Bocchi Y., Barolli L., Enokido T.},
  pages               = {796-802},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 10},
  abbrev_source_title = {Proc. - IEEE Int. Conf. Adv. Inf. Netw. Appl. Workshops, WAINA},
  abstract            = {The Internet of Things (IoT) is driving the technology and advances of the Internet and every day it is becoming more popular to talk about IoT systems in multiple domains: Smart Cities, Agriculture, and Industrial Internet, etc. Increasingly, IoT systems will need to interact and be interconnected for offering the always-promoted everything-connected paradigm. Current IoT systems rely on semantic web technologies for integrating data and ensure web services interoperability. However there are yet a gap to ensure semantic interoperability among IoT systems. Most of the existing proposed (open) approaches and solutions lack on formal methodologies for interoperability in technology and standard format of the data. We studied and analyzed most available semantic-based IoT approaches to identify the main requirements hindering IoT semantic interoperability. In this paper, we present SEG 3.0 a methodology to federate, unify and provide semantic interoperability. SEG 3.0 emerges from methodologies for ontology engineering and the idea of unification and federated systems. We propose SEG 3.0 and apply it to Internet of Things (IoT) and particularly on use cases for smart cities as proof of concept. Firstly, we define characteristics required for the methodology. Secondly, we describe the processes and the different formal steps. Thirdly, we provide a proof of concept framework and architecture applying this methodology, thus the benefits of using SEG 3.0 methodology in IoT domains are described. Finally, we demonstrate that the SEG 3.0 methodology is applied to three use cases: (1) the M3 framework to assist developers in designing semantic-based IoT applications, (2) the VITAL EU project for smart cities, and (3) the FIESTA-IoT EU project for IoT semantic interoperability. SEG 3.0 is a formal methodology generic enough to be applied to other domains than IoT and smart cities, since the main benefit of the SEG 3.0 is integrating heterogeneous data and adding value to it to build innovative applications. © 2016 IEEE.},
  affiliation         = {Insight and National University of Ireland, Galway, Ireland},
  art_number          = {7471300},
  author_keywords     = {Federation; Internet of Things; Interoperability; Methodology; Ontology; Semantic Web of Things; Semantic Web Technologies; Smart Cities; Unification},
  document_type       = {Conference Paper},
  doi                 = {10.1109/WAINA.2016.151},
  isbn                = {9781509018574},
  journal             = {Proceedings - IEEE 30th International Conference on Advanced Information Networking and Applications Workshops, WAINA 2016},
  keywords            = {Data integration; Internet; Interoperability; Ontology; Semantic Web; Web services, Federation; Methodology; Semantic Web technology; Smart cities; Unification, Internet of things},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983499599&doi=10.1109%2fWAINA.2016.151&partnerID=40&md5=e0a5ff7eee475a9bd9c119eb4a9587e7},
}

@Conference{Avazpour2016,
  author              = {Avazpour, I. and Grundy, J. and Zhu, L.},
  title               = {V for variety: Lessons learned from complex smart cities data harmonization and integration},
  year                = {2016},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {IEEE Int. Conf. Pervasive Comput. Commun. Workshops, PerCom Workshops},
  abstract            = {With emerging trends for Internet of Things (IoT) and Smart Cities, complex data transformation, aggregation and visualization problems are becoming increasingly common. These tasks support improved business intelligence, analytics and enduser access to data. However, in most cases developers of these tasks are presented with challenging problems including noisy data, diverse data formats, data modeling and increasing demand for sophisticated visualization support. This paper describes our experiences with just such problems in the context of Household Travel Surveys data integration and harmonization. We describe a common approach for addressing these harmonizations. We then discuss a set of lessons that we have learned from our experience that we hope will be useful for others embarking on similar problems. We also identify several key directions and needs for future research and practical support in this area. © 2016 IEEE.},
  affiliation         = {Software Innovation Laboratory, Faculty of Science, Engineering and Technology, Swinburne University of Technology, Hawthorn, VIC 3122, Australia; Software and Computational Systems, Data61, CSIRO, Australia; School of Computer Science and Engineering, University of New South Wales, Sydney, Australia},
  art_number          = {7457092},
  document_type       = {Conference Paper},
  doi                 = {10.1109/PERCOMW.2016.7457092},
  isbn                = {9781509019410},
  journal             = {2016 IEEE International Conference on Pervasive Computing and Communication Workshops, PerCom Workshops 2016},
  keywords            = {Data visualization; Information analysis; Metadata; Transportation; Ubiquitous computing; Visualization, Complex data; Data harmonization; Emerging trends; End users; Household travel surveys; Internet of Things (IOT); Noisy data; Smart cities, Data integration},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966552330&doi=10.1109%2fPERCOMW.2016.7457092&partnerID=40&md5=8d7a5db87fd7a75eafe745119159c4fb},
}

@Conference{Javidroozi2016312,
  author              = {Javidroozi, V. and Shah, H. and Cole, A. and Amini, A.},
  title               = {Towards a city's systems integration model for smart city development: A conceptualization},
  year                = {2016},
  editor              = {Tran Q.-N., Deligiannidis L., Arabnia H.R.},
  pages               = {312-317},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 4},
  abbrev_source_title = {Proc. - Int. Conf. Comput. Sci. Comput. Intell., CSCI},
  abstract            = {Smart city development is a response to address the issues of urbanization and need for flexibility and agility in delivering services to citizens. City as a complex system of systems needs to be efficient, inter-operable, and integrated. Thus, similar to systems integration in enterprises, integration of city systems provides flexibility and access to real-time information for creation and delivery of efficient services. In addition, Business Process Change is essential for systems integration in smart city development. Similar to business process change in the private enterprises, there are a number of challenging dimensions in smart city development. This conceptualization research considers a city as a large-scale enterprise and attempts to design a business process centric model for city's systems integration. © 2015 IEEE.},
  affiliation         = {Computing, Engineering, the Built Environment (CEBE), Faculty Birmingham City University (BCU), Birmingham, United Kingdom},
  art_number          = {7424108},
  author_keywords     = {Business process change; Smart city; Smart city dimensions; Systems integration},
  document_type       = {Conference Paper},
  doi                 = {10.1109/CSCI.2015.10},
  isbn                = {9781467397957},
  journal             = {Proceedings - 2015 International Conference on Computational Science and Computational Intelligence, CSCI 2015},
  keywords            = {Artificial intelligence; Integration; Real time systems, Business Process; Business process change; Private enterprise; Real-time information; Smart cities; Systems integration, Urban growth},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964467474&doi=10.1109%2fCSCI.2015.10&partnerID=40&md5=3f8e71c9f357925666a242b55f23e4ed},
}

@Conference{Jin20161289,
  author              = {Jin, P. and Meng, T. and Guo, K. and Shao, F.},
  title               = {Research of routing algorithm based on smart city and the design of multi-network integration},
  year                = {2016},
  pages               = {1289-1292},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Proc. - Chin. Autom. Congr., CAC},
  abstract            = {In the face of problems of communication network in the smart city, which is featured with the limited bandwidth and huge amount of data, it is difficult to ensure the validity of the data transmission. Based on the rate of timeliness and data transfer rate, this paper improves the LEACH algorithm, and shows that it can ensure the timeliness of various types of data transmission and improve the efficiency of data transmission by the simulation. In addition, this paper proposes an overall design of one map-Two line-four meter-four network, which has been applied to the construction of Shenyang city. The demonstration project can meet the requirements of the smart city effectively and support the construction of the smart city strongly. © 2015 IEEE.},
  affiliation         = {Shenyang Power Supply Company, Liaoning Provincial Power Grid Corp, Shenyang, 110003, China; School of Information Science and Engineering, Northeastern University, Shenyang, 110819, China},
  art_number          = {7382698},
  author_keywords     = {improved LEACH algorithm; multi-network integration; smart city; smart grid},
  document_type       = {Conference Paper},
  doi                 = {10.1109/CAC.2015.7382698},
  isbn                = {9781467371896},
  journal             = {Proceedings - 2015 Chinese Automation Congress, CAC 2015},
  keywords            = {Algorithms; Data transfer; Data transfer rates; Leaching, Demonstration project; Leach algorithms; Limited bandwidth; Network integration; Overall design; Smart cities; Smart grid; Two-line, Data communication systems},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966546023&doi=10.1109%2fCAC.2015.7382698&partnerID=40&md5=cd37697b2ff4c9eadb91f747e5767a16},
}

@Article{Shih2016181,
  author                  = {Shih, P.-J.},
  title                   = {Integration is the key to urban evolution: Technical challenges for the smart city and the internet of thins},
  journal                 = {International Journal of Automation and Smart Technology},
  year                    = {2016},
  volume                  = {6},
  number                  = {4},
  pages                   = {181-183},
  issn                    = {22239766},
  note                    = {cited By 0},
  abbrev_source_title     = {Int. J. Autom. Amart Technol.},
  affiliation             = {Market Intelligence and Consulting Institute (MIC), Institute for Information Industry (III), Taiwan},
  correspondence_address1 = {Shih, P.-J.; Market Intelligence and Consulting Institute (MIC), Institute for Information Industry (III)Taiwan; email: linahlli@micmail.iii.org.tw},
  document_type           = {Article},
  doi                     = {10.5875/ausmt.v6i4.1315},
  language                = {English},
  publisher               = {Chinese Institute of Automation Engineers},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009911252&doi=10.5875%2fausmt.v6i4.1315&partnerID=40&md5=a0b3e287a91d756bfa3d32979813081c},
}

@Conference{Klonari2016166,
  author              = {Klonari, V. and Toubeau, J.-F. and Lobry, J. and Vallée, F.},
  title               = {Photovoltaic integration in smart city power distribution : A Probabilistic photovoltaic hosting capacity assessment based on smart metering data},
  year                = {2016},
  editor              = {Klein C., Donnellan B., Helfert M.},
  pages               = {166-178},
  publisher           = {SciTePress},
  note                = {cited By 4},
  abbrev_source_title = {SMARTGREENS - Proc. Int. Conf. Smart Cities Green ICT Syst.},
  abstract            = {Maximizing the share of renewable resources in the electric energy supply is a major challenge in the design of smart cities. Concerning the smart city power distribution, the main focus is on the Low Voltage (LV) level in which distributed Photovoltaic (PV) units are the mostly met renewable energy systems. This paper demonstrates the usefulness of smart metering (SM) data in determining the maximum photovoltaic (PV) hosting capacity of an LV distribution feeder. Basically, the paper introduces a probabilistic tool that estimates PV hosting capacity by using user-specific energy flow data, recorded by SM devices. The probabilistic evaluation and the use of historical SM data yield a reliable estimation that considers the volatile character of distributed generation and loads as well as technical constraints of the network (voltage magnitude, phase unbalance, congestion risk, line losses). As a case study, an existing LV feeder in Belgium is analysed. The feeder is located in an area with high PV penetration and large deployment of SM devices. The estimated PV hosting capacity is proved to be much higher than the one obtained with a deterministic worst case approach, considering voltage margin (magnitude and unbalance). © Copyright 2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
  affiliation         = {Electrical Engineering Department, University of Mons, 31 Boulevard Dolez 7000, Mons, Belgium; General Physics Department, University of Mons, 9 Rue de Houdain 7000, Mons, Belgium},
  author_keywords     = {Hosting capacity; Low voltage; Photovoltaic; Probabilistic analysis; Smart cities power distribution; Smart meters},
  document_type       = {Conference Paper},
  isbn                = {9789897581847},
  journal             = {SMARTGREENS 2016 - Proceedings of the 5th International Conference on Smart Cities and Green ICT Systems},
  keywords            = {Electric measuring instruments; Feeding; Renewable energy resources; Risk perception; Smart meters, Hosting capacity; Low voltages; Photovoltaic; Power distributions; Probabilistic analysis, Probability distributions},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979642931&partnerID=40&md5=eea82f087a17a04cb12c93e1c74ea418},
}

@Book{Ahuja20161,
  title                   = {Integration of nature and technology for smart cities},
  publisher               = {Springer International Publishing},
  year                    = {2016},
  author                  = {Ahuja, A.},
  isbn                    = {9783319257150; 9783319257136},
  note                    = {cited By 3},
  abbrev_source_title     = {Integr. of Nature and Technology for Smart Cities},
  abstract                = {This book is a resumption of the work “Integrated M/E Design: Building Systems Engineering” published by Anil Ahuja in 1997. Together with an international group of authors from the engineering, urban planning, and architecture fields, Mr. Ahuja discussed new trends and paradigms in the smart buildings and smart city sectors and extended the topic of the previous publication from the building to the entire city. A smart, sustainable building is not just about the building itself. There are things happening in the inside of the building and on the outside. A smart building connects the inside with the outside, provides efficiencies on both sides, synchronizes the outside infrastructure with its inside systems, and integrates nature and its occupants in its design. A smart building doesn’t just provide technology solutions. It is about constant exchange between the inside and the outside of the building, the contribution of the building to the quality of the entire neighborhood and the rest of the city, how the smart building can connect people in a sharing community, and how technology can be the key to make it happen. © Springer International Publishing Switzerland 1997, 2016.},
  affiliation             = {C.C. Johnson and Malhotra, P.C.(CCJM), Chicago, IL, United States},
  correspondence_address1 = {Ahuja, A.; C.C. Johnson and Malhotra, P.C.(CCJM)United States},
  document_type           = {Book},
  doi                     = {10.1007/978-3-319-25715-0},
  journal                 = {Integration of Nature and Technology for Smart Cities},
  language                = {English},
  pages                   = {1-404},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969255683&doi=10.1007%2f978-3-319-25715-0&partnerID=40&md5=2bef8ff026cb788635c98b5f967a870c},
}

@Conference{An201613,
  author              = {An, X. and Sun, S. and Bai, W. and Deng, H.},
  title               = {Data integration in the development of smart cities in China: Towards a digital continuity model},
  year                = {2016},
  editor              = {Zlateva T., Greiman V.A.},
  pages               = {13-20},
  publisher           = {Academic Conferences Limited},
  note                = {cited By 3},
  abbrev_source_title = {Proc. Int. Conf. Cyber Warf. Secur., ICCWS},
  abstract            = {This paper presents a digital continuity model for managing big data in the development of smart cities in China. A mix-methods approach including site visits, document analysis, interviews and case study is adopted in the study, leading to the identification of four challenges with respect to data provenance, data stakeholders, data processing, and data risk management and several big data governance problems including data assurance, data loss, data trustiness, data security and data reusability in the development of smart cities. To effectively tackle such challenges and adequately address these problems, a digital continuity model is proposed as a holistic approach to managing big data resources that can be tracked, traced, linked and exploited for the sustainable development of smart cities in China. The proposed model can be used to guide the development of a national strategy for the integration of big data resources to improve data assurance, data integrity, data trustiness, data security and data reusability in the provision of smart city services.},
  affiliation         = {School of Information Resource Management, Renmin University of China, Beijing, China; Key Laboratory of Data Engineering and Knowledge Engineering of the Ministry of Education, Renmin University of China, Beijing, China; Business School, Nankai University, Tianjin, China; School of Business Information Technology and Logistics, RMIT University, Australia},
  author_keywords     = {Big data; China; Data governance; Data integration; Digital continuity; Smart city},
  document_type       = {Conference Paper},
  isbn                = {9781910810828},
  journal             = {Proceedings of the 11th International Conference on Cyber Warfare and Security, ICCWS 2016},
  keywords            = {Computer crime; Data handling; Data integration; Planning; Reusability; Risk assessment; Risk management, China; Data governances; Data reusability; Digital continuity; Document analysis; Holistic approach; National strategies; Smart cities, Big data},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969141781&partnerID=40&md5=a54f9d3ec6a975539abae4ecbff71701},
}

@Article{Hefnawy2016687,
  author                  = {Hefnawy, A. and Bouras, A. and Cherifi, C.},
  title                   = {Integration of smart city and lifecycle concepts for enhanced large-scale event management},
  journal                 = {IFIP Advances in Information and Communication Technology},
  year                    = {2016},
  volume                  = {467},
  pages                   = {687-697},
  issn                    = {18684238},
  note                    = {cited By 4},
  abbrev_source_title     = {IFIP Advances in Information and Communication Technology},
  abstract                = {Hosting large-scale events is the dream of many cities around the world, however challenging. Hosting a large-scale event is a complex project that requires careful planning, precise implementation, interactive operation, and successful closure of all activities, with the involvement of all relevant organizations, authorities and stakeholders. Therefore, event organizers pay their utmost attention to the improvement of every aspect of Event Management. Application of smart city concepts can address the complexity of service provisioning during large-scale events, through better efficiency, higher quality, and real-time decision-making capabilities. Lifecycle management concepts can improve the whole event management cycle across different phases. This paper proposes combining Smart City and Lifecycle concepts to improve vertical service provisioning and horizontal integration between different sectors, across different phases while creating a suitable platform for information and knowledge sharing within the same event and with other similar events. This research aims to reach a more holistic smart event experience. © IFIP International Federation for Information Processing 2016.},
  affiliation             = {DISP Lab, Lyon 2 University, Lyon, France; DCSE, College of Engineering, Qatar University, Doha, Qatar; Ministry of Information and Communications Technology (ictQATAR), Doha, Qatar},
  author_keywords         = {Event management; IoT; Lifecycle; QLM; Smart city},
  correspondence_address1 = {Hefnawy, A.; DISP Lab, Lyon 2 UniversityFrance; email: ahmed.hefnawy@univ-lyon2.fr},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-319-33111-9_62},
  editor                  = {Bouras A., Foufou S., Thoben K.-D., Eynard B.},
  isbn                    = {9783319331102},
  keywords                = {Decision making; Internet; Internet of things, Event management; Horizontal integrations; Interactive operations; Large scale events; Life-cycle management; Real time decision-making; Service provisioning; Smart cities, Life cycle},
  language                = {English},
  publisher               = {Springer New York LLC},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964900834&doi=10.1007%2f978-3-319-33111-9_62&partnerID=40&md5=b3150f9ba8acd0248491c77f06e043f6},
}

@Conference{Bertoncini2015247,
  author              = {Bertoncini, M. and Arnone, D. and Cioara, T. and Anghel, I. and Salomie, I. and Velivassaki, T.-H.},
  title               = {Next generation data centers business models enabling multi-resource integration for smart city optimized energy efficiency},
  year                = {2015},
  pages               = {247-252},
  publisher           = {Association for Computing Machinery, Inc},
  note                = {cited By 2},
  abbrev_source_title = {e-Energy - Proc. ACM Int. Conf. Future Energy Syst.},
  abstract            = {An innovative approach for increasing the energy efficiency of Data Centers is discussed. This approach views Data Centers as active load resources, integrated in the context of the smart city and operated in a coordinated manner. Data Centers can thus contribute to establishing sustainable, local, energy management ecosystems on a smart city level, while enabling optimized operation of the involved energy grids. To that end, the development of local marketplaces will allow for trading surplus of energy, both electricity and thermal, and provide local balancing flexibility as ancillary services. Reinforcing this vision, innovative business models are proposed that enable next generation of smart Net-zero Energy Data Centers acting as energy prosumers at the interface with smart energy grids within a smart city environment. Simulation experiments are conducted using the GEYSER defined Data Centers flexibility models and non-linear optimization techniques. Such simulations are used to evaluate the Data Centers energy demand flexibility in meeting various network level goals. © 2015 ACM.},
  affiliation         = {Engineering Ingegneria Informatica, Via S. M. della Battaglia 56, Rome, Italy; Technical University of Cluj-Napoca, Baritiu 26, Cluj-Napoca, Romania; Singular Logic, Al. Panagouli and Siniosoglou, Athens, Greece},
  author_keywords     = {Business models; Data center; Demand response; Energy efficiency; Optimization; Smart grid},
  document_type       = {Conference Paper},
  doi                 = {10.1145/2768510.2768522},
  isbn                = {9781450336093},
  journal             = {e-Energy 2015 - Proceedings of the 2015 ACM 6th International Conference on Future Energy Systems},
  keywords            = {Commerce; Electric power transmission networks; Energy efficiency; Energy management; Nonlinear programming; Optimization, Business models; Data centers; Demand response; Innovative approaches; Next generation data centers; Non-linear optimization; Optimized operations; Smart grid, Smart power grids},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961248502&doi=10.1145%2f2768510.2768522&partnerID=40&md5=3c0cf11d428b5869b809d4bb1ca46970},
}

@Article{Avelar20154,
  author                  = {Avelar, E. and Marques, L. and Dos Passos, D. and Macedo, R. and Dias, K. and Nogueira, M.},
  title                   = {Interoperability issues on heterogeneous wireless communication for smart cities},
  journal                 = {Computer Communications},
  year                    = {2015},
  volume                  = {58},
  pages                   = {4-15},
  issn                    = {01403664},
  note                    = {cited By 14},
  abbrev_source_title     = {Comput Commun},
  abstract                = {Smart cities have become a reality around the world. They rely on wireless communication technologies, and they have provided many benefits to society, such as monitoring road traffic in real-time, giving continuous healthcare assistance to residents and managing the environment. This article revisits key interoperability questions in heterogeneous wireless networks for smart cities, and outlines a simple, modular architecture to deal with these complex issues. The architecture is composed by sensing, access network, Internet/cloud and application layers. Different features provided by the architecture, such as interoperability among technologies, low cost, reliability and security, have been evaluated through experiments and simulations under different scenarios. The QoS support and the seamless connectivity between pairs of heterogeneous technologies are proposed through a policy-based management (PBM) framework and MIH (Media Independent Handover). Moreover, an 802.11 mesh backbone composed of different types of mesh routers has been deployed for interconnecting the sensors and actuators to the Internet. Key results from experiments in the backbone are examined. They compare: (i) the performance of a single-path routing protocol (OLSR) with a multipath one (MP-OLSR); (ii) the monitoring delays from the proposed low cost sunspot/mesh and arduino/mesh gateways; and (iii) the authentication mechanisms employed. Significant results from simulations allow the analysis of the reliability on vehicular/mesh networks under jamming attacks by applying the OLSR and MP-OLSR routing protocols. Finally, this article provides an overview of open research questions. © 2014 Elsevier B.V.},
  affiliation             = {Federal University of Pernambuco (UFPE), Brazil; Federal University of Paraná (UFPR), Brazil},
  author_keywords         = {Architecture; Heterogeneous wireless communication; Interoperability; Low cost; Smart cities},
  coden                   = {COCOD},
  correspondence_address1 = {Nogueira, M.; Federal University of Paraná (UFPR)Brazil},
  document_type           = {Article},
  doi                     = {10.1016/j.comcom.2014.07.005},
  keywords                = {Architecture; Complex networks; Costs; Heterogeneous networks; Internet; Mobile telecommunication systems; Network architecture; Reliability analysis; Routing protocols; Wireless telecommunication systems, Authentication mechanisms; Heterogeneous technology; Heterogeneous wireless network; Low costs; Media independent handover; Smart cities; Wireless communication technology; Wireless communications, Interoperability},
  language                = {English},
  publisher               = {Elsevier},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923693945&doi=10.1016%2fj.comcom.2014.07.005&partnerID=40&md5=0875e06944159db39f6c3d67ceffcb9e},
}

@Conference{Psyllidis2015,
  author                  = {Psyllidis, A.},
  title                   = {Ontology-based data integration from heterogeneous urban systems: A knowledge representation framework for smart cities},
  year                    = {2015},
  publisher               = {CUPUM},
  note                    = {cited By 6},
  abbrev_source_title     = {CUPUM - Int. Conf. Comput. Urban Plan. Urban Manag.},
  abstract                = {This paper presents a novel knowledge representation framework for smart city planning and management that enables the semantic integration of heterogeneous urban data from diverse sources. Currently, the combination of information across city agencies is cumbersome, as the increasingly available datasets are stored in disparate data silos, using different models and schemas for their description. To overcome this interoperability barrier, the presented framework employs a modular and scalable system architecture, comprising a comprehensive ontology capable of integrating data from various sectors within a city, a web ontology browser, and a web-based knowledge graph for online data discovery, mapping, and sharing across stakeholders. Linked Data, Semantic Web technologies, and ontology matching techniques are key to the framework's implementation. The paper ultimately showcases an application example, where the framework is used as a semantic enrichment mechanism in a platform for urban analytics, focusing particularly on human-generated data integration.},
  affiliation             = {Hyperbody - Digitally-driven Architecture, Department of Architectural Engineering and Technology, Faculty of Architecture and the Built Environment, Delft University of Technology (TU Delft), Delft, 2628 BL, Netherlands},
  correspondence_address1 = {Psyllidis, A.; Hyperbody - Digitally-driven Architecture, Department of Architectural Engineering and Technology, Faculty of Architecture and the Built Environment, Delft University of Technology (TU Delft)Netherlands; email: A.Psyllidis@tudelft.nl},
  document_type           = {Conference Paper},
  isbn                    = {9780692474341},
  journal                 = {CUPUM 2015 - 14th International Conference on Computers in Urban Planning and Urban Management},
  keywords                = {Data integration; Interoperability; Knowledge representation; Ontology; Smart city; Urban planning, Application examples; Knowledge graphs; Ontology matching; Ontology-based; Scalable systems; Semantic enrichment; Semantic integration; Semantic Web technology, Information management},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992380859&partnerID=40&md5=4a4fbbc6dd0390f33fdf9329e07a914b},
}

@Conference{Atasoy2015547,
  author              = {Atasoy, T. and Akinc, H.E. and Ercin, O.},
  title               = {An analysis on smart grid applications and grid integration of renewable energy systems in smart cities},
  year                = {2015},
  pages               = {547-550},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 13},
  abbrev_source_title = {Int. Conf. Renew. Energy Res. Appl., ICRERA},
  abstract            = {A smart city consists of several components such as governance, mobility, economy and energy that play a key role in transition towards a sustainable urban life, integrating critical infrastructure and various stakeholders. Smart cities are a logical extension of the smart grid concept and realization of smart cities are tightly connected to the process of modernization of traditional power systems. This paper provides an analysis on the strong link between the two concepts, focusing on grid integration of renewable energy resources, energy storage systems, electric vehicles and smart lighting concepts in sustainable smart cities. © 2015 IEEE.},
  affiliation         = {R and D and Automation Management, Enerjisa Electricity Distribution Company, Ankara, Turkey},
  art_number          = {7418473},
  author_keywords     = {distributed generation; energy storage; ICT; renewable energy; smart city; smart grid},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICRERA.2015.7418473},
  isbn                = {9781479999828},
  journal             = {2015 International Conference on Renewable Energy Research and Applications, ICRERA 2015},
  keywords            = {Distributed power generation; Electric power transmission networks; Energy resources; Energy storage; Renewable energy resources; Smart city, Energy storage systems; Grid integration; Renewable energies; Smart grid; Smart grid applications; Smart lightings; Strong link; Traditional power system, Smart power grids},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964584250&doi=10.1109%2fICRERA.2015.7418473&partnerID=40&md5=c5dba8564d586882aa221efbd6331a60},
}

@Article{Banerjee2015113,
  author              = {Banerjee, P. and Kumar, A. and Jain, G. and Gupta, A. and Jain, S.},
  title               = {Integration of procurement system using technology in making smarter cities in India},
  journal             = {International Journal of Applied Engineering Research},
  year                = {2015},
  volume              = {10},
  number              = {69},
  pages               = {113-116},
  issn                = {09734562},
  note                = {cited By 0},
  abbrev_source_title = {Int. J. Appl. Eng. Res.},
  abstract            = {Ineffective procurement of materials and mismanagement of these materials in a construction project can significantly impact on project performance by causing delays and cost-overruns. A different project has shown that construction materials and equipment may constitute more than 70% of the total cost for a typical construction project. Implementation of innovative technology for integrating the process of procurement and materials management can be a response to these challenges as providing the project engineering and management teams with online accessible information during entire project lifecycle will enable effective materials management, deliver cost benefits and improve efficiency of procurement process. Through this research our objective is to develop a concept of deploying procurement management through Information Technology (IT) in Smart city projects and try to overcome the drawbacks and barriers to effective implementation of e-Procurement in the present Indian scenario. © Research India Publications.},
  affiliation         = {NICMAR, Pune, India},
  author_keywords     = {Construction projects; Eprocurement; Information technology; Smart city},
  document_type       = {Article},
  language            = {English},
  publisher           = {Research India Publications},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942410892&partnerID=40&md5=f0cfb511ad12db0a0c243c261e0cea43},
}

@Conference{Bululukova2015101,
  author              = {Bululukova, D. and Wahl, H.},
  title               = {Towards a sustainable smart cities integration in teaching and research},
  year                = {2015},
  editor              = {Donnellan B., Klein C., Helfert M., Krempels K.-H.},
  pages               = {101-106},
  publisher           = {SciTePress},
  note                = {cited By 1},
  abbrev_source_title = {SMARTGREENS - Int. Conf. Smart Cities Green ICT Syst., Proc.},
  abstract            = {The urban population growth and rapid urbanization are the key issues many of the European cities are currently dealing with. Vienna, as the one of the leading cities, embodies the smart cities goals and values. The new Smart City Wien Framework Strategy is more than a technological approach, furthermore, it emphasises importance of the social innovation. Nevertheless, the strategy lacks concrete goals for academic research and smart cities integration into educational programs. Little to no academic research discusses smart cities oriented study programs. This paper aims to close existing gap and proposes exemplary practical approach to integrate smart cities concepts at the academic level. Starting with the basic evaluation of the existing smart cities relevant study programs in the European area, we elaborate three interacting tracks for implementation: educational Web platform, postgraduate program and cross-departmental study programs including student projects. A practical, professional field-oriented and diversity-fair approach is chosen. The paper describes the status quo of the implementation process and in particular a cross-departmental study program. This exemplary implementation concept of smart cities may serve as a basis for universities with practice-oriented education to utilize own smart cities related studies.},
  affiliation         = {Institute of Information Engineering and Security, University of Applied Sciences Technikum Wien, Hoechstaedtplatz 6, Vienna, 1200, Austria},
  author_keywords     = {Holistic education; Learning platform; Lifelong learning; Smart cities education; Smart energy; Smart mobility},
  document_type       = {Conference Paper},
  isbn                = {9789897581052},
  journal             = {SMARTGREENS 2015 - 4th International Conference on Smart Cities and Green ICT Systems, Proceedings},
  keywords            = {Population statistics; Urban growth, Holistic educations; Learning platform; Life long learning; Smart cities; Smart energies, Education},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938799357&partnerID=40&md5=a9852d80461a9ccbc4a24c89dcb756f7},
}

@Article{Mattoni2015105,
  author                  = {Mattoni, B. and Gugliermetti, F. and Bisegna, F.},
  title                   = {A multilevel method to assess and design the renovation and integration of Smart Cities},
  journal                 = {Sustainable Cities and Society},
  year                    = {2015},
  volume                  = {15},
  pages                   = {105-119},
  issn                    = {22106707},
  note                    = {cited By 63},
  abbrev_source_title     = {Sustainable Cities Soc.},
  abstract                = {Contemporary cities are the scenes of sudden and numerous changes from social, economical and environmental points of view. The capability for cities to endorse, foster, enhance ongoing transformations and modern challenges is obstructed by the unsuitableness and lack of communication and integration of both material and immaterial infrastructures. The new vision of Smart Cities can fill these gaps, as it represents a balance among hardware and software aspects, technology and human capital, and it aims at realizing and guaranteeing the quality of life to the inhabitants. At today, there is absence of uniformity both in the definition and in the concept development of a Smart City, and there are not practical methodologies supporting the evaluation models developed in literature. The approach often does not appear as a holistic, complete and integrated, but as a combination of sector-based non communicating and non integrated actions. In this framework, the aim of this paper is to outline a planning methodology of actions to realize a Smart City that provides a holistic and specific approach to territories and cities by taking into account the specific features of the context and by developing different and appropriate strategies. According to this, a way to integrate the various aspects of a Smart City through the definition of the relations existing among all the subsystems of the city, considered as a whole (human) organism, has been developed. © 2014 Elsevier Ltd. All rights reserved.},
  affiliation             = {Sapienza University of Rome, Department of Astronautical, Electrical and Energetic Engineering, Via Eudossiana 18, Rome, 00184, Italy},
  author_keywords         = {Methodology; Network; Smart Cities},
  correspondence_address1 = {Bisegna, F.; Sapienza University of Rome, Department of Astronautical, Electrical and Energetic Engineering, Via Eudossiana 18, Italy},
  document_type           = {Article},
  doi                     = {10.1016/j.scs.2014.12.002},
  language                = {English},
  publisher               = {Elsevier Ltd},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925345881&doi=10.1016%2fj.scs.2014.12.002&partnerID=40&md5=57c16a4559ccb745a301c362eddccd2b},
}

@Article{Otero-Cerdeira201423581,
  author                  = {Otero-Cerdeira, L. and Rodríguez-Martínez, F.J. and Gómez-Rodríguez, A.},
  title                   = {Definition of an ontology matching algorithm for context integration in smart cities},
  journal                 = {Sensors (Switzerland)},
  year                    = {2014},
  volume                  = {14},
  number                  = {12},
  pages                   = {23581-23619},
  issn                    = {14248220},
  note                    = {cited By 8},
  abbrev_source_title     = {Sensors},
  abstract                = {In this paper we describe a novel proposal in the field of smart cities: using an ontology matching algorithm to guarantee the automatic information exchange between the agents and the smart city. A smart city is composed by different types of agents that behave as producers and/or consumers of the information in the smart city. In our proposal, the data from the context is obtained by sensor and device agents while users interact with the smart city by means of user or system agents. The knowledge of each agent, as well as the smart city’s knowledge, is semantically represented using different ontologies. To have an open city, that is fully accessible to any agent and therefore to provide enhanced services to the users, there is the need to ensure a seamless communication between agents and the city, regardless of their inner knowledge representations, i.e., ontologies. To meet this goal we use ontology matching techniques, specifically we have defined a new ontology matching algorithm called OntoPhil to be deployed within a smart city, which has never been done before. OntoPhil was tested on the benchmarks provided by the well known evaluation initiative, Ontology Alignment Evaluation Initiative, and also compared to other matching algorithms, although these algorithms were not specifically designed for smart cities. Additionally, specific tests involving a smart city’s ontology and different types of agents were conducted to validate the usefulness of OntoPhil in the smart city environment. © 2014 by the authors; licensee MDPI, Basel, Switzerland.},
  affiliation             = {LIA2 Group, Computer Science Department, University of Vigo, Galicia, 32004, Spain},
  author_keywords         = {Ambient intelligence; Context-awareness; Information fusion; Multi-agent system; Ontology; Ontology matching; Smart city},
  correspondence_address1 = {Otero-Cerdeira, L.; LIA2 Group, Computer Science Department, University of VigoSpain},
  document_type           = {Article},
  doi                     = {10.3390/s141223581},
  keywords                = {Information fusion; Intelligent agents; Knowledge representation; Multi agent systems; Ontology; User interfaces, Ambient intelligence; Automatic information; Context- awareness; Matching algorithm; Ontology alignment; Ontology matching; Seamless communication; Smart cities, Algorithms},
  language                = {English},
  publisher               = {MDPI AG},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924691922&doi=10.3390%2fs141223581&partnerID=40&md5=b8bdc149a6acee9e1a58dd7970dc24d2},
}

@Article{Orłowski2014136,
  author                  = {Orłowski, C.},
  title                   = {Rule-based model for selecting integration technologies for smart cities systems},
  journal                 = {Cybernetics and Systems},
  year                    = {2014},
  volume                  = {45},
  number                  = {2},
  pages                   = {136-145},
  issn                    = {01969722},
  note                    = {cited By 1},
  abbrev_source_title     = {Cybern Syst},
  abstract                = {The aim of this article is to present the stages of development for an information technology integration model for the design of systems for smart cities. The Introduction explains the need for integration technologies and presents a model for selecting integration technologies and the conditions for its use in designing smart cities systems. Then two verification stages of the presented model are discussed. In the first stage, the model underwent a replicative verification in the Eureka project, the purpose of which was to build fuzzy decision-making scenarios for the needs of smart cities. In the second stage, the developed model underwent a predictive verification process that aimed at selecting integration technologies (suggested by the developed model) in the construction of an intelligent operating center (IOC) decision-making system. The article is summarized with conclusions and observations about the importance of integration technologies and the possibility of predicting them. © 2014 Copyright Taylor & Francis Group, LLC.},
  affiliation             = {IBM Center for Advanced Studies on Campus, Gdánsk, Narutowicza 11/12, Koszalin, Śniadeckich 2, Poland},
  author_keywords         = {rule based model; smart models},
  coden                   = {CYSYD},
  correspondence_address1 = {Orłowski, C.; IBM Center for Advanced Studies on Campus, Gdánsk, Narutowicza 11/12, Koszalin, Śniadeckich 2, Poland; email: cor@zie.pg.gda.pl},
  document_type           = {Article},
  doi                     = {10.1080/01969722.2014.874811},
  keywords                = {Decision-making systems; Developed model; Fuzzy decision-making; Integration technologies; Operating centers; Rule-based models; Technology Integration; Verification process, Decision making; Electronic commerce; Information technology, Integration},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897894695&doi=10.1080%2f01969722.2014.874811&partnerID=40&md5=42ef33ba4b98fea402bb4db3865b7cd8},
}

@Conference{Maeomichi2014365,
  author              = {Maeomichi, H. and Tsutsui, A.},
  title               = {Interoperability enhancement for virtualization of sensors for smart cities},
  year                = {2014},
  pages               = {365-366},
  publisher           = {IEEE Computer Society},
  note                = {cited By 0},
  abbrev_source_title = {IEEE World Forum Internet Things, WF-IoT},
  abstract            = {We discuss interoperability enhancement for sensor virtualization for smart cities. We propose a model of metadata and data conversion components for interoperability enhancement and introduce our research approach. © 2014 IEEE.},
  affiliation         = {NTT Network Innovation Laboratories, NTT Corporation, Tokyo, Japan},
  art_number          = {6803189},
  author_keywords     = {ClouT; Internet of things; Interoperability; Smart City},
  document_type       = {Conference Paper},
  doi                 = {10.1109/WF-IoT.2014.6803189},
  journal             = {2014 IEEE World Forum on Internet of Things, WF-IoT 2014},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900406711&doi=10.1109%2fWF-IoT.2014.6803189&partnerID=40&md5=c7e54eaf0a9dd3297e3e5c7167da6307},
}

@Conference{Ma2014,
  author              = {Ma, X. and Pogrebna, G. and Ng, I.},
  title               = {Smart home, smart things and smart ME in the smart city: The hub-of-all-things resource integration and enabling tool (HARRIET)},
  year                = {2014},
  volume              = {2014},
  number              = {15564},
  publisher           = {Institution of Engineering and Technology},
  note                = {cited By 4},
  abbrev_source_title = {IET Semin Dig},
  abstract            = {Smart' homes with "smart" things working together in the smart city as one coherent and dynamic system to help individuals make "smarter" decisions. This paper presents multi-disciplinary research from the HAT project and its extension, the HARRIET project, on the creation of the first ever Multi-sided Market Platform for the exchange of data enabled by the Internet-of-Things. This allows individuals to trade their personal data for personalised products and services in the future, and assists individuals to better understand their household consumption behaviour and make "smarter" decisions to plan and live better lives, based on their personal data. The research subscribes to a mindset of enabling, 'nudging' and prompting consumers to become 'smart' through the use of their personal data vs the conventional thinking of making smart products and/or devices. Personal data can be a valuable asset for consumers to use and trade with product and service providers (businesses) in exchange for better-customised products and services or even cash rewards; and for product and service providers who, by creating more customised products/services in a scalable way through the platform, could increase customer value and thereby improve revenues.},
  affiliation         = {University of Warwick, United Kingdom; Department of Marketing and Service Systems, University of Warwick, United Kingdom},
  author_keywords     = {Behavioural Science; Information Systems; Internet of Things; Personal Data; Service System},
  document_type       = {Conference Paper},
  doi                 = {10.1049/ic.2014.0050},
  journal             = {IET Seminar Digest},
  keywords            = {Automation; Commerce; Data privacy; Information systems; Intelligent buildings; Internet; Internet of things, Behavioural science; Customer values; Household Consumption; Multi-disciplinary research; Product and services; Products and services; Resource integration; Service systems, Behavioral research},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949499226&doi=10.1049%2fic.2014.0050&partnerID=40&md5=40594af55adbcdc2c08dbb0617daafba},
}

@Conference{Cledou2014536,
  author                  = {Cledou, G.},
  title                   = {A virtual factory for Smart City Service Integration},
  year                    = {2014},
  editor                  = {Barbosa L.S., Estevez E., Janssen M.},
  volume                  = {2014-January},
  pages                   = {536-539},
  publisher               = {Association for Computing Machinery},
  note                    = {cited By 1},
  abbrev_source_title     = {ACM Int. Conf. Proc. Ser.},
  abstract                = {In the last years, new technologies - referred as emerging information and communication technologies (EICTs), have appeared and are immersed in peoples' lives assisting them and facilitating their daily activities. Taking advantage of the diffusion and infusion of these technologies, governments are using EICTs to deliver better public services to citizens. However, to address citizens' demands and to provide customer oriented services governments face various types of challenges. The aim of this research work is to provide solutions to some of the challenges, in particular to the rapid development of electronic public services (EPS) and the service integration in the context of development of smart cities. Following the aim, we propose an approach, called Virtual Factory for Smart City Service Integration. The idea of the virtual factory is to provide a framework to automatically produce software based on a given set of specifications of a family of EPS taking advantage of similarities in the EPS business processes. The expected contributions of this research work is to produce a domain specific language (DSL) for service specification and supporting tools that based on the produced specifications, workflow techniques and ideas of software product lines (SPL) can automatically produce software applications for EPS that can be easily parameterized and completed. Copyright 2014 ACM.},
  affiliation             = {HASLab INESC TEC, Universidade Do Minho, Portugal},
  author_keywords         = {Domain specific language; E-government; Formal methods; Service integration; Smart cities; Software product line; Workflows},
  correspondence_address1 = {Cledou, G.; HASLab INESC TEC, Universidade Do MinhoPortugal},
  document_type           = {Conference Paper},
  doi                     = {10.1145/2691195.2691288},
  isbn                    = {9781605586113},
  journal                 = {ACM International Conference Proceeding Series},
  keywords                = {Computational linguistics; Computer programming languages; Computer software; DSL; Formal methods; Formal specification; Government data processing; Problem oriented languages; Software design; Specifications, Domain specific languages; E-governments; Service integration; Smart cities; Software Product Line; Work-flows, Application programs},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939149389&doi=10.1145%2f2691195.2691288&partnerID=40&md5=c6312a0570b68bc7caabe429d33ecd27},
}

@Conference{Chang2014,
  author              = {Chang, E.C.-P. and Yan, Z.},
  title               = {From Intelligent Transport System (ITS) integration to effective Smart City (SC) implementation - An overview for global knowledge management},
  year                = {2014},
  publisher           = {Intelligent Transport Systems (ITS)},
  note                = {cited By 0},
  abbrev_source_title = {World Congr. Intell. Transp. Syst., ITSWC: Reinventing Transp. Connect. World},
  abstract            = {Significant development has been made, in the past two decades, in deploying various Intelligent Transportation Systems (ITS) by operating agencies throughout world. The World Bank has been actively involved in funding and supporting various ITS projects, including public transport, fleet management, vehicular/pedestrian detectors, signal controllers, communication systems, and information exchange platforms and needed information for incoming Digital City (DC) and Smart City (SC) implementation through improved Information Communication Technology (ICT) backbone. As China is seeking to promote "smart city" development and many cities now see themselves as "smart cities", in which economic development and service delivery is facilitated by improved ICT services with high-speed communications networks, databases, big-data applications, etc. One major component of smart cities is ITS due to its impact on: (a) flow of people and goods; (b) public safety; (c) cleaner environment, etc. Several WB ITS projects have been successfully implemented in China. As new ICT/ITS technologies become available, there is an increasing need to elevate the existing planning, design, procurement, operation, and evaluation practice into the next level. This short note discussed the eminent needs to: (1) address the critical planning, design, implementation, and evaluation gaps, (2) recommend World Bank procurement changes, and (3) suggest the enhancement and added technical assistance that could better accommodate the increasing SC/DC and ICT implementation through the past system integration experience. Much experience can be learned from the past and ongoing ITS/SC/DC/ICT project implementations from China and overseas, and the results could be readily implemented immediately on the ongoing World Bank financed ITS systems. The valuable insights would not only improve future ITS system implementation, share operational practice through improved Knowledge Base Management/Community of Practice (COP), and lead to better manage clients' expectation, stage implementation, utilize valuable human resource from both WB and clients' sides, but also improve the integrated experience already in place.},
  affiliation         = {EDCPC, Inc. (USA), 8720, Snowhill Ct., Potomac, MD 20854, United States; World Bank China Headquarter, China},
  author_keywords     = {Digital City; Integrated Transport; ITS; Smart City; Traffic Management},
  document_type       = {Conference Paper},
  journal             = {21st World Congress on Intelligent Transport Systems, ITSWC 2014: Reinventing Transportation in Our Connected World},
  keywords            = {Advanced public transportation systems; Advanced traffic management systems; Big data; Fleet operations; Highway traffic control; Human resource management; Intelligent systems; Intelligent vehicle highway systems; Knowledge based systems; Knowledge management; Multicasting; Supply chains; Traffic control; Transportation; Transportation personnel, Digital cities; Integrated transport; ITS; Smart cities; Traffic management, Information management},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929223802&partnerID=40&md5=0912f4e1033ed6af704cc0d0144c94b8},
}

@Article{Montanelli20143,
  author                  = {Montanelli, S. and Castano, S. and Genta, L.},
  title                   = {Urban information integration through smart city views},
  journal                 = {International Journal of Knowledge and Learning},
  year                    = {2014},
  volume                  = {9},
  number                  = {1-2},
  pages                   = {3-22},
  issn                    = {17411009},
  note                    = {cited By 0},
  abbrev_source_title     = {Int. J. Knowl. Learn.},
  abstract                = {Obtaining a tailored and integrated information about events and points of interest of an urban area is becoming a major challenging issue for users like citizens and tourists that aim ateffectively enjoying the urban life initiatives. Inthis paper, we propose a comprehensive approach for urban information integration based on: i) similarity clusters, to aggregate web contents with different nature but similar topic; ii) smart city views, to package and deliver tailored cluster contents to the final users filtered according to user interest, geo-location, and time-based criteria, and iii) crowdsourced recommendations, to highlight the city view contents based on event freshness and popularity. © 2014 Inderscience Enterprises Ltd.},
  affiliation             = {Department of Computer Science, Università degli Studi di Milano, Via Comelico, 39, Milano, 20135, Italy},
  author_keywords         = {Crowdsourcing-based recommendations; Smart city view; Urban information integration},
  correspondence_address1 = {Montanelli, S.; Department of Computer Science, Università degli Studi di Milano, Via Comelico, 39, Italy},
  document_type           = {Article},
  doi                     = {10.1504/IJKL.2014.067147},
  language                = {English},
  publisher               = {Inderscience Enterprises Ltd.},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929142771&doi=10.1504%2fIJKL.2014.067147&partnerID=40&md5=0490ac3de699de4e6c4920980f86b5fd},
}

@Conference{Krimmling201473,
  author              = {Krimmling, J. and Peter, S.},
  title               = {Integration and evaluation of intrusion detection for CoAP in smart city applications},
  year                = {2014},
  pages               = {73-78},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 7},
  abbrev_source_title = {IEEE Conf. Commun. Netw. Secur., CNS},
  abstract            = {The Constrained Application Protocol (CoAP) is a promising candidate for future smart city applications that run on resource-constrained devices. However, additional security means are mandatory to cope with the high security requirements of smart city applications. We present a framework to evaluate lightweight intrusion detection techniques for CoAP applications. This framework combines an OMNeT++ simulation with C/C++ application code that also runs on real hardware. As the result of our work, we used our framework to evaluate intrusion detection techniques for a smart public transport application that uses CoAP. Our first evaluations indicate that a hybrid IDS approach is a favorable choice for smart city applications. © 2014 IEEE.},
  affiliation         = {IHP, Frankfurt (Oder), Germany; University of California, Irvine, United States},
  art_number          = {6997468},
  author_keywords     = {Critical Infrastructure protection; Intrusion detection; OMNeT++; Simulation; Smart city},
  document_type       = {Conference Paper},
  doi                 = {10.1109/CNS.2014.6997468},
  isbn                = {9781479958900},
  journal             = {2014 IEEE Conference on Communications and Network Security, CNS 2014},
  keywords            = {C (programming language); Electronic commerce; Network security; Secure communication, Application codes; Constrained Application Protocol (CoAP); Critical infrastructure protection; OMNeT; Public transport; Resourceconstrained devices; Simulation; Smart cities, Intrusion detection},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921499880&doi=10.1109%2fCNS.2014.6997468&partnerID=40&md5=6eb05a439d8381d9bf40c7ed84e1c64a},
}

@Conference{Diez2014,
  author              = {Diez, L.F. and Anwar, S.M. and De Lope, L.R. and Hennaff, M.L. and Toutain, Y. and Aguero, R.},
  title               = {Design and integration of a low-complexity dosimeter into the smart city for EMF assessment},
  year                = {2014},
  publisher           = {IEEE Computer Society},
  note                = {cited By 4},
  abbrev_source_title = {EuCNC - Eur. Conf. Networks Commun.},
  abstract            = {Despite the increasing usage of mobile communications, strengthened by the growing penetration of smartphones, end users seem to be concerned about the potential health risks of the electromagnetic fields (EMF) induced by such technologies, according to the latest statistics gathered by the Eurobarometer. The Low EMF Exposure Networks (LEXNET) project aims at designing techniques able to reduce the corresponding exposure, without jeopardizing the quality of experience perceived by the end-users. In order to tackle that goal, a first step must be to accurately estimate such exposure, even in large areas, and with real operating networks. This paper introduces the work that is being carried out to deploy a number of low-complexity dosimeters to characterize the EMF at four different bands. The devices exploit the facilities provided by a wireless sensor network testbed, and are therefore integrated as another IoT (Internet of Things) node. The preliminary measurements that are discussed in the paper assess the validity and feasibility of this novel methodology, which provides clear advantages to other traditional procedures, such as the use of drive tests and/or spectrum analyzers. © 2014 IEEE.},
  affiliation         = {Universidad de Cantabria, Avda. de los Castros s/n., 39005 Santander, Spain; SATIMO Industries, Microwavevision Group, Brest, France},
  art_number          = {6882637},
  document_type       = {Conference Paper},
  doi                 = {10.1109/EuCNC.2014.6882637},
  isbn                = {9781479952809},
  journal             = {EuCNC 2014 - European Conference on Networks and Communications},
  keywords            = {Dosimeters; Electromagnetic fields; Spectrum analyzers; Wireless sensor networks, Design and integrations; Designing techniques; Iot( internet of things); Mobile communications; Novel methodology; Potential health risks; Quality of experience (QoE); Wireless sensor network test beds, Complex networks},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906987186&doi=10.1109%2fEuCNC.2014.6882637&partnerID=40&md5=d31c366403e6043eb4070ed21894b12c},
}

@Conference{Vakali2014,
  author              = {Vakali, A. and Anthopoulos, L. and Krco, S.},
  title               = {Smart cities data streams integration: Experimenting with internet of things and social data flows},
  year                = {2014},
  publisher           = {Association for Computing Machinery},
  note                = {cited By 18},
  abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
  abstract            = {Smart cities are nowadays expanding and flourishing worldwide with Internet of Things (IoT), i.e. smart things like sensors and actuators, and mobile devices applications and installations which change the citizens' and authorities' everyday life. Smart cities produce daily huge streams of sensors data while citizens interact with Web and/or mobile devices utilizing social networks. In such a smart city context, new approaches to integrate big data streams from both sensors and social networks are needed to exploit big data production and circulation towards offering innovative solutions and applications. The SmartSantander infrastructure (EU FP7 project) has offered the ground for the SEN2SOC experiment which has integrated sensor and social data streams. This presentation outlines its research and industrial perspective and potential impact. © 2014 ACM.},
  affiliation         = {Informatics Department, Aristotle University, 54124 Thessaloniki, Greece; Department of Business Administration, TEI of Thessaly, 41110 Larissa, Greece; Ericsson Belgrada, Serbia},
  author_keywords     = {Data Management; Data Modeling; Smart City; Smart Government; Smart People; Visualization},
  document_type       = {Conference Paper},
  doi                 = {10.1145/2611040.2611094},
  isbn                = {9781450325387},
  journal             = {ACM International Conference Proceeding Series},
  keywords            = {Big data; Data communication systems; Data structures; Data visualization; Electronic commerce; Flow visualization; Industrial research; Information management; Mobile devices; Semantic Web; Semantics; Sensors; Social networking (online), Innovative solutions; Integrated sensors; Internet of Things (IOT); Mobile devices applications; Sensors and actuators; Smart cities; Smart Government; Smart People, Internet of things},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903648127&doi=10.1145%2f2611040.2611094&partnerID=40&md5=807fc04fa36d3e61d7e4b71bf1c79765},
}

@Conference{Cohen2014,
  author              = {Cohen, S. and Money, W. and Quick, M.},
  title               = {Improving integration and insight in smart cities with policy and trust},
  year                = {2014},
  publisher           = {Association for Computing Machinery},
  note                = {cited By 1},
  abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
  abstract            = {This paper examines the issues of policy and trust in the context of IT infrastructures for Smart Cities. This paper proposes that trusted Smart city policies can lead to the development of trusted foundational service underlying all smart city solutions. Such a set services are critical for architectural choices of data integration and use within smart city domains, and will lead to the development of a marketplace where service providers and consumers engage in a free and fully informed exchange to choose worthy and reliable experiences to address everything from reporting street light outage to identifying economic advantages during city planning. It argues that two usually mutually exclusive architectural meta-models; Centralization and Federation, are required to achieve a set of trusted foundational services. It reviews the large array of options for implementing the marketplace component of the foundational services to support scenarios varying from fully isolated well known analytics to the anonymous access that allows potential users to browse for services without any controls. It concludes that Trusted Policies are highly important as successful ingredients in the development of foundational services and the following developmental stage, and in the operations and maintenance stages for integrated Smart city systems. It is critical that Smart cities systems implement city-wide policies that improve and sustain trust that in turn help Smart cities manage across the multitude of systems that are in both developmental and operational stages simultaneously, and will be so for many decades to come. © 2014 ACM.},
  affiliation         = {Microsoft, Oakton, VA, United States; George Washington University, Washington, DC, United States},
  author_keywords     = {foundational services; integrated solutions; IT infrastructures; Policy; trust},
  document_type       = {Conference Paper},
  doi                 = {10.1145/2611040.2611091},
  isbn                = {9781450325387},
  journal             = {ACM International Conference Proceeding Series},
  keywords            = {Public policy; Semantic Web; Semantics, Developmental stage; Economic advantages; foundational services; Integrated solutions; IT infrastructures; Operational stages; Operations and maintenance; trust, Electronic commerce},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903641177&doi=10.1145%2f2611040.2611091&partnerID=40&md5=08fa690f7134423e2ca1e3f0376308f9},
}

@Article{Ruiz-Romero2014223,
  author                  = {Ruiz-Romero, S. and Colmenar-Santos, A. and Mur-Pérez, F. and López-Rey, Á.},
  title                   = {Integration of distributed generation in the power distribution network: The need for smart grid control systems, communication and equipment for a smart city - Use cases},
  journal                 = {Renewable and Sustainable Energy Reviews},
  year                    = {2014},
  volume                  = {38},
  pages                   = {223-234},
  issn                    = {13640321},
  note                    = {cited By 52},
  abbrev_source_title     = {Renewable Sustainable Energy Rev},
  abstract                = {The exploitation of renewable energy resources poses great challenges regarding the manner in which they can be integrated into the modern electrical distribution infrastructure. To understand the difficulties of integration of Distributed Generation (DG) in electricity distribution network, the analyses and result of the effects on aspects of power quality are provided, as can be the problem of failure defects in networks and how DG grid connection affects voltage control at both medium-voltage (MV) and low-voltage (LV) levels. Results demonstrated that there was a communication system between all generators protective systems, a selective protective system, a tracking of perturbations system to isolate failure defects, and a phase control system between the generators and the network. Also synchronizing voltage regulation is crucial for guaranteeing the quality of the power supply. Currently, recent and modern technologies allow different services to share a single communications infrastructure while guaranteeing the required levels of security, reliability, and efficiency. This paper aims to provide a Smart City (SC) project, implemented in the city of Malaga, Spain, where the integration of the applications of Smart Grid (SG) and the Use Cases (UCs) for the different functionalities of SG has been developed. The SC architecture proposed envisions a hierarchical, distributed, and autonomous structure to address the challenge of smart distribution grids. As a result of this project, new levels of standardization of languages and protocols and new interconnection functions will be required. These functions will allow smart devices to recognize each other so that they can reconnect in case of failure regardless of the state of the network topology. In conclusion, renewable energy sources (RES) can be optimally integrated into the distribution grid. Generation can approach consumption through the installation of photovoltaic (PV) panels and mini-wind generators, with the reuse of electrical infrastructure. © 2014 Elsevier Ltd.},
  affiliation             = {Department of Control System, Electronics, and Electrical Engineering, UNED, Ciudad Universitaria, 28040 Madrid, Spain},
  author_keywords         = {Distributed generation; Distribution grids; Microgrids; Renewable energy; Smart city; Smart grid},
  coden                   = {RSERF},
  correspondence_address1 = {Colmenar-Santos, A.; Department of Control System, Electronics, and Electrical Engineering, UNED, Ciudad Universitaria, 28040 Madrid, Spain; email: acolmenar@ieec.uned.es},
  document_type           = {Review},
  doi                     = {10.1016/j.rser.2014.05.082},
  keywords                = {Control systems; Defects; Distributed power generation; Electric power systems; Electric power transmission networks; Electric utilities; Integration; Outages; Power quality; Quality control; Renewable energy resources; Smart city; Smart power grids; Voltage regulators, Communications infrastructure; Distribution grid; Electrical infrastructure; Electricity distribution networks; Micro grid; Power distribution network; Renewable energies; Smart grid, Electric power system control},
  language                = {English},
  publisher               = {Elsevier Ltd},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902828833&doi=10.1016%2fj.rser.2014.05.082&partnerID=40&md5=0084856a34a088e25a511255d2869051},
}

@Article{Hu2014260,
  author                  = {Hu, C. and Chen, N. and Guan, Q. and Li, J. and Wang, X. and Yang, X.},
  title                   = {An integration and sharing method for heterogeneous sensors oriented to emergency response in Smart City},
  journal                 = {Jisuanji Yanjiu yu Fazhan/Computer Research and Development},
  year                    = {2014},
  volume                  = {51},
  number                  = {2},
  pages                   = {260-277},
  issn                    = {10001239},
  note                    = {cited By 3},
  abbrev_source_title     = {Jisuanji Yanjiu yu Fazhan},
  abstract                = {It can be said that smart city will be built on the observations of sensors. Nowadays, city sensors have the features of being diverse in sensor type, different in observation mechanism and huge in quantity, and they represent a closed, isolated and autonomous observation scenario. Facing with complex city emergency events, it is inefficient to manage those heterogeneous city sensors via World Wide Web. The scarcity of the real-time, right and reliable data sourced from physical sensors and the inefficiency of emergency response decision-making seriously hinder the "smart" process of emergency response in smart city. We propose a framework for the integrating and sharing of heterogeneous city sensors oriented to emergency response. Firstly those heterogeneous sensors are uniformly described; Secondly we register them into a standard Web-based catalogue service and the registered sensor resources can be on-demand discovered; Thirdly, we construct an integration and sharing platform for city heterogeneous sensors. Last, we use waterlogging emergency response of Wuhan city as the disaster application to verify the feasibility and extensibility of integration and sharing method for heterogeneous flood-related sensors. The result shows that the proposed framework promotes the shift of heterogeneous waterlogging sensors from the observation island to integration management situation, which can lay a solid basis for sensor sharing and observation planning required in smart city emergency response.},
  affiliation             = {Faculty of Information Engineering, China University of Geosciences (Wuhan), Wuhan 430074, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan 430079, China},
  author_keywords         = {Emergency response; Integration management; Sensor resources sharing; Sensor Web; Smart city; Waterlogging},
  coden                   = {JYYFE},
  correspondence_address1 = {Hu, C.; Faculty of Information Engineering, China University of Geosciences (Wuhan), Wuhan 430074, China; email: andyhuli@tom.com},
  document_type           = {Article},
  doi                     = {10.7544/issn1000-1239.2014.20131095},
  keywords                = {Electronic commerce; Integration; Sensors; World Wide Web, Emergency response; Sensor resources; Sensor web; Smart cities; Waterlogging, Emergency services},
  language                = {Chinese},
  publisher               = {Science Press},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896048334&doi=10.7544%2fissn1000-1239.2014.20131095&partnerID=40&md5=fad543b1bbc994ef3b2b10f243d6e039},
}

@Conference{Samaras2013327,
  author                  = {Samaras, C. and Vakali, A. and Giatsoglou, M. and Chatzakou, D. and Angelis, L.},
  title                   = {Requirements and architecture design principles for a smart city experiment with sensor and social networks integration},
  year                    = {2013},
  pages                   = {327-334},
  note                    = {cited By 9},
  abbrev_source_title     = {ACM Int. Conf. Proc. Ser.},
  abstract                = {Smart city infrastructures offer unique testbeds ground for innovative experimentation and services offering. Sensors networks in cities with integrated social networks activities can improve people-centric services, while improving infrastructures setting. This work summarizes the principles and priorities chosen in a smart city experiment, entitled SEN2SOC which bridges sensor measurements and social networks interactions for supporting smart city services. SEN2SOC prioritizes requirements along particular categories which cover data collection, users sensing along with applications implementation and architectural concerns. These requirements are correlated with the suggested components in an architecture which is flexible enough in order to permit various activities control flow in terms of data preprocessing, conditions detection, statistical analysis as well as applications development and social data mining. Copyright © 2013 ACM.},
  affiliation             = {Department of Informatics, Aristotle University, 54124 Thessaloniki, Greece},
  author_keywords         = {Collective aware applications; Sensors data management; Smart city; Social networks mining},
  correspondence_address1 = {Department of Informatics, Aristotle University, 54124 Thessaloniki, Greece},
  document_type           = {Conference Paper},
  doi                     = {10.1145/2491845.2491887},
  isbn                    = {9781450319690},
  journal                 = {ACM International Conference Proceeding Series},
  keywords                = {Applications development; Architecture designs; Networks integration; Sensor measurements; Sensors data; Smart cities; Social data mining; Social networks minings, Computer peripheral equipment; Experiments; Information management; Information science; Network architecture; Sensors; Social networking (online), Electronic commerce},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886410523&doi=10.1145%2f2491845.2491887&partnerID=40&md5=15885115d38c2516e25974beb28a07de},
}

@Article{Sánchez201314438,
  author                  = {Sánchez, L. and Elicegui, I. and Cuesta, J. and Muñoz, L. and Lanza, J.},
  title                   = {Integration of utilities infrastructures in a future internet enabled smart city framework},
  journal                 = {Sensors (Switzerland)},
  year                    = {2013},
  volume                  = {13},
  number                  = {11},
  pages                   = {14438-14465},
  issn                    = {14248220},
  note                    = {cited By 18},
  abbrev_source_title     = {Sensors},
  abstract                = {Improving efficiency of city services and facilitating a more sustainable development of cities are the main drivers of the smart city concept. Information and Communication Technologies (ICT) play a crucial role in making cities smarter, more accessible and more open. In this paper we present a novel architecture exploiting major concepts from the Future Internet (FI) paradigm addressing the challenges that need to be overcome when creating smarter cities. This architecture takes advantage of both the critical communications infrastructures already in place and owned by the utilities as well as of the infrastructure belonging to the city municipalities to accelerate efficient provision of existing and new city services. The paper highlights how FI technologies create the necessary glue and logic that allows the integration of current vertical and isolated city services into a holistic solution, which enables a huge forward leap for the efficiency and sustainability of our cities. Moreover, the paper describes a real-world prototype, that instantiates the aforementioned architecture, deployed in one of the parks of the city of Santander providing an autonomous public street lighting adaptation service. This prototype is a showcase on how added-value services can be seamlessly created on top of the proposed architecture. © 2013 by the authors; licensee MDPI, Basel, Switzerland.},
  affiliation             = {Communications Engineering Department, University of Cantabria, Edificio de Ingeniería de Telecomunicaciones, Plaza de la Ciencia s/n, Santander 39005, Spain},
  author_keywords         = {Future internet; Internet of things; Key performance indicators; Proof-of-concept; Smart city},
  correspondence_address1 = {Sánchez, L.; Communications Engineering Department, University of Cantabria, Edificio de Ingeniería de Telecomunicaciones, Plaza de la Ciencia s/n, Santander 39005, Spain; email: lsanchez@tlmat.unican.es},
  document_type           = {Article},
  doi                     = {10.3390/s131114438},
  keywords                = {Future internet; Internet of Things (IOT); Key performance indicators; Proof of concept; Smart cities, Architecture; Benchmarking; Electronic commerce; Information technology; Internet; Sustainable development, Information services},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886470189&doi=10.3390%2fs131114438&partnerID=40&md5=3562e0dbeea8f6932fd9d4c19302e1be},
}

@Conference{Jung20131361,
  author                  = {Jung, M. and Weidinger, J. and Kastner, W. and Olivieri, A.},
  title                   = {Building automation and smart cities: An integration approach based on a service-oriented architecture},
  year                    = {2013},
  pages                   = {1361-1367},
  note                    = {cited By 19},
  abbrev_source_title     = {Proc. - Int. Conf. Adv. Inf. Networking Appl. Workshops, WAINA},
  abstract                = {Building automation is a vital part of many use cases related to energy efficiency and smart living in the context of smart cities. State of the art building automation systems like KNX, BACnet or ZigBee are based on control networks mainly used for local control scenarios using non-IP communications. This paper presents an integration approach for building automation systems using an IPv6 enabled service-oriented architecture allowing interconnecting heterogeneous technologies into a large-scale distributed control system. Details on the concept, a proof of concept implementation and performance evaluation results of a multi-protocol gateway are presented, offering a per-device IPv6 interface using a novel CoAP/EXI protocol binding for oBIX. The integration approach aims at providing a homogeneous integration layer that can be used to build advanced control scenarios that might arise in the context of smart cities. © 2013 IEEE.},
  affiliation             = {Institute of Computer Aided Automation, Vienna University of Technology, Vienna, Austria; L'Institut Informatique de Gestion, Haute Ecole Specialisee de Suisse Occidentale, Sierre, Switzerland},
  art_number              = {6550585},
  author_keywords         = {Home Automation; Internet of Things; IPv6; Web services},
  correspondence_address1 = {Institute of Computer Aided Automation, Vienna University of Technology, Vienna, Austria},
  document_type           = {Conference Paper},
  doi                     = {10.1109/WAINA.2013.200},
  isbn                    = {9780769549521},
  journal                 = {Proceedings - 27th International Conference on Advanced Information Networking and Applications Workshops, WAINA 2013},
  keywords                = {Building automation; Building automation systems; Evaluation results; Heterogeneous technology; Home automation; Integration approach; Internet of Things (IOT); IPv6, Electronic commerce; Energy efficiency; Gateways (computer networks); Information services; Integration; Intelligent buildings; Service oriented architecture (SOA); Web services, Internet protocols},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881455588&doi=10.1109%2fWAINA.2013.200&partnerID=40&md5=bb08fa0e5407eb17a4b43685db923be2},
}

@Conference{Nemirovski2013,
  author                  = {Nemirovski, G. and Nolle, A. and Sicilia, Á. and Ballarini, I. and Corado, V.},
  title                   = {Data integration driven ontology design, case study smart city},
  year                    = {2013},
  note                    = {cited By 14},
  abbrev_source_title     = {ACM Int. Conf. Proc. Ser.},
  abstract                = {Methods to design of formal ontologies have been in focus of research since the early nineties when their importance and conceivable practical application in engineering sciences had been understood. However, often significant customization of generic methodologies is required when they are applied in tangible scenarios. In this paper, we present a methodology for ontology design developed in the context of data integration. In this scenario, a targeting ontology is applied as a mediator for distinct schemas of individual data sources and, furthermore, as a reference schema for federated data queries. The methodology has been used and evaluated in a case study aiming at integration of buildings' energy and carbon emission related data. We claim that we have made the design process much more efficient and that there is a high potential to reuse the methodology. Copyright © 2013 ACM.},
  affiliation             = {Albstadt-Sigmaringen University of Applied Sciences, Albstadt, Germany; ARC Enginyeria i Arquitectura La Salle, Universitat Ramon Llull, Barcelona, Spain; Department of Energy (DENERG), Politecnico di Torino, Torino, Italy},
  art_number              = {43},
  author_keywords         = {Data integration; Description logic; DL-lite family; Ontology design; Ontology mapping; Semantic web},
  correspondence_address1 = {Albstadt-Sigmaringen University of Applied Sciences, Albstadt, Germany},
  document_type           = {Conference Paper},
  isbn                    = {9781450318501},
  journal                 = {ACM International Conference Proceeding Series},
  keywords                = {Carbon emissions; Description logic; Dl-lite; Engineering science; Focus of researches; Formal ontology; Ontology design; Ontology mapping, Data description; Research; Semantic Web, Data integration},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879743044&partnerID=40&md5=5f9426733906a642e2fba4363b3d5ade},
}

@Conference{Aldama-Nalda2012289,
  author                  = {Aldama-Nalda, A. and Chourabi, H. and Pardo, T.A. and Gil-Garcia, J.R. and Mellouli, S. and Scholl, H.J. and Alawadhi, S. and Nam, T. and Walker, S.},
  title                   = {Smart cities and service integration initiatives in North American cities: A status report},
  year                    = {2012},
  pages                   = {289-290},
  note                    = {cited By 11},
  abbrev_source_title     = {ACM Int. Conf. Proc. Ser.},
  abstract                = {E-government initiatives have been stepping forward in governments of all levels around the world. One of the most important strategies that are being carried is that of providing citizens with a single entry point for services that involve different government entities. The Smart Cities and Service Integration project (hereafter, SmartCities) aims to establish a framework for smart city service integration that would assist in the management of large scale projects related to the integration of services across governments. By using comparative case studies of six cities (New York City, Philadelphia, Seattle, Quebec City, Mexico City, Macao, and Shanghai), the project aims to develop a theoretical framework to guide smart cities service integration. This poster summarizes some of the most important results of the interviewing process. These results correspond to the analysis of four cities in North America: Philadelphia, Quebec City, Seattle and Mexico City. The research project is funded by the Social Sciences and Humanities Research Council of Canada. © 2012 Authors.},
  affiliation             = {Centro de Investigación Y Docencia Económicas, Mexico; Université Laval, Canada; Center for Technology in Government, University at Albany, SUNY, United States; University of Washington, United States},
  author_keywords         = {e-government; local and provincial governments; service integration; smart city},
  correspondence_address1 = {Aldama-Nalda, A.; Centro de Investigación Y Docencia EconómicasMexico; email: fco.aldama@gmail.com},
  document_type           = {Conference Paper},
  doi                     = {10.1145/2307729.2307789},
  isbn                    = {9781450314039},
  journal                 = {ACM International Conference Proceeding Series},
  keywords                = {e-Government; Government entities; Humanities research; Integration of services; Large-scale projects; local and provincial governments; Mexico City; New York city; North American; Philadelphia; Quebec city; Seattle; Service integration; Single entry; smart city; Theoretical framework, Electronic commerce; Government data processing; Humanities computing, Research},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864352476&doi=10.1145%2f2307729.2307789&partnerID=40&md5=b0d3a583de8ddef9c1b3663a89a8023a},
}

@Article{Pol2012258,
  author                  = {Pol, O. and Palensky, P. and Kuh, C. and Leutgöb, K. and Page, J. and Zucker, G.},
  title                   = {Integration of centralized energy monitoring specifications into the planning process of a new urban development area: A step towards smart cities},
  journal                 = {Elektrotechnik und Informationstechnik},
  year                    = {2012},
  volume                  = {129},
  number                  = {4},
  pages                   = {258-264},
  issn                    = {0932383X},
  note                    = {cited By 3},
  abbrev_source_title     = {Elektr. Inf. Tech.},
  abstract                = {New urban development areas are expected to meet highest ecological standards. Beside the construction phase, it is the daily life in neighbourhoods that impacts their carbon footprint. Energy monitoring is a powerful tool for energy analytics, benchmarking, improvements and even real-time energy management on neighbourhood scale. Unfortunately, the standard planning processes on neighbourhood scale do not facilitate seamless monitoring. This paper describes the fundamentals of centralized monitoring on neighbourhood scale, shows the limits of available real-world examples and introduces a current project aiming at tackling some of the lessons learned from previous projects, focusing on the specifications and their integration into the planning process of new urban development areas. © Springer-Verlag 2012.},
  affiliation             = {Energy Department, Austrian Institute of Technology, Giefinggasse 2, 1210 Wien, Austria; E7 Energie Markt Analyse GmbH, Theresianumgasse 7/1/8, 1040 Wien, Austria},
  author_keywords         = {Energy; Monitoring; Neighbourhood; Requirements; Smart city; Specifications},
  correspondence_address1 = {Pol, O.; Energy Department, Austrian Institute of Technology, Giefinggasse 2, 1210 Wien, Austria},
  document_type           = {Article},
  doi                     = {10.1007/s00502-012-0010-7},
  keywords                = {Construction phase; Current projects; Daily lives; Ecological standards; Energy; Energy monitoring; Neighbourhood; Planning process; Real-time energy management; Requirements; Smart city; Urban development, Carbon footprint; Electronic commerce; Monitoring; Urban growth, Specifications},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867210762&doi=10.1007%2fs00502-012-0010-7&partnerID=40&md5=0218b3e16e9791758cb1ec10a525c876},
}

@Conference{Nam2011333,
  author                  = {Nam, T. and Aldama, F.A. and Chourabi, H. and Mellouli, S. and Pardo, T.A. and Gil-Garcia, J.R. and Scholl, H.J. and Ojo, A. and Estevez, E. and Zheng, L.},
  title                   = {Smart cities and service integration},
  year                    = {2011},
  pages                   = {333-334},
  note                    = {cited By 4},
  abbrev_source_title     = {ACM Int. Conf. Proc. Ser.},
  abstract                = {E-government advancements have not fully resolved the challenge of providing citizens with a single entry point for services that involve different government entities. The Smart Cities and Service Integration project (hereafter, SmartCities) aims to establish a framework for smart city service integration that would assist in the management of large scale projects related to the integration of services across governments. By using comparative case studies of six cities (New York City, Seattle, Quebec City, Mexico City, Macao, and Shanghai), the project aims to develop a theoretical framework to guide smart cities service integration. The project will highlight integration of public services and cross-boundary information sharing by focusing on specific policy domains. An additional goal of this project is to develop research capabilities of graduate students who participate in the research. The research project is funded by the Social Sciences and Humanities Research Council of Canada. © 2011 Authors.},
  affiliation             = {Center for Technology in Government, University at Albany, SUNY, United States; Centro de Investigación Y Docencia Económicas, Mexico; Université Laval, Canada; University of Washington, United States; United Nations University, Macau; Fudan University, China},
  author_keywords         = {e-government; service integration; smart city},
  correspondence_address1 = {Nam, T.; Center for Technology in Government, University at Albany, SUNYUnited States; email: tnam@ctg.albany.edu},
  document_type           = {Conference Paper},
  doi                     = {10.1145/2037556.2037612},
  isbn                    = {9781450307628},
  journal                 = {ACM International Conference Proceeding Series},
  keywords                = {e-Government; Government entities; Graduate students; Humanities research; Information sharing; Integration of services; Large-scale projects; Mexico City; New York City; Public services; Quebec city; Research capabilities; Seattle; Service integration; Single entry; smart city; Theoretical framework, Electronic commerce; Government data processing; Humanities computing; Research; Students, Integration},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80054792068&doi=10.1145%2f2037556.2037612&partnerID=40&md5=c974e48631fc915851536dfd9a461d00},
}

@Article{Baumann200724,
  author                  = {Baumann, J.},
  title                   = {Cape town's emphasis on systems integration exemplifies 'smart city' goals},
  journal                 = {Water and Wastewater International},
  year                    = {2007},
  volume                  = {22},
  number                  = {4},
  pages                   = {24-26},
  issn                    = {08915385},
  note                    = {cited By 0},
  abbrev_source_title     = {Water Wastewater Int},
  abstract                = {Cape Town in the Republic of South Africa has aimed for systems integration by consolidating and streamlining municipal water/wastewater services across the Cape Town metropolitan area through the implementation of Geographic information system (GIS) and SAP. The city has implemented an enterprise GIS based on ESRI's ArcGIS platform to allow extensive functionality within a multi-user environment. SAP enables the city to establish the system's business information capabilities and its location-based asset information such as pipes, meters, reservoirs, treatment plants, and associated attribute data stored in GIS. The city is also aimed to apply the lessens learned form the water Services implementation to the development of a sewer and stormwater geodatabase. Cape Town has planned to implement the transactional integration of GIS and SAP to provide lifecycle views and real-time feedback asset maintenance of wastewater.},
  affiliation             = {ESRI},
  coden                   = {WWINE},
  correspondence_address1 = {Baumann, J.; ESRIemail: info@esri.com},
  document_type           = {Article},
  keywords                = {Geographic information systems; Information retrieval systems; Reservoirs (water); User interfaces; Water management, Multi-user environment; Wastewater services, Wastewater treatment},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-35348915428&partnerID=40&md5=28dc2201f8a90f6636387ea624f85d4d},
}

@Conference{Zhang20191168,
  author              = {Zhang, H. and Wei, Z.},
  title               = {Polymerization Methods of Systems-of-Systems Integration Effect Based on Choquet Integral},
  year                = {2019},
  editor              = {Cheng Y., Li S., Dai Y.},
  pages               = {1168-1175},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Proc. - Int. Conf. Inf. Sci. Control Eng., ICISCE},
  abstract            = {Systems-of-systems integration is an important aspect of systems-of-systems and it's engineering research. It is comprehensive expression of overall emergent property and overall optimization property of systems-of-systems. Integration effect is measurement of systems-of-systems integration process. Systems-of-systems integration activities have strong randomness, which decides that systems-of-systems integration effect polymerization has strong non-linear additivity, making evaluation polymerization of systems-of-systems integration effect difficult. Systems-of-systems integration activity characteristics are analyzed from information integration, function integration, business process integration in the Paper firstly to establish evaluation index system of systems-of-systems integration effect; secondly, analytic hierarchy process method is adopted to establish weight vector among evaluation index system level of integration effect; then, basic set-valued random variable not only can describe random nature of development of things, but also can describe uncertainty of development state of things, and Choquet integral is a non-additive and non-linear integral based on fuzzy measurement, polymerization methods of systems-of-systems integration effect based on Choquet integral are proposed. Finally, cases are adopted to illustrate effectiveness of methods in the Paper. © 2018 IEEE.},
  affiliation         = {Systems Engineering Research Institute, Beijing, China},
  art_number          = {8612738},
  author_keywords     = {evaluation; index system; integration effect; polymerization; systems-of-systems},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICISCE.2018.00240},
  isbn                = {9781538655009},
  journal             = {Proceedings - 2018 5th International Conference on Information Science and Control Engineering, ICISCE 2018},
  keywords            = {Integral equations; Polymerization; Systems engineering; Uncertainty analysis, Business process integration; evaluation; Evaluation index system; Index systems; Information integration; Polymerization method; Set-valued random variables; Systems of systems, System of systems},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062101432&doi=10.1109%2fICISCE.2018.00240&partnerID=40&md5=8b971ae882b88c3915f1d800a75c8eb6},
}

@Article{Joiner201925,
  author                  = {Joiner, K. and Efatmaneshnik, M. and Tutty, M.},
  title                   = {Modelling the efficacy of assurance strategies for better integration, interoperability and information assurance in family-of-system-of-systems portfolios},
  journal                 = {Advances in Intelligent Systems and Computing},
  year                    = {2019},
  volume                  = {878},
  pages                   = {25-36},
  issn                    = {21945357},
  note                    = {cited By 0},
  abbrev_source_title     = {Adv. Intell. Sys. Comput.},
  abstract                = {Military systems, and more broadly society’s, are increasingly complex and interconnected enabling hitherto only dreamed of capabilities and yet also humanity’s forays into wholesale malicious cyber-warfare. Loosely coupled families-of-systems of systems cooperate and evolve sporadically when using linear lifecycles and project-by-project development, defying capability control and assurance at that mesa-level. The U.S. Defense has evolved systematic ways for their families-of-systems to be progressively more integrated, interoperable and information assured and this is dramatically differentiating its capability assurance from its allies. This paper reports new Markovian testability modelling comparing the abstract efficacy of assurance experimentation and testing strategies employed by Australia Defence against the new U.S. strategies that are now able to quantitatively illustrate the widening gap between these allies. The modelling technique has potential to tailor Australian plans to keep pace with its ally and in modelling civilian families-of-system-of-systems in transportation, energy healthcare and the like. © Springer Nature Switzerland AG 2019.},
  affiliation             = {School of Engineering and Information Technology, Capability Systems Centre, University of New South Wales – Canberra, Australian Defence Force Academy, CampbellACT 2612, Australia; Capability Systems Centre, University of New South Wales – Canberra, Australian Defence Force Academy, CampbellACT 2612, Australia; Air Power Development Centre, Royal Australian Air Force, Fairbairn Offices, Department of Defence, CanberraACT 2600, Australia},
  correspondence_address1 = {Efatmaneshnik, M.; Capability Systems Centre, University of New South Wales – Canberra, Australian Defence Force Academy, Campbell, Australia; email: m.efatmaneshnik@adfa.edu.au},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-030-02886-2_3},
  editor                  = {Cardin M.A., Hastings D., Krob D., Lui P.C., Jackson P., Schmitt G.},
  isbn                    = {9783030028855},
  keywords                = {Military applications; System of systems; Systems analysis; Systems engineering, Cyber warfare; Information assurance; Loosely coupled; Military systems; Modelling techniques; Project development; Systems of systems; Testing strategies, Interoperability},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057286375&doi=10.1007%2f978-3-030-02886-2_3&partnerID=40&md5=78d24142f9879ac4b3a490e7481789c3},
}

@Article{Ed-Daoui20191,
  author                  = {Ed-Daoui, I. and Itmi, M. and El Hami, A. and Hmina, N. and Mazri, T.},
  title                   = {A study of an adaptive approach for systems-of-systems integration},
  journal                 = {International Journal of System of Systems Engineering},
  year                    = {2019},
  volume                  = {9},
  number                  = {1},
  pages                   = {1-27},
  issn                    = {17480671},
  note                    = {cited By 0},
  abbrev_source_title     = {Int. J. Syst. Syst. Eng.},
  abstract                = {Systems-of-systems are a growing composition of complex, autonomous and heterogeneous systems that collaborate in order to achieve complex and evolving targets that exceed the sum of the parts. In fact, the biggest challenge in such environment lays in the preservation of the viability of the system-of-systems and its evolvement while handling component systems' dynamic integrations. This also represents a pressing issue in systems-of-systems engineering. In this paper, we present a collection of definitions dedicated to sire the system-of-systems' concept, their characteristics and typology. Next, we detail the challenges facing the integration process in systems-of-systems. Then, we present our proposition to manage this issue. It is based on an adaptive integration approach to systems-of-systems typology. Two case studies are provided in order to experiment our theory. We evaluate the performance of the approach in both cases. Results are cross-compared. © 2019 Inderscience Enterprises Ltd.},
  affiliation             = {LMN Laboratory, INSA Rouen Normandy, University of Rouen Normandy, 685 University Av., Saint-Etienne-du-Rouvray, 76800, France; LGS Laboratory, ENSA of Kenitra, Ibn Tofail University, BP 242, University Av., Kenitra 14, 000, Morocco; LITIS Laboratory, INSA Rouen Normandy, University of Rouen Normandy, 685 University Av., Saint-Etienne-du-Rouvray, 76800, France; ETSE Laboratory, ENSA of Kenitra, Ibn Tofail University, BP 242, University Av., Kenitra 14, 000, Morocco},
  author_keywords         = {Interoperability; Performance evaluation; Simulation; Systems-of-systems architecture; Systems-of-systems integration},
  correspondence_address1 = {Ed-Daoui, I.; LMN Laboratory, INSA Rouen Normandy, University of Rouen Normandy, 685 University Av., France; email: edd.ilyas@gmail.com},
  document_type           = {Article},
  doi                     = {10.1504/IJSSE.2019.097895},
  language                = {English},
  publisher               = {Inderscience Enterprises Ltd.},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062176364&doi=10.1504%2fIJSSE.2019.097895&partnerID=40&md5=c2ac221757e8767e5869dff138eba333},
}

@Conference{Khayal2018387,
  author                  = {Khayal, I.},
  title                   = {Modeling a community as a system of systems: A methodology for data integration},
  year                    = {2018},
  pages                   = {387-391},
  publisher               = {Institute of Electrical and Electronics Engineers Inc.},
  note                    = {cited By 0},
  abbrev_source_title     = {Syst. Syst. Eng. Conf., SoSE},
  abstract                = {We live, work and play within interacting and embedded systems of systems. While systems of systems engineering may be perceived as primarily physical or 'hard' infrastructure, we live in critical systems of systems that emerge within physical and social systems. One such example is the living community system, one that strongly impacts our health and the way we live. The complex interconnected living environment is becoming a central focus for improvement given its strong influence on health in general and on how chronic conditions arise and persist. Such a strong focus on our community living environment has prompted various level regions (i.e. cities, districts) to take action in their communities. Stakeholders have turned to national data sources to inform a region of the many factors that describe it. However, these multiple factor datasets should be analyzed holistically as a system rather than individually. Consequently, this work develops a system of systems community typology from national data describing types of factor value combinations within a region. This paper presents a method of integrating multifactorial community data using a clustering based method to determine holistic system of systems community typologies. © 2018 IEEE.},
  affiliation             = {Dartmouth Institute of Health Policy and Clinical Practice, Department of Computer Science, Dartmouth College, Hanover, NH 03755, United States},
  art_number              = {8428766},
  correspondence_address1 = {Khayal, I.; Dartmouth Institute of Health Policy and Clinical Practice, Department of Computer Science, Dartmouth CollegeUnited States; email: Inas.Khayal@dartmouth.edu},
  document_type           = {Conference Paper},
  doi                     = {10.1109/SYSOSE.2018.8428766},
  isbn                    = {9781538648766},
  journal                 = {2018 13th System of Systems Engineering Conference, SoSE 2018},
  keywords                = {Data integration; System of systems; Systems engineering, Chronic conditions; Critical systems; Data-sources; Living communities; Living environment; Multiple factors; Social systems; Systems of systems, Embedded systems},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052308357&doi=10.1109%2fSYSOSE.2018.8428766&partnerID=40&md5=40f748e124bbc4e7ef541dd5253f75e0},
}

@Conference{Mendes201821,
  author              = {Mendes, A. and Loss, S. and Cavalcante, E. and Lopes, F. and Batista, T.},
  title               = {Mandala: An agent-based platform to support interoperability in systems-of-systems},
  year                = {2018},
  pages               = {21-28},
  publisher           = {IEEE Computer Society},
  note                = {cited By 0},
  abbrev_source_title = {Proc Int Conf Software Eng},
  abstract            = {A particular challenge to the construction of systems-of-systems (SoS) is the high heterogeneity of their constituent systems, thereby making interoperability an important issue to be tackled. This paper introduces Mandala, a platform to support interoperability in SoS. Mandala aims to offer a software layer to integrate heterogeneous, independent information systems without significantly changing their implementation or even knowing details about each system. The proposal relies on (i) business process models to represent activities associated to SoS global missions and (ii) software agents to support asynchronous communication among autonomous components. This paper presents an evaluation of Mandala and its interoperability mechanisms through a case study using information systems within a smart city scenario. © 2018 ACM.},
  affiliation         = {Federal University of Rio Grande Do Norte, Natal, Brazil},
  author_keywords     = {business processes; information systems; interoperability; middleware; software agents; systems-of-systems},
  coden               = {PCSED},
  document_type       = {Conference Paper},
  doi                 = {10.1145/3194754.3194757},
  isbn                = {9781450357470},
  issn                = {02705257},
  journal             = {Proceedings - International Conference on Software Engineering},
  keywords            = {Autonomous agents; Information systems; Information use; Middleware; Software agents; System of systems; Systems engineering, Agent based; Asynchronous communication; Autonomous components; Business Process; Business process model; Global missions; High heterogeneity; Systems of systems, Interoperability},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051172970&doi=10.1145%2f3194754.3194757&partnerID=40&md5=3d12ec2a781ba0c210667651541a6b19},
}

@Article{Mordecai2018637,
  author                  = {Mordecai, Y. and Orhof, O. and Dori, D.},
  title                   = {Model-based interoperability engineering in systems-of-systems and civil aviation},
  journal                 = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
  year                    = {2018},
  volume                  = {48},
  number                  = {4},
  pages                   = {637-648},
  issn                    = {21682216},
  note                    = {cited By 4},
  abbrev_source_title     = {IEEE Trans. Syst. Man Cybern. Syst.},
  abstract                = {Interoperability is the capability of multiple parties and systems to collaborate and exchange information and matter to obtain their objectives. Interoperability challenges call for a model-based systems engineering approach. This paper describes a conceptual modeling framework for model-based interoperability engineering (MoBIE) for systems of systems, which integrates multilayered interoperability specification, modeling, architecting, design, and testing. Treating interoperability infrastructure as a system in its own right, MoBIE facilitates interoperability among agents, processes, systems, services, and interfaces. MoBIE is founded on ISO 19450 standard - object-process methodology, a holistic paradigm for modeling and architecting complex, dynamic, and multidisciplinary systems - and allows for synergistic integration of the interoperability model with system-centric models. We also discuss the implementation of MoBIE with the unified modeling language. We discuss the importance of interoperability in the civil aviation domain, and apply MoBIE to analyze the passenger departure process in an airport terminal as a case-in-point. The resulting model enables architectural and operational decision making and analysis at the system-of-systems level and adds significant value at the interoperability engineering program level. © 2013 IEEE.},
  affiliation             = {TechnionIsrael Institute of Technology, Haifa, 32000, Israel; Center for Academic Studies, Or-Yehuda, 60218, Israel},
  author_keywords         = {Airport terminals; interoperability; model-based systems engineering (MBSE); object process methodology (OPM); systems-of-systems (SoS)},
  correspondence_address1 = {Mordecai, Y.; TechnionIsrael Institute of TechnologyIsrael; email: yanivmor@technion.ac.il},
  document_type           = {Article},
  doi                     = {10.1109/TSMC.2016.2602543},
  keywords                = {Airport buildings; Airports; Civil aviation; Computer simulation languages; Decision making; ISO Standards; Modeling languages; System of systems; Systems engineering; Unified Modeling Language, Airport terminals; Interoperability modeling; Model-based systems engineering; Model-based systems engineering (MBSE); Multi-disciplinary systems; Object-process methodology; Operational decision making; Systems of systems, Interoperability},
  language                = {English},
  publisher               = {Institute of Electrical and Electronics Engineers Inc.},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025169631&doi=10.1109%2fTSMC.2016.2602543&partnerID=40&md5=4d6a84b916167943e59eeddd8e0dd0e3},
}

@Conference{Fasano2018,
  author              = {Fasano, L. and De Luca, G.F.},
  title               = {The exploitation of the COSMO-SkyMed Interoperability, Expandability, Multimission-Multisensor capabilities for the SIASGE System of Systems},
  year                = {2018},
  editor              = {Fierro D., Garro A., Mancin E., Tirone L., Falcone A., Gaudenzi P.},
  volume              = {2248},
  publisher           = {CEUR-WS},
  note                = {cited By 0},
  abbrev_source_title = {CEUR Workshop Proc.},
  abstract            = {COSMO-SkyMed is an Italian Earth Observation system born to cope with Dual-Use (i.e. military and civilian) and Multimission (MM)/Multisensor (MS) (SAR, Optical,) requirements. Within this perspective, it is a highly innovative system capable to be expanded to other systems and sensors. SIASGE is a Space Earth Observation System set-up by an international cooperation between Italy and Argentina for complementary utilisation of COSMO-SkyMed and the SAOCOM CONAE (Comisión Nacional de Actividades Espaciales) Mission. This work describes how a system already in operation (COSMO-SkyMed) can be used, thanks to its IEM (Interoperability, Expandability, Multimission/Multisensor) native capabilities, to form, jointly with a new-developed system (SAOCOM), the complex SIASGE "System of Systems". © 2018 CEUR-WS. All rights reserved.},
  affiliation         = {Italian Space Agency, Rome, Italy},
  author_keywords     = {COSMO-SkyMed; IEM; SAOCOM; SAR; Satellite; SIASGE},
  document_type       = {Conference Paper},
  issn                = {16130073},
  journal             = {CEUR Workshop Proceedings},
  keywords            = {Earth (planet); International cooperation; Observatories; Satellites; Space-based radar; System of systems; Systems engineering, Argentina; Cosmo skymed; Earth observation systems; Expandability; Innovative systems; Multi sensor; SAOCOM; SIASGE, Interoperability},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057571332&partnerID=40&md5=819bacfae1e08c2368a34357d54c9e18},
}

@Conference{Jha2017,
  author              = {Jha, U.S. and White, A. and Stucke, A.},
  title               = {Integrated modeling and simulation framework expedite operational software testing, integration and verification for system of systems platform},
  year                = {2017},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {AUTOTESTCON Proc},
  abstract            = {Modeling and Simulation (M&S) has become an essential tool in the development, testing and verification of operational software in a complex multi-domain, multi-threaded heterogeneous system of systems environment. The complex systems of today encompass mix of hardware sub-systems (with varying degree of capabilities), software environments (comprising a plethora of development environments, operating systems and programming languages) and peripherals (sensors, effectors, actuators etc.), realization of which requires massive investments (human, capital, tools etc.) and carries a huge risk to cost, schedule and requirements compliance. These risks are alleviated to a large extent with a well formulated test architecture and integrated simulation environment with high fidelity systems modeling framework, where majority of system compliance metrics can be verified in a digital domain. © 2017 IEEE.},
  affiliation         = {Space and Airborne Systems, Raytheon Co El Segundo, California, United States},
  art_number          = {8080506},
  author_keywords     = {Acceptance testing; Algorithm Development; CONOPS; Design & development; Failure Analysis; Modeling; Performance evaluation; Prototyping; Regression Testing Automated Testing & Verification; Simulation; Trade-off analysis},
  document_type       = {Conference Paper},
  doi                 = {10.1109/AUTEST.2017.8080506},
  isbn                = {9781509049226},
  journal             = {AUTOTESTCON (Proceedings)},
  keywords            = {Computer software; Economic and social effects; Failure analysis; Integration testing; Models; Software prototyping; Software testing; System of systems; Systems engineering; Verification, Acceptance testing; Algorithm development; Automated testing; CONOPS; Performance evaluation; Simulation; Trade-off analysis, Acceptance tests},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038585545&doi=10.1109%2fAUTEST.2017.8080506&partnerID=40&md5=1fd74f9dc603a3471450d68912e3288e},
}

@Conference{Enos2017,
  author              = {Enos, J.R. and Nilchiani, R.},
  title               = {Using social network analysis to quantify interoperability in a large system of systems},
  year                = {2017},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 3},
  abbrev_source_title = {Syst. Syst. Eng. Conf., SoSE},
  abstract            = {The Department of Defense (DoD) manages a large, complex system of systems that must operate together on the battlefield to deliver value. However, it is difficult to understand the network wide impacts of changes to the system of systems. The DoD has had difficulty managing this system of systems due to the scale and complexity of the network and traditional systems engineering tools do not provide necessary insights for DoD decision makers. This paper proposes applying social network analysis to understand the interoperability associated with the DoD system of systems. It applies several centrality metrics to a network of Major Defense Acquisition Programs (MDAPs) to quantify the interoperability of individual systems within the system of systems. Specifically, it examines the differences between the degree, closeness, and eigenvector centrality metrics to identify which metric best represents the interoperability of individual systems. © 2017 IEEE.},
  affiliation         = {School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, NJ 07030, United States},
  art_number          = {7994932},
  author_keywords     = {interoperability; social network analysis; system of systems engineering},
  document_type       = {Conference Paper},
  doi                 = {10.1109/SYSOSE.2017.7994932},
  isbn                = {9781509059454},
  journal             = {2017 12th System of Systems Engineering Conference, SoSE 2017},
  keywords            = {Complex networks; Decision making; Network security; Social networking (online); System of systems; Systems engineering, Decision makers; Defense acquisition program; Department of Defense; Eigenvector centralities; Engineering tools; Individual systems; Large system; Traditional systems, Interoperability},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028569769&doi=10.1109%2fSYSOSE.2017.7994932&partnerID=40&md5=820555a61dc33675aaf4cb3c8052a533},
}

@Article{Antal2016,
  author                  = {Antal, M. and Pop, C. and Cioara, T. and Anghel, I. and Salomie, I. and Pop, F.},
  title                   = {A System of Systems approach for data centers optimization and integration into smart energy grids},
  journal                 = {Future Generation Computer Systems},
  year                    = {2016},
  issn                    = {0167739X},
  note                    = {cited By 1; Article in Press},
  abbrev_source_title     = {Future Gener Comput Syst},
  abstract                = {This paper addresses the problem of proactive planning and optimizing the operation of a Systems of Systems (SoS) over a time horizon while considering the characteristics of each constituent system and complex interactions among them. We define a mathematical formalism for modeling complex systems composed of a mesh of sub-systems with linear and non-linear behaviors and abstractions like discrete time, atomic systems and interconnection of atomic system. The proposed modeling approach is simple enough to allow fast computations and simulations, and at the same time complex enough to capture the essential features of the real system thus allowing the mapping of proactive optimization problems to Mixed-Integer Optimal Control Problems. The proactive planning uses hierarchical optimization processes that compute predictions and optimization plans at various time granularities, each finer layer plan adjusting and refining the ones with higher granularity. To show case our approach we model a Data Center which is a well-known case of a large scale complex system aiming to plan and optimize its operation to use as much as possible the locally produced renewable energy and optimize its integration in smart grid advanced context. Simulation based results show a reduction of 5% of the carbon footprint and at the same time an increase in profit of more than 14% due to flexible energy shifting. © 2017 Elsevier B.V.},
  affiliation             = {Technical University of Cluj-Napoca, Baritiu 26, Cluj-Napoca, Romania, Romania; University Politehnica of Bucharest, Splaiul Independenţei 313, Bucharest, Romania; National Institute for Research and Development in Informatics (ICI), Mareşal Averescu, 8-10, Bucharest, Romania},
  author_keywords         = {Data center; Energy flexibility; Modeling; Multi-layer optimization; Systems of Systems},
  coden                   = {FGCSE},
  correspondence_address1 = {Anghel, I.Romania; email: ionut.anghel@cs.utcluj.ro},
  document_type           = {Article in Press},
  doi                     = {10.1016/j.future.2017.05.021},
  keywords                = {Carbon footprint; Data integration; Integer programming; Large scale systems; Models; Optimal control systems; System of systems; Systems engineering, Data centers; Energy flexibility; Hierarchical optimization; Large-scale complex systems; Mathematical formalism; Optimal control problem; Optimization problems; Systems of systems, Smart power grids},
  language                = {English},
  publisher               = {Elsevier B.V.},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020734415&doi=10.1016%2fj.future.2017.05.021&partnerID=40&md5=555956a0c53b76c222515a076a568b32},
}

@Article{Stary2016155,
  author                  = {Stary, C. and Wachholder, D.},
  title                   = {System-of-systems support — A bigraph approach to interoperability and emergent behavior},
  journal                 = {Data and Knowledge Engineering},
  year                    = {2016},
  volume                  = {105},
  pages                   = {155-172},
  issn                    = {0169023X},
  note                    = {cited By 7},
  abbrev_source_title     = {Data Knowl Eng},
  abstract                = {When designing highly interactive distributed systems such as e-learning environments, a system-of-systems (SoS) perspective enables dynamic adaptation to situations of use and thus user-centeredness during operation. Each system, e.g., a mobile device for accessing a learning management system, can still be operated as a separate system, e.g., displaying the latest feedback from peers, while being run as part of a federated system, e.g., synchronizing a learning group for a tutoring session taking into account individual availability of participants. This type of coupling requires interoperability assurance of systems, in particular federating various devices and cross-over features (e.g., linking learning content to posts on social media platforms) in dynamically evolving environments. We demonstrate the utility of bigraph-based handling of SoS. Abstract relationships allow not only the representation of dynamic interaction but also the re-specification of these systems through behavior adaptations. This abstraction supports cross-system decomposition as well as composition of interaction patterns for the purpose of emergent behavior. We show the potential of this approach orchestrating two distributed and independent systems, with orchestration enabling directly respondence to changes in a federated system's context. © 2015 Elsevier B.V.},
  affiliation             = {Department of Business Information Systems — Communications EngineeringJohannes Kepler University Linz, Altenberger Straβe 69, Linz, 4040, Austria},
  author_keywords         = {Behavior orchestration; Context-sensitive interoperability; Cross-system interaction; Emergent behavior; Semantic specification; Usage-centered design},
  coden                   = {DKENE},
  correspondence_address1 = {Wachholder, D.; Department of Business Information Systems — Communications EngineeringJohannes Kepler University Linz, Altenberger Straβe 69, Austria; email: dominik.wachholder@jku.at},
  document_type           = {Article},
  doi                     = {10.1016/j.datak.2015.12.001},
  keywords                = {Behavioral research; Computer aided instruction; E-learning; Mobile devices; Semantics; Specifications; System of systems; Systems engineering, Behavior orchestration; Context sensitive; Cross systems; Emergent behaviors; Semantic specification, Interoperability},
  language                = {English},
  publisher               = {Elsevier B.V.},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961313278&doi=10.1016%2fj.datak.2015.12.001&partnerID=40&md5=2362ff9b0e7434c31a6773a8f5279927},
}

@Conference{Vaneman2016,
  author                  = {Vaneman, W.K.},
  title                   = {The system of systems engineering and integration «vee» model},
  year                    = {2016},
  publisher               = {Institute of Electrical and Electronics Engineers Inc.},
  note                    = {cited By 1},
  abbrev_source_title     = {Annu. Int. Syst. Conf., SysCon - Proc.},
  abstract                = {In the twenty-first century, mission success will require unprecedented interoperability among disparate constituent systems resulting in a System of Systems (SoS). Unlike traditional systems engineering where systems are created based on a set of user needs, a SoS is composed of multiple constituent systems, at various stages within their lifecycles (i.e. new start systems, systems in-development, legacy systems), to satisfy needed mission capabilities. System of Systems Engineering has been exploring appropriate methods and processes for almost two decades. This paper takes the discussion further by introducing a System of Systems Engineering and Integration (SOSE&I) methodology. SoSE&I is the planning, analyzing, and integrating of constituent systems into an SoS capability greater than the sum of those individual systems. The SoSE&I «Vee» process model is introduced and discusses how it is used to engineer the SoS throughout its lifecycle to increase systems integration and interoperability, and directly impact the operational success. © 2016 IEEE.},
  affiliation             = {Systems Engineering Department, Naval Postgraduate School, Monterey, CA, United States},
  art_number              = {7490599},
  author_keywords         = {System of Systems; System of Systems Engineering and Integration; Systems Engineering «Vee» Model},
  correspondence_address1 = {Vaneman, W.K.; Systems Engineering Department, Naval Postgraduate SchoolUnited States},
  document_type           = {Conference Paper},
  doi                     = {10.1109/SYSCON.2016.7490599},
  isbn                    = {9781467395182},
  journal                 = {10th Annual International Systems Conference, SysCon 2016 - Proceedings},
  keywords                = {Integration; Legacy systems; Life cycle; System of systems; Systems engineering, Individual systems; Methods and process; Mission capability; Mission success; Process Modeling; Systems integration; Traditional systems; User need, Interoperability},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979231636&doi=10.1109%2fSYSCON.2016.7490599&partnerID=40&md5=c812aeccc2f354b09125f4928b461c08},
}

@Conference{Vargas201632,
  author              = {Vargas, I.G. and Gottardi, T. and Teresinha, R. and Braga, V.},
  title               = {Approaches for integration in system of systems: A systematic review},
  year                = {2016},
  pages               = {32-38},
  publisher           = {Association for Computing Machinery, Inc},
  note                = {cited By 7},
  abbrev_source_title = {Proc. - Int. Workshop Softw. Eng. Syst-Syst., SESoS},
  abstract            = {Software systems have become increasingly complex, and they are often formed by integrating independent systems, resulting in a new class of systems referenced as System of Systems (SoS). The System of Systems Integration (SoSI) emerges as a new challenge and aims to create a new feature by integrating constituent systems that contribute to the overall goal of the SoS. Often the constituent systems tend to be from different sources and behaviors and, as such, tend to employ different terminology and concepts. Also, when SoSI involves the integration of legacy systems, cases where the documentation and the necessary skills for the harmonious integration are readily available are very rare. However, it is observed that there is a lack of studies that are comprehensive and, at the same time, contain a detailed view of how the constituent systems are integrated in order to collectively achieve a common goal. Based on this scenario, the main contribution of this systematic review (SR) is to investigate the state of the art of SoSI and the software engineering methods that assist in the integration between constituent systems of a SoS. The SR has found 1398 studies and, at the end of the selection process, we selected 29 studies for data extraction. Most studies describe individuals and teams who have worked in isolation to develop solutions to certain problems without widespread adoption of a form of integration. Thus, there is a growing concern of researchers in the SoS context. However, it still lacks research and greater dissemination of concepts among researchers in the field. © 2016 ACM.},
  affiliation         = {ICMC-University of São Paulo, São Carlos São Paulo, Brazil},
  author_keywords     = {Integration; Interoperability; System of Systems Integration; Systematic review},
  document_type       = {Conference Paper},
  doi                 = {10.1145/2897829.2897835},
  isbn                = {9781450341721},
  journal             = {Proceedings - 4th International Workshop on Software Engineering for Systems-of-Systems, SESoS 2016},
  keywords            = {Integration; Legacy systems; Software engineering; System of systems; Systems engineering, Data extraction; Independent systems; Software engineering methods; Software systems; State of the art; Systematic Review, Interoperability},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974578334&doi=10.1145%2f2897829.2897835&partnerID=40&md5=53f0bab4a96ee9997256f7ccce05f9a6},
}

@Conference{Cureton2016,
  author              = {Cureton, K.L. and Madni, A.M.},
  title               = {Role of interoperability in resilient system-of-systems for humanitarian assistance and disaster relief},
  year                = {2016},
  publisher           = {American Institute of Aeronautics and Astronautics Inc, AIAA},
  note                = {cited By 0},
  abbrev_source_title = {Space Astronaut. Forum Expos.},
  abstract            = {Interoperability requirements of federated System-of-Systems (SoS) for humanitarian assistance and disaster relief missions are complicated by the fact that the SoS needs to be cybersecure and exhibit resilience in the face of disruptions. These missions require multiple organizations to dependably work with others, while assuring timely information sharing among them and orchestrated resilient responses to deal with contingencies and disruptions. This paper discusses interoperability challenges for resilient cybersecure SoS, and offers promising solution directions. © 2016, American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved.},
  affiliation         = {Systems Architecting and Engineering, University of Southern California, Los Angeles, CA 90089-0193, United States; Systems Architecting and Astronautical Engineering, University of Southern California, Los Angeles, CA 90089-0193, United States},
  document_type       = {Conference Paper},
  isbn                = {9781624104275},
  journal             = {AIAA Space and Astronautics Forum and Exposition, SPACE 2016},
  keywords            = {Disaster prevention; Disasters; Emergency services; System of systems; Systems engineering, Disaster relief; Federated systems; Humanitarian assistances; Information sharing; Interoperability requirements; Multiple organizations; Resilient systems, Interoperability},
  language            = {English},
  page_count          = {8},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995639956&partnerID=40&md5=761c8d185d88d0e1e8bd2a83193eadb5},
}

@Conference{Bellman2015249,
  author              = {Bellman, K.L. and Landauer, C.A.},
  title               = {Early work on the brain patch, a reflective service for system of systems integration},
  year                = {2015},
  editor              = {Lalanda P., Kounev S., Diaconescu A., Cherkasova L.},
  pages               = {249-254},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 3},
  abbrev_source_title = {Proc. - IEEE Int. Conf. Auton. Comput., ICAC},
  abstract            = {In previous work we've shown that reflection supports the integration of components and of self-optimization within a complex system. In this paper, we discuss some early work on how some of these capabilities could support a similar integration and conflict resolution among the members of a system of systems (SoS). We start with a brief overview of the Wrappings approach to reflection, the notion of a web of reflection, and the CARS test bed where we are developing our concepts. We then introduce some early work on a new reflective service, the Brain Patch which helps to integrate a system into a System of Systems (SoS) by being both a domain specific expert on the reason for the formation of the SoS and its goals, situation, operating rules, etc. And by also continually observing and building a model of the system assigned to it. © 2015 IEEE.},
  affiliation         = {Topcy House Consulting, Thousand Oaks, CA, United States},
  art_number          = {7266975},
  author_keywords     = {Reflection; Self-optimization component; System of Systems integration; Wrappings},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICAC.2015.73},
  isbn                = {9781467369701},
  journal             = {Proceedings - IEEE International Conference on Autonomic Computing, ICAC 2015},
  keywords            = {Integration; Large scale systems; Reflection; Systems engineering, Conflict Resolution; Domain specific; Operating rule; Self-optimization; Wrappings, System of systems},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983208651&doi=10.1109%2fICAC.2015.73&partnerID=40&md5=10e7177189f75c9bff7ca67f81fffdf0},
}

@Conference{Nelson2015285,
  author              = {Nelson, P.R. and Landauer, C. and Bellmany, K.L. and Goto, S. and Taylor, J.},
  title               = {System of systems integration also includes hardware integration: A small demonstration of providing some reflection processes for HW},
  year                = {2015},
  editor              = {Lalanda P., Kounev S., Diaconescu A., Cherkasova L.},
  pages               = {285-288},
  publisher           = {Institute of Electrical and Electronics Engineers Inc.},
  note                = {cited By 0},
  abbrev_source_title = {Proc. - IEEE Int. Conf. Auton. Comput., ICAC},
  abstract            = {In previous work we showed that reflection and Wrappings are useful tools for system integration. But System of Systems integration also needs to accommodate specific hardware challenges. We discuss simple examples from the operation of a single cyber-physical agent that accepts top-down commands, but uses the Wrappings architecture to self-organize its context specific implementation of them. Our experimental context is CARS (Computational Architectures for Reflective Systems) a test bed for exploring the behavior of distributed autonomous cyber-physical agents in a complex environment. © 2015 IEEE.},
  affiliation         = {Electrical and Computer Engineering Department, California State Polytechnic University, Pomona, Pomona, CA, United States; Topcy House Consulting, Thousand Oaks, CA, United States},
  art_number          = {7266981},
  author_keywords     = {Computational Reection; Experimental Testbed; Real-Time Systems; Self-Organizing Systems; Wrapping Infrastructure},
  document_type       = {Conference Paper},
  doi                 = {10.1109/ICAC.2015.74},
  isbn                = {9781467369701},
  journal             = {Proceedings - IEEE International Conference on Autonomic Computing, ICAC 2015},
  keywords            = {Autonomous agents; Hardware; Interactive computer systems; Large scale systems; Real time systems; Reconfigurable hardware; System of systems; Systems engineering, Complex environments; Computational architecture; Computational Reection; Experimental testbed; Hardware integrations; Reflection process; Reflective systems; Self-organizing systems, Distributed computer systems},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961820809&doi=10.1109%2fICAC.2015.74&partnerID=40&md5=8ac855a5ef53ae3df869a45804d413b6},
}

@Article{Billaud201553,
  author                  = {Billaud, S. and Daclin, N. and Chapurlat, V.},
  title                   = {Interoperability as a key concept for the control and evolution of the system of systems (Sos)},
  journal                 = {Lecture Notes in Business Information Processing},
  year                    = {2015},
  volume                  = {213},
  pages                   = {53-63},
  issn                    = {18651348},
  note                    = {cited By 4},
  abbrev_source_title     = {Lect. Notes Bus. Inf. Process.},
  abstract                = {A coalition of enterprises wanting to collaborate, and more generally a Collaborative Network of Organizations (CNO), can conceptually be assimilated as a System of Systems (SoS) presenting a number of characteristics to respect all over its life cycle. Interoperability is one of these characteristics (both functional and non-functional), which is from our point of view, essential in order to guarantee the control of the SoS, its behavior and the fulfillment of its mission(s). Moreover, it ensures the reaction of the SoS to deal with some risky situations and with potential local or global deficits during its functioning. In this paper, we propose to determine the relation between the current level of interoperability of the SoS and its functioning whatever may be its situation. A matrix shows how this relation evolves taking into account several characteristics of the SoS, particularly its capacity to respect interoperability requirements (Compatibility, Interoperation, Autonomy and Reversibility) and the so-called analysis perspectives of the SoS: Performance, Integrity and Stability. This relation is requested in order to permit and to guide SoS behavioral simulation currently in development. Thus, a set of indicators is derived and formalized. © IFIP International Federation for Information Processing 2015.},
  affiliation             = {LGI2P, Ecole des Mines d‘Alès, Parc Scientifique G. Besse, Nîmes Cedex 1, 30035, France},
  author_keywords         = {Adaptability; Integrity; Interoperability; Performance; Stability; System of Systems (SoS); System of Systems Engineering (SoSE)},
  correspondence_address1 = {Billaud, S.; LGI2P, Ecole des Mines d‘Alès, Parc Scientifique G. Besse, France},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-662-47157-9_5},
  editor                  = {van Sinderen M., Chapurlat V.},
  isbn                    = {9783662471562},
  keywords                = {Convergence of numerical methods; Life cycle; System of systems; Systems engineering, Adaptability; Behavioral simulation; Collaborative network; Current levels; Integrity; Interoperability requirements; Interoperations; Performance, Interoperability},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937468961&doi=10.1007%2f978-3-662-47157-9_5&partnerID=40&md5=60eb810200ed77d029af61ea5177ce68},
}

@Conference{Benali201464,
  author              = {Benali, H. and Ben Saoud, N.B. and Ben Ahmed, M.},
  title               = {Context-based ontology to describe System-of-Systems Interoperability},
  year                = {2014},
  volume              = {2014},
  pages               = {64-71},
  publisher           = {IEEE Computer Society},
  note                = {cited By 1},
  abbrev_source_title = {Proc. IEEE/ACS Int. Conf. Comput. Syst. Appl., AICCSA},
  abstract            = {The concept of System-of-Systems (SoS) presents a high level perspective that explains the interactions between independent subsystems. In the context of SoS, the issue of interoperability is crucial especially when integrating multiple heterogeneous and independently governed systems. Any solution is naturally applied to resolve a problem in a precise context, where context specificities are implicitly or explicitly processed. In the scope of this paper, we tackle the problem of SoS interoperability knowledge description taking into account the notion of context. To structure this description, we propose ontology design patterns (ODPs) that describe the notion of 'context' in the field of SoS Interoperability. These ODPs was defined based on a Foundational Ontology (FO) for 'Context' description. An example in the field of Traffic management is given to illustrate the practical usefulness of the proposed ontology. © 2014 IEEE.},
  affiliation         = {Laboratoire RIADI, ENSI, Université de la Manouba, Manouba, Tunisia; Faculté des Sciences, Université de Gafsa, Gafsa, Tunisia; Institut Supérieur D'Informatique, Université Tunis El Manar, Tunis, Tunisia},
  art_number          = {7073180},
  author_keywords     = {Conceptual Modeling; Context; Framework; Interoperability; Ontology; System-of-Systems},
  document_type       = {Conference Paper},
  doi                 = {10.1109/AICCSA.2014.7073180},
  isbn                = {9781479971008},
  issn                = {21615322},
  journal             = {Proceedings of IEEE/ACS International Conference on Computer Systems and Applications, AICCSA},
  keywords            = {Ontology; System of systems; Systems engineering, Conceptual model; Context; Context-based; Foundational ontologies; Framework; Ontology design; Traffic management, Interoperability},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988292015&doi=10.1109%2fAICCSA.2014.7073180&partnerID=40&md5=5790fe595af5f17612c97937be170330},
}

@Article{Wachholder2014241,
  author                  = {Wachholder, D. and Stary, C.},
  title                   = {Bigraph-ensured interoperability for system(-of-systems) emergence},
  journal                 = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year                    = {2014},
  volume                  = {8842},
  pages                   = {241-254},
  issn                    = {03029743},
  note                    = {cited By 3},
  abbrev_source_title     = {Lect. Notes Comput. Sci.},
  abstract                = {Today’s complexity of distributed application systems, such as dynamic supply networks, requires a system-of-systems (SoS) perspective for effective adaptation and sustainable use. Those systems not only need to be operated as separate systems (e.g., optimizing each transport modality in supply networks), but also are required to capture complex situations as interconnected entity (e.g., adapting a transport chain involving different modalities according to weather conditions). SoS can handle such challenges through emerging behavior, while letting each of the involved systems operate separately. The latter property requires interoperability of systems that can be preserved even in dynamically changing environments applying the theory of bigraphs. Abstract relationships allow not only the representation of dynamic interaction but also the respecification of these systems through behavior adaptations. This abstraction supports cross-system decomposition as well as composition of interaction patterns for the purpose of emergent behavior. We demonstrate the potential of this approach by orchestrating two distributed and independent systems. SoS behavior orchestration enables to directly respond to changes in the application system context. © Springer-Verlag Berlin Heidelberg 2014.},
  affiliation             = {Communications Engineering, Department of Information Systems, Johannes Kepler University Linz, Altenberger Straße 69, Linz, 4040, Austria},
  author_keywords         = {Behavior orchestration; Context-sensitive interoperability; Cross-system interaction; Emergent behavior},
  correspondence_address1 = {Wachholder, D.; Communications Engineering, Department of Information Systems, Johannes Kepler University Linz, Altenberger Straße 69, Austria},
  document_type           = {Conference Paper},
  editor                  = {Mishra A., Ciuciu I., Bezzi M., Valencia-Garcia R., Lucas Soares A., Meersman R., Panetto H., Moser T., Chan H., Ferri F., Weichhart G.},
  isbn                    = {9783662455494},
  keywords                = {Behavioral research; C (programming language); Complex networks; Systems engineering, Behavior orchestration; Changing environment; Context-sensitive; Distributed application systems; Dynamic supply networks; Emergent behaviors; System decomposition; System interactions, Interoperability},
  language                = {English},
  publisher               = {Springer Verlag},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910154287&partnerID=40&md5=86496706e680deff8c8860196963c511},
}

@Article{Madni2014330,
  author                  = {Madni, A.M. and Sievers, M.},
  title                   = {System of systems integration: Key considerations and challenges},
  journal                 = {Systems Engineering},
  year                    = {2014},
  volume                  = {17},
  number                  = {3},
  pages                   = {330-347},
  issn                    = {10981241},
  note                    = {cited By 32},
  abbrev_source_title     = {Syst. Eng.},
  abstract                = {As systems are called on to participate on demand within system-of-systems (SoS), system-of-systems integration (SoSI) has become a key concern. This capability is especially important in defense and aerospace where systems are increasingly required to interoperate on demand to satisfy mission requirements. SoSI is also becoming increasingly important in healthcare and energy domains. SoSI involves interfacing and enabling the interactions of component systems to create the needed SoS capability to accomplish mission or business goals. SoSI, which is part of the overall SoS development life cycle, increases in complexity when there are legacy systems that need to be integrated, and when humans are tasked to perform in various capacities within the SoS. An added layer of complexity is introduced when the SoS has to exhibit certain quality attributes such as adaptability and resilience in the face of contingencies and disruptions in the operational environment. This paper addresses key considerations and challenges in SoSI. © 2013 Wiley Periodicals, Inc.},
  affiliation             = {Daniel J. Epstein Department of Industrial and Systems Engineering, Viterbi School of Engineering, University of Southern California, Los Angeles CA 90089, United States; Jet Propulsion Laboratory, California Institute of Technology, Pasadena CA 91109, United States},
  author_keywords         = {human-systems integration; integration ontology; interoperability; system of systems; system of systems integration},
  correspondence_address1 = {Madni, A.M.; Daniel J. Epstein Department of Industrial and Systems Engineering, Viterbi School of Engineering, University of Southern California, Los Angeles CA 90089, United States; email: azad.madni@usc.edu},
  document_type           = {Article},
  doi                     = {10.1002/sys.21272},
  keywords                = {Legacy systems; Systems engineering, Business goals; Component systems; Energy domain; Human-systems; Mission requirements; Operational environments; Quality attributes; System of systems, Interoperability},
  language                = {English},
  publisher               = {John Wiley and Sons Inc.},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897991239&doi=10.1002%2fsys.21272&partnerID=40&md5=38a9aded4a1502e87c210ec8432a386f},
}

@Article{Luo20132314,
  author                  = {Luo, X.-Y. and Feng, H.-Y. and Pan, X. and Kang, R.},
  title                   = {Integration modeling approach of process oriented support system of systems},
  journal                 = {Xi Tong Gong Cheng Yu Dian Zi Ji Shu/Systems Engineering and Electronics},
  year                    = {2013},
  volume                  = {35},
  number                  = {11},
  pages                   = {2314-2319},
  issn                    = {1001506X},
  note                    = {cited By 1},
  abbrev_source_title     = {Xi Tong Cheng Yu Dian Zi Ji Shu/Syst Eng Electron},
  abstract                = {Setting up the integrated model of supporting system-of-systems (SoS) is the basis for modeling analysis and verification. Based on SoS engineering, the hierarchy of SoS concepts towards system procedures is proposed, and the descriptive models for each level of supporting SoS from basic objective to specific working procedures are constructed. Using Petri nets and particle swarm algorithm, based on structural model and activity model, all levels of the models for the supporting SoS are integrated. In real cases, it is verified to be effective by applying the models and methods to the analysis and modeling.},
  affiliation             = {School of Reliability and Systems Engineering, Beihang University, Beijing 100191, China; Chinese Navy Headquarter, Beijing 100841, China; Aeronautical Military Representatives Office of Navy in Chengdu, Chengdu 610091, China},
  author_keywords         = {Framework; Particle swarm algorithm; Petri net; System of systems (SoS)},
  coden                   = {XGYDE},
  correspondence_address1 = {Luo, X.-Y.; School of Reliability and Systems Engineering, Beihang University, Beijing 100191, China; email: luoxiangyong@sina.com},
  document_type           = {Article},
  doi                     = {10.3969/j.issn.1001-506X.2013.11.14},
  keywords                = {Activity modeling; Analysis and modeling; Framework; Integrated modeling; Integration models; Particle swarm algorithm; Structural modeling; System of systems, Algorithms; Models; Petri nets, Systems engineering},
  language                = {Chinese},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891321156&doi=10.3969%2fj.issn.1001-506X.2013.11.14&partnerID=40&md5=22943d6d85165ea6f974a2a1fe1ea07b},
}

@Conference{Kazman2013141,
  author                  = {Kazman, R. and Schmid, K. and Nielsen, C.B. and Klein, J.},
  title                   = {Understanding patterns for system of systems integration},
  year                    = {2013},
  pages                   = {141-146},
  note                    = {cited By 10},
  abbrev_source_title     = {Proc. Int. Conf. Syst. Syst. Eng.: SoSE Cloud Comput. Emerg. Inf. Technol. Appl., SoSE 2013},
  abstract                = {Architecting systems of systems is well known to be a formidable challenge. A major aspect in this is defining the integration among the systems that constitute the system of systems. In this paper, we aim to support the SoS architect by systematically developing a way to characterize system of systems integration patterns. These characteristics at the same time support the architecting process by highlighting important issues a SoS architect needs to consider. We discuss the consolidated template and illustrate it with an example pattern. We also discuss the integration of this novel pattern approach into the overall architecting process. © 2013 IEEE.},
  affiliation             = {University of Hawaii, Honolulu, HI, United States; Institute of Computer Science, University of Hildesheim, Hildesheim, Germany; Department of Engineering, Aarhus University, Aarhus, Denmark; Software Engineering Institute, Carnegie Mellon University, Pittsburgh, PA, United States},
  art_number              = {6575257},
  author_keywords         = {Integration; Patterns; SoS Development; System of Systems architecture},
  correspondence_address1 = {University of Hawaii, Honolulu, HI, United States},
  document_type           = {Conference Paper},
  doi                     = {10.1109/SYSoSE.2013.6575257},
  isbn                    = {9781467355971},
  journal                 = {Proceedings of 2013 8th International Conference on System of Systems Engineering: SoSE in Cloud Computing and Emerging Information Technology Applications, SoSE 2013},
  keywords                = {Novel patterns; Patterns; SoS Development; System of systems; System-of-systems architecture; Systems of systems, Architecture; Cloud computing; Information technology; Integration, Systems engineering},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883182787&doi=10.1109%2fSYSoSE.2013.6575257&partnerID=40&md5=e3e1bd8b4cd396ee2c29fbfbbd0cdeae},
}

@Conference{Jones-Wyatt2013408,
  author                  = {Jones-Wyatt, E. and Domercant, J.C. and Mavris, D.N.},
  title                   = {A reliability-based measurement of interoperability for systems of systems},
  year                    = {2013},
  pages                   = {408-413},
  note                    = {cited By 3},
  abbrev_source_title     = {SysCon - Annu. IEEE Int. Syst. Conf., Proc.},
  abstract                = {The increasing complexity of net-centric systems of systems requires each system to be interoperable to achieve operational goals. Interoperability can be considered a metric of an architecture, and must be understood by decision makers as early as the conceptual design phase. Many measurements of interoperability of system pairs exist, but an architecture-level method for calculating interoperability of a system of systems is not currently available. This research presents a flexible, intuitive measure of interoperability of system pairs within a potential architecture performing a set of resource exchanges. It draws from reliability theory to incorporate system requirements and to link the interoperability of a system of systems with operational metrics of performance. This measure of interoperability could provide decision makers with information about an architecture and allow them to compare existing and potential systems of systems during the early phases of acquisition. © 2013 IEEE.},
  affiliation             = {Aerospace Systems Design Laboratory, Georgia Institute of Technology, Atlanta, GA, United States},
  art_number              = {6549914},
  author_keywords         = {acquisition; architectures; interoperability; reliability; systems of systems},
  correspondence_address1 = {Aerospace Systems Design Laboratory, Georgia Institute of Technology, Atlanta, GA, United States},
  document_type           = {Conference Paper},
  doi                     = {10.1109/SysCon.2013.6549914},
  isbn                    = {9781467331067},
  journal                 = {SysCon 2013 - 7th Annual IEEE International Systems Conference, Proceedings},
  keywords                = {acquisition; Conceptual design phase; Metrics of performance; Net-centric systems; Potential systems; System of systems; System requirements; Systems of systems, Architecture; Conceptual design; Decision making; Reliability; Systems engineering, Interoperability},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84882981415&doi=10.1109%2fSysCon.2013.6549914&partnerID=40&md5=1224d4cbf4175158bf645f5aad8dc58f},
}

@Article{Dickerson2013549,
  author                  = {Dickerson, C.E.},
  title                   = {A relational oriented approach to system of systems assessment of alternatives for data link interoperability},
  journal                 = {IEEE Systems Journal},
  year                    = {2013},
  volume                  = {7},
  number                  = {4},
  pages                   = {549-560},
  issn                    = {19328184},
  note                    = {cited By 4},
  abbrev_source_title     = {IEEE Syst. J.},
  abstract                = {ROSE is applied to a large-scale SoS tactical data link interoperability problem. A model-driven framework structure developed using the ROSE methodology is employed to prescribe a repeatable approach for determining viable candidate solutions that complete and make rigorous a previous capability-based exploratory analysis performed by the Office of the Chief Engineer of the U.S. Navy. This novel and efficient approach to a long-standing problem concentrates on the relationships between models to provide a framework and factorization of an SoS architecture for portfolio selection and evaluation. The approach is demonstrated in a simplified, but end-to-end, case study derived from the original data link interoperability analysis. The abstract approach employed can be applied to a much wider class of problems than data link interoperability. © 2013 IEEE.},
  affiliation             = {School of Electronic, Electrical and Systems Engineering, Loughborough University, Loughborough, Leicestershire LE11 3TU, United Kingdom},
  art_number              = {6516918},
  author_keywords         = {Architecture; assessment of alternatives; capability-based acquisition; case study; frame; framework; interface; interoperability; Link 16; model; object orientation; relational orientation; relational structure; system of systems; systems engineering; tactical data link; transformation},
  correspondence_address1 = {Dickerson, C.E.; School of Electronic, Electrical and Systems Engineering, Loughborough University, Loughborough, Leicestershire LE11 3TU, United Kingdom; email: c.dickerson@lboro.ac.uk},
  document_type           = {Article},
  doi                     = {10.1109/JSYST.2013.2254215},
  keywords                = {assessment of alternatives; capability-based acquisition; frame; framework; Link 16; Object orientation; Relational orientations; Relational structures; System of systems; Tactical data links; transformation, Architecture; Interfaces (materials); Models; Systems engineering, Interoperability},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885178813&doi=10.1109%2fJSYST.2013.2254215&partnerID=40&md5=016caf266ca5aaff1c5e2aecaca87b27},
}

@Article{VanLeer201323,
  author                  = {VanLeer, M.D. and Jain, R.},
  title                   = {A framework to address the impact of system of systems integration using commercially off the shelf (COTS) technology},
  journal                 = {International Journal of System of Systems Engineering},
  year                    = {2013},
  volume                  = {4},
  number                  = {1},
  pages                   = {23-43},
  issn                    = {17480671},
  note                    = {cited By 2},
  abbrev_source_title     = {Int. J. Syst. Syst. Eng.},
  abstract                = {For systems engineering, systems integration (SI) establishes linkages between hardware (HW), software (SW), products, services, processes and humans. Over the last decade the world of systems development has evolved rapidly particularly in the use of commercial-off-the-shelf (COTS) products as elements of larger systems. The growing trend toward COTS-based systems (CBS) architectures is based on modular components available within the market. This trend has presented various challenges for systems engineering practitioners attempting to understand the implications of using COTS products within these large and complex projects. This paper analyses those unique aspects of COTS products that influence the SI process differently than the integration of 'in-house' custom developed products. Copyright © 2013 Inderscience Enterprises Ltd.},
  affiliation             = {Sustainability Consortium, University of Arkansas, 534 West Research Center, Blvd., ENTR 120, Fayetteville, AR 72701, United States; Department of Industrial and Systems Engineering, National University of Singapore, 1 Engineering Drive 2, 117576, Singapore, Singapore},
  author_keywords         = {CBS; Commercial off the shelf; COTS; COTS-based systems; Systems integration; Systems life cycle; Systems of systems architecture; Systems of systems integration complexity; Systems requirements},
  correspondence_address1 = {VanLeer, M.D.; Sustainability Consortium, University of Arkansas, 534 West Research Center, Blvd., ENTR 120, Fayetteville, AR 72701, United States; email: mary.vanleer@att.net},
  document_type           = {Article},
  doi                     = {10.1504/IJSSE.2013.053490},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876960591&doi=10.1504%2fIJSSE.2013.053490&partnerID=40&md5=bd8f5fbc185206cd8dd3e153fd707fcb},
}

@Conference{Mordecai20131304,
  author              = {Mordecai, Y. and Dori, D.},
  title               = {I5: A model-based framework for architecting system-of-systems interoperability, interconnectivity, interfacing, integration, and interaction},
  year                = {2013},
  volume              = {2},
  pages               = {1304-1325},
  publisher           = {INCOSE-International Council on Systems Engineering},
  note                = {cited By 4},
  abbrev_source_title = {Anu. Int. Symp. Of . Int. Counc. Syst. Eng.},
  abstract            = {We present I5 - Interoperability, Interconnectivity, Interfacing, Integration, and Interaction - a Model-Based Framework for Architecting Systems-of-Systems. Interoperability programs deliver end-to-end cooperation and collaboration capabilities and services among organizations, users, systems, and infrastructures, on top of a set of existing systems. Each system has its own programmatic and technical constraints and issues. System-level stakeholders usually prefer core functionality over integration, and expect the interconnectivity infrastructure to be transparent and simple, regardless of its actual cost, complexity, or criticality. Hence, coordinating and aligning the multiple system and team efforts in order to reach a synergetic effect is a challenge that many integration professionals in the cyber, energy, manufacturing, and traffic domains are familiar with. Traditional system-centered design methods fail to capture interconnectivity and collaboration aspects and issues, and they are of little interest to the individual systems' stakeholders. The framework we propose is based on Object-Process Methodology, an emerging ISO standard (ISO 19450) for modeling and design of complex, dynamic, and multidisciplinary systems. Our framework facilitates a smooth transition from a set of disparate system-centered views to a consolidated, integrated model, which accounts for integration aspects, interface and payload structure and behavior, interconnectivity processes and services, and eventually emergent interoperability capabilities. © 2013 by Author Name.},
  affiliation         = {Israel Institute of Technology, Israel; Massachusetts Institute of Technology, United States},
  author_keywords     = {Enterprise integration; Interconnectivity; Interface modeling; Interoperability; Model based systems engineering; Object process methodology; Systems of systems},
  document_type       = {Conference Paper},
  journal             = {23rd Annual International Symposium of the International Council on Systems Engineering, INCOSE 2013},
  keywords            = {Integration; Systems engineering, Enterprise Integration; Interconnectivity; Interface model; Model-based systems engineering; Object-process methodology; Systems of systems, Interoperability},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896292248&partnerID=40&md5=a407b2478e221698e372361669e9e43e},
}

@Conference{Buscher2013426,
  author              = {Buscher, M. and Bylund, M. and Sanches, P. and Ramirez, L. and Wood, L.},
  title               = {A new manhattan project? Interoperability and ethics in emergency response systems of systems},
  year                = {2013},
  pages               = {426-431},
  publisher           = {Karlsruher Institut fur Technologie (KIT)},
  note                = {cited By 4},
  abbrev_source_title = {ISCRAM Conf. Proc. - Int. Conf. Inf. Syst. Crisis Response Manage.},
  abstract            = {In this paper we discuss ethical challenges arising around IT supported interoperability in multi-agency emergency management and explore some methodological responses.},
  affiliation         = {Mobilities.lab, Lancaster University, United Kingdom; Swedish Institute of Computer Science, Kista, Sweden; Fraunhofer Institute for Applied Information Technology (FhG-FIT), Sankt Augustin, Germany; School of Health and Medicine, Lancaster University, United Kingdom},
  author_keywords     = {Emergency response; Ethics; Interoperability; Systems of systems},
  document_type       = {Conference Paper},
  isbn                = {9783923704804},
  journal             = {ISCRAM 2013 Conference Proceedings - 10th International Conference on Information Systems for Crisis Response and Management},
  keywords            = {Information systems; Philosophical aspects; Risk management; Systems engineering, Emergency management; Emergency response; Emergency response systems; Ethics; Manhattan Project; Multi agencies; Systems of systems, Interoperability},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905667649&partnerID=40&md5=4ff359a38c76c33d5fc23e5c4a5e12e4},
}

@Conference{Luna2013298,
  author              = {Luna, S. and Lopes, A. and Tao, H.Y.S. and Zapata, F. and Pineda, R.},
  title               = {Integration, verification, validation, test, and evaluation (IVVT\&E) framework for system of systems (SoS)},
  year                = {2013},
  volume              = {20},
  pages               = {298-305},
  publisher           = {Elsevier B.V.},
  note                = {cited By 12},
  abbrev_source_title = {Procedia Comput. Sci.},
  abstract            = {The traditional systems engineering (SE) methodologies for integration, verification, validation, test and evaluation (IVVT&E) throughout the lifecycle are focused on expected outcomes (behavior, capabilities), which may not necessarily apply for system of systems (SoS), where some emergent behavior and knowledge may be needed in untested scenarios (unknown environments). Next-generation SoS consisting of partially or fully decentralized systems are incorporating advances in computing, sensing, and communications operations to address uncertainty and emergence in SoS. Thus, current standardized and formalized IVVT&E methodologies will need to be modified, adapted, or an evolutionary IVVT&E framework for SoS is required to test and evaluate integrated SoS capabilities in unknown scenarios. This paper discusses several potential strategies and explores possible methodologies that may be applied to develop a SoS IVVT&E framework, as applied to an unmanned aerial system (UAS), based on existing architectural frameworks such as Department of Defense Architecture Framework (DoDAF). © 2013 The Authors. Published by Elsevier B.V.},
  affiliation         = {Stevens Institute of Technology, University of Texas, El Paso, United States; Research Institute for Manufacturing and Engineering Systems, University of Texas, El Paso, United States},
  author_keywords     = {Combinatorial testing methodologies; Department of defense architecture framework (DoDAF); Design structure matrix (DSM); Integration; System of systems (SoS); Unmanned aerial systems (UAS); Validation (IVV); Verification},
  document_type       = {Conference Paper},
  doi                 = {10.1016/j.procs.2013.09.276},
  issn                = {18770509},
  journal             = {Procedia Computer Science},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896998269&doi=10.1016%2fj.procs.2013.09.276&partnerID=40&md5=343f3f4dcadb8ead7b89b10de9936820},
}

@Conference{Vaneman20131272,
  author              = {Vaneman, W.K. and Budka, R.},
  title               = {Defining a system of systems engineering and integration approach to address the Navy's information technology technical authority},
  year                = {2013},
  volume              = {2},
  pages               = {1272-1284},
  publisher           = {INCOSE-International Council on Systems Engineering},
  note                = {cited By 2},
  abbrev_source_title = {Anu. Int. Symp. Of . Int. Counc. Syst. Eng.},
  abstract            = {The United States Navy's focus on Information Dominance as a warfare enabler requires an integrated and coordinated System of Systems (SoS) for mission success. The Space and Naval Warfare Systems Command (SPAWAR) has been designated the Information Technology Technical Authority (IT TA) to address the challenges posed by this unprecedented interoperability among Navy systems. To address these engineering and planning challenges, SPAWAR has adopted a System of Systems Engineering and Integration (SoSE&I) methodology. SoSE&I is the planning, analyzing, and integrating constituent systems into an SoS capability greater than the sum of those systems. This paper defines the SoSE&I "Vee" process model, and discusses how it is used to engineer the SoS throughout its life-cycle, and how it can be used by decision-makers to increase systems integration and interoperability to directly impact the operational effectiveness of the Navy's networks and weapons. © 2013 by Warren K. Vaneman and Richard Budka.},
  affiliation         = {Naval Postgraduate School, 777 Dyer Road, Monterey, CA 93943-5189, United States; Customer Inspired Solutions, LLC, 700 American Ave., Suite 303, King of Prussia, PA 19406, United States},
  author_keywords     = {Information dominance; Model-based systems engineering; System of systems engineering and integration},
  document_type       = {Conference Paper},
  journal             = {23rd Annual International Symposium of the International Council on Systems Engineering, INCOSE 2013},
  keywords            = {Information technology; Integration; Systems engineering, Coordinated system; Information dominance; Integration approach; Model-based systems engineering; Operational effectiveness; Space and Naval warfare systems; System of systems engineering; Systems integration, Interoperability},
  language            = {English},
  source              = {Scopus},
  url                 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896307425&partnerID=40&md5=15c75c9bdee0fea528d298de3d1399af},
}

@Article{Daclin2012245,
  author                  = {Daclin, N.},
  title                   = {Embedding interoperability in system of systems: Definition and characterization of fundamental requirements},
  journal                 = {IFIP Advances in Information and Communication Technology},
  year                    = {2012},
  volume                  = {380 AICT},
  pages                   = {245-253},
  issn                    = {18684238},
  note                    = {cited By 1},
  abbrev_source_title     = {IFIP Advances in Information and Communication Technology},
  abstract                = {The main objective of this communication is to discuss the engineering of a System of Systems (SoS), including interoperability concept. More precisely, the here presented research focuses on the fundamental requirements to consider in a System of Systems Engineering (SoSE) project and that have to be maintain during the entire life cycle of a SoS. First, the concept of interoperability, according to its definition and its characteristics, is presented. Then, the concept of SoS is presented in the same manner. This leads to introduce and present the possible links between System of Systems and interoperability. These links are (1) clarified and defined, (2) re-expressed to meet requirements' definition and (3) not related to a given SoS in order to be generic. © 2012 International Federation for Information Processing.},
  affiliation             = {LGI2P - Laboratoire de Génie Informatique et d'Ingénierie de Production, Site de l'Ecole des Mines d'Alès, Parc Scientifique G. Besse, Nîmes Cedex 1 30035, France},
  author_keywords         = {interoperability; requirements; System Engineering; System of Systems},
  correspondence_address1 = {Daclin, N.; LGI2P - Laboratoire de Génie Informatique et d'Ingénierie de Production, Site de l'Ecole des Mines d'Alès, Parc Scientifique G. Besse, Nîmes Cedex 1 30035, France; email: nicolas.daclin@mines-ales.fr},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-642-32775-9_25},
  isbn                    = {9783642327742},
  keywords                = {requirements; System of systems; System of systems engineering, Systems engineering; Virtual corporation, Interoperability},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870376670&doi=10.1007%2f978-3-642-32775-9_25&partnerID=40&md5=a71aa8a8c521a8878b0f0189362849ff},
}

@Conference{Curry2012101,
  author                  = {Curry, E.},
  title                   = {System of systems information interoperability using a linked dataspace},
  year                    = {2012},
  pages                   = {101-106},
  note                    = {cited By 27},
  abbrev_source_title     = {Proc. - Int. Conf. Syst. Syst. Eng., SoSE},
  abstract                = {System of Systems pose significant technical challenges in terms of information interoperability that require overcoming conceptual barriers (both syntax and semantic) and technological barriers. This paper presents an approach to System of Systems information interoperability based on the Dataspace data management abstraction and the Linked Data approach to sharing information on the web. The paper describes the fundamentals of the approach and demonstrates the concept with a System of Systems for enterprise energy management. © 2012 IEEE.},
  affiliation             = {Digital Enterprise Research Institute, National University of Ireland, Galway, Ireland},
  art_number              = {6384200},
  author_keywords         = {energy management; interoperability; linked data; System of systems},
  correspondence_address1 = {Curry, E.; Digital Enterprise Research Institute, National University of Ireland, Galway, Ireland; email: ed.curry@deri.org},
  document_type           = {Conference Paper},
  doi                     = {10.1109/SYSoSE.2012.6384200},
  isbn                    = {9781467329750},
  journal                 = {Proceedings - 2012 7th International Conference on System of Systems Engineering, SoSE 2012},
  keywords                = {Enterprise energy management; Information interoperability; Linked data approaches; Linked datum; Sharing information; System of systems; Technical challenges; Technological barriers, Data handling; Energy management; Information management; Semantics; Systems engineering, Interoperability},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872420666&doi=10.1109%2fSYSoSE.2012.6384200&partnerID=40&md5=19e1cb8ea23abcc353f84aefdba695d0},
}

@Conference{Gianni20122705,
  author                  = {Gianni, D. and D'Ambrogio, A. and De Simone, P. and Lisi, M. and Luglio, M.},
  title                   = {Model-based interface specification for systems integration in systems of systems engineering},
  year                    = {2012},
  volume                  = {4},
  pages                   = {2705-2717},
  note                    = {cited By 2},
  abbrev_source_title     = {Annu. Int. Sympos. Int. Counc. Syst. Eng., INCOSE, Biennial Eur. Syst. Eng. Conf., EuSEC},
  abstract                = {The key to enable systems integration is that systems inter-communications are accurately and unambiguously specified. In line with ongoing Model-based Systems Engineering (MBSE) initiatives aiming to support systems engineering activities by means of formal and graphical models, we have introduced a logical model for the definition of Interface Communication Modelling Language (ICML), to enable a model-based approach for interface specification. ICML is based on UML and can potentially be integrated with other systems models in similar forms, e.g., SySML, and with systems of systems models in UPDM or related frameworks. We have designed ICML basing on a preliminary domain analysis on radio signal specifications, with application to space systems. In the analysis, we have specifically considered simple digital and unidirectional signals, and subsequently we have included a method to use ICML for Time-Division Multiplexed signals. We also present an excerpt of the ICML metamodel and a simple example application. © 2012 by Daniele Gianni et al.},
  affiliation             = {European Space Agency, Noordwijk, Netherlands; Dept. of Enterprise Engineering, University of Rome TorVergata, Rome, Italy; Dept. of Electronics Engineering, University of Rome TorVergata, Rome, Italy},
  correspondence_address1 = {Gianni, D.; European Space Agency, Noordwijk, Netherlands; email: daniele.gianni@esa.int},
  document_type           = {Conference Paper},
  isbn                    = {9781622769162},
  journal                 = {22nd Annual International Symposium of the International Council on Systems Engineering, INCOSE 2012 and the 8th Biennial European Systems Engineering Conference 2012, EuSEC 2012},
  keywords                = {Engineering activities; Interface specification; Model based approach; Model-based systems engineering (MBSE); Modelling language; Multiplexed signals; Systems integration; Systems of systems, Specifications, Systems engineering},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884132292&partnerID=40&md5=137b25c099fd2308a19460fd8ff866b8},
}

@Conference{Nagano2012,
  author                  = {Nagano, S.},
  title                   = {Robust and cost-effective aerospace complex systems/system of systems integration based on distributed systems integration},
  year                    = {2012},
  note                    = {cited By 0},
  abbrev_source_title     = {AIAA SPACE Conf. Exp. 2012},
  abstract                = {Complex systems science and complex systems/System of systems engineering are recently gaining much interest in many fields of science and engineering particularly in the aerospace community. Well coordinated activities between the fields of "Complex Systems Science" and "Complex Systems/System of Systems Engineering" are essential for developing a well integrated, robust, and cost-effective complex system that satisfies its stakeholders' needs. "Complex Systems Science" enables us to scientifically observe and analyze the behavior of an "object of interest" along with the causes and effects of its internal/external phenomena; thus, it helps stakeholders to establish a well defined set of mission requirements which they are trying to satisfy by effectively integrating newly developing and heritage systems. The "object of interests", as an example, may be airport locations, their traffic size, communication capabilities, population trends, and weather conditions, etc.. Each of these objects of interests demands scientific investigation and analysis to understand their behaviors in order to establish a solid set of mission requirements for developing a very effective air traffic control system. The system integrator of this "Complex Systems/System of Systems", can then develop a robust air traffic control system with the use of "Distributed" systems integration processes that satisfies each of these mission requirements. In another example, the object of interests may be the locations of objects, required time to detect and response to conflicts areas, involved weapons, and political environments of the international and the region of interests. The developing system may be a complex unmanned aerial vehicle system integrated with space systems that can fully satisfy the mission requirements developed by the stakeholders. For any aerospace system to be acceptable, it is utmost important that an integrated system must be that of a "quasi deterministic system" in which its outputs can be predicted under giving inputs and environmental conditions with a very high confidence. Otherwise, it can cause unbearable human causality as well as social, political, and financial disasters. © 2012 by the American Institute of Aeronautics and Astronautics, Inc. All rights reserved.},
  affiliation             = {M6-213 P.O Box 92977, Los Angeles, CA 90009, United States},
  correspondence_address1 = {Nagano, S.M6-213 P.O Box 92977, Los Angeles, CA 90009, United States},
  document_type           = {Conference Paper},
  isbn                    = {9781600869402},
  journal                 = {AIAA SPACE Conference and Exposition 2012},
  keywords                = {Communication capabilities; Coordinated activity; Deterministic systems; Environmental conditions; Mission requirements; Science and engineering; Scientific investigation; Unmanned aerial vehicle systems, Aerospace engineering; Aircraft accidents; Control systems; Control towers; Cost effectiveness; Large scale systems; Systems engineering, Coordination reactions},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881010352&partnerID=40&md5=bebe78b743e8c3865cd9bf0278b51a78},
}

@Conference{Badger2012,
  author                  = {Badger, M. and Bushmitch, D. and Agnish, V. and Cozby, R. and Fikus, J. and Halloran, F. and Chang, K. and McCabe, P. and Erramilli, S.},
  title                   = {Laboratory-based end-to-end network System of Systems Integration, design and risk reduction: Critical activity for System of Systems Integration Directorate and the Army},
  year                    = {2012},
  note                    = {cited By 3},
  abbrev_source_title     = {Proc IEEE Mil Commun Conf MILCOM},
  abstract                = {The Army is currently using the Network Integration Events (NIE) to test emerging technologies in a relevant military environment with soldiers operating the equipment. This process strengthens the design and deployment process as network integrators are able to detect and diagnose problems and equipment glitches before they affect deployed troops. However, past events have demonstrated that a large number of network problems experienced during the NIE are time consuming to troubleshoot and require expert intervention from engineers in the field. To address this, the System of Systems Integration Directorate has begun the process of Laboratory Based Risk Reduction (LBRR) that performs network integration, design and automated analysis in a laboratory environment prior to each NIE. This allows prescreening of the NIE integrated network enabling the early discovery of problems related to integration, debugging of network anomalies by subject matter experts in a controlled environment, early detection of incorrect configurations and up-front analysis of network performance. LBRR uses capabilities that include 1) Thread-based lab testing, 2) Unified Offered Load, 3) Communication Effects through waveform emulation and 4) Automated performance analysis. To date, this LBRR approach has been used in advance of NIE 12.2 and the results are encouraging. The lab-based integration exercise helped in discovering numerous technical problems related to integrating the highly heterogeneous network many of them of a critical nature that would have caused extensive delays during the NIE. With LBRR, the vendors and Army programs were able to provide fixes or workarounds in time for NIE. For future NIEs, it is anticipated that the full LBRR capability set will provide more sophisticated analysis and results. © 2012 IEEE.},
  art_number              = {6415712},
  coden                   = {PMICE},
  correspondence_address1 = {Agnish, V.email: vivek.agnish@us.army.mil},
  document_type           = {Conference Paper},
  doi                     = {10.1109/MILCOM.2012.6415712},
  isbn                    = {9781467317290},
  journal                 = {Proceedings - IEEE Military Communications Conference MILCOM},
  keywords                = {Automated analysis; Automated performance analysis; Communication effects; Controlled environment; Critical activities; Deployment process; Emerging technologies; End-to-end network; Integrated networks; Lab testing; Laboratory environment; Military environment; Network anomalies; Network integration; Network problems; Offered loads; Prescreening; Risk reductions; Subject matter experts; System of systems; Troubleshoots; Wave forms, Computer aided software engineering; Design; Heterogeneous networks; Integration; Laboratories; Military communications; Network performance, Systems engineering},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874305828&doi=10.1109%2fMILCOM.2012.6415712&partnerID=40&md5=d4fd82b3fdc6543ff639d4ae84f7c32f},
}

@Conference{Wyatt2012240,
  author                  = {Wyatt, E.J. and Griendling, K. and Mavris, D.N.},
  title                   = {Addressing interoperability in military systems-of-systems architectures},
  year                    = {2012},
  pages                   = {240-247},
  note                    = {cited By 5},
  abbrev_source_title     = {SysCon - IEEE Int. Syst. Conf., Proc.},
  abstract                = {The increasing complexity of net-centric warfare requires systems to be interoperable to achieve mission success. Established methods do exist to measure various forms of interoperability; however, these methods tend to be specific towards a certain application, and often are qualitative rather than quantitative assessments. This research surveys existing interoperability measurement methods and assesses them from the perspective of using interoperability as a metric to evaluate system-of-systems architectures. The goal is to identify metrics useful to quantify interoperability during the early phases of the joint acquisition process and provide decision-makers with information about a potential architecture's interoperability during the selection of a new military system-of-systems. © 2012 IEEE.},
  affiliation             = {Aerospace Systems Design Laboratory, Georgia Institute of Technology, Atlanta, GA, United States},
  art_number              = {6189515},
  author_keywords         = {acquisition; architectures; interoperability; system-of-systems},
  correspondence_address1 = {Wyatt, E.J.; Aerospace Systems Design Laboratory, Georgia Institute of Technology, Atlanta, GA, United States; email: ejones@asdl.gatech.edu},
  document_type           = {Conference Paper},
  doi                     = {10.1109/SysCon.2012.6189515},
  isbn                    = {9781467307499},
  journal                 = {SysCon 2012 - 2012 IEEE International Systems Conference, Proceedings},
  keywords                = {acquisition; Decision makers; Joint acquisition; Measurement methods; Mission success; Net-centric warfare; Quantitative assessments; Research survey; System-of-systems; System-of-systems architecture; Systems-of-systems architecture, Architecture; Military applications, Interoperability},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861321800&doi=10.1109%2fSysCon.2012.6189515&partnerID=40&md5=e831fa5c3b65b28f052c9351b0602294},
}

@Conference{Mazzuchi2011806,
  author                  = {Mazzuchi, T. and Albakri, G.},
  title                   = {System of systems engineering facilitates integration of large scale complex systems},
  year                    = {2011},
  volume                  = {1},
  pages                   = {806-841},
  note                    = {cited By 3},
  abbrev_source_title     = {Annu. Int. Symp. Int. Counc. Syst. Eng., INCOSE},
  abstract                = {Systems of Systems Engineering, SOSE, is a new field and opens a wide challenge for Systems Engineering researchers who are dealing with large scale complex systems. Integration is one of many tasks required by Systems Engineers who are involved in the process of acquiring a working system that fulfills the main mission of the large scale system. Generally, there are three large scale complex systems cases that need to be integrated: 1) new systems with new systems, 2) old systems with new systems, and 3) old systems with old systems. In the literature,the main focus of the research is on Systems Engineering integration processes for systems which are still under design and before their final phase-out. This research presents a contribution to define the System of Systems Engineering (SOSE) science through facilitating the integration of two existing large scale complex systems "old system to old system" into one using a simple and clear new process model for integration. One of the reasons for selecting this caseis the significant need to integrate "old systems with other old systems". The integration process has many approaches and models, i.e. V-Model which is mostly used during the life cycle of building a system. What makes this research unique is the introduction of the "M-model" thatfacilitates integration of "existing / old" large scale complex systems with each other. The M-Model starts with defining the "Problem statement," then the sequence of building-up documents and plans leads to a master plan documented called "SOSE Master Plan (SOSEMP)." Some case studies will be discussed.},
  affiliation             = {School of Engineering and Applied Science, GWU, Eng. Management and Systems Engineering, United States; School of Engineering and Applied Science, GWU, EMSE Ph. D. Graduate, Embassy of UAE/Military, United States},
  correspondence_address1 = {Mazzuchi, T.; School of Engineering and Applied Science, GWU, Eng. Management and Systems EngineeringUnited States},
  document_type           = {Conference Paper},
  isbn                    = {9781618391155},
  journal                 = {21st Annual International Symposium of the International Council on Systems Engineering, INCOSE 2011},
  keywords                = {Integration process; Large-scale complex systems; Master plan; Problem statement; Process model; System of systems engineering; Systems engineers; Working systems, Integration; Large scale systems; Research, Systems engineering},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879294517&partnerID=40&md5=fa8a688eb3347359766150c42c6f6d97},
}

@Conference{Farroha2011182,
  author                  = {Farroha, D.L. and Farroha, B.S.},
  title                   = {Agile development for system of systems: Cyber security integration into information repositories architecture},
  year                    = {2011},
  pages                   = {182-188},
  note                    = {cited By 8},
  abbrev_source_title     = {IEEE Int. Syst. Conf., SysCon - Proc.},
  abstract                = {In order to meet the mission needs of today and keep up with the pace of technological advances, adapting the Enterprise Systems Engineering (ESE) process in a time constrained mission-centric environment is critical to leverage the efficient delivery of new capabilities in a Net Centric environment. Agility (contemporary) versus rigidity (traditional) are approaches that have their trade-offs but to meet the demands and needs of our war-fighters, we must have an ESE process that allows us to deliver quality capabilities to the tactical edge. Governance plays a significant role and testing services needs to be addressed different from the traditional T&E of stovepiped systems. The traditional approach of building systems to deliver a specific function is being changed to an approach of architecting services. ESE utilizes defined processes that use managerial and technical tools to analyze problems and provide structure to the overall process of planning, procuring, designing, implementing and testing an enterprise system. Adding agility and assurance to the traditional and ESE is the process by which we build quality into complex systems while delivering functionality and security of contents in a manageable timeframe and stay flexible to meet emerging requirements. This study is based on architecting the GIG which is the ultimate complex system. Utilizing the DoD's framework to facilitate information sharing; which starts with data discovery and access, we analyzed several concepts to achieve agility and higher level of security in Information Sharing Systems. The concept of the GIG also ensures that systems are not only robust but also incorporate the flexibility needed to satisfy needs that evolve during the system's life. © 2011 IEEE.},
  affiliation             = {Department of Defense, Ft Meade, MD, United States},
  art_number              = {5929083},
  correspondence_address1 = {Farroha, D.L.; Department of Defense, Ft Meade, MD, United States; email: deborah.l.farroha@ugov.gov},
  document_type           = {Conference Paper},
  doi                     = {10.1109/SYSCON.2011.5929083},
  isbn                    = {9781424494927},
  journal                 = {2011 IEEE International Systems Conference, SysCon 2011 - Proceedings},
  keywords                = {Agile development; Build quality; Building systems; Cyber security; Data discovery; Deliver quality; Enterprise system; Enterprise-systems engineering; Information repositories; Information sharing; Information sharing systems; Net-centric environments; System of systems; Technical tools; Technological advances, Enterprise resource planning; Information dissemination; Information management; Information retrieval; Large scale systems; Systems engineering, Security of data},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960592365&doi=10.1109%2fSYSCON.2011.5929083&partnerID=40&md5=63e2c7971d78a8f43019910e2104b2c6},
}

@Conference{Ramalingam2011448,
  author                  = {Ramalingam, K. and Kalawsky, R. and Noonan, C.},
  title                   = {Integration of Unmanned Aircraft System (UAS) in non-segregated airspace: A complex system of systems problem},
  year                    = {2011},
  pages                   = {448-455},
  note                    = {cited By 9},
  abbrev_source_title     = {IEEE Int. Syst. Conf., SysCon - Proc.},
  abstract                = {Unmanned Aircraft System (UAS) has been primarily used in the military domain, and their use has increased tremendously in the last decade. UAS provide several distinct operational capabilities and cost advantages compared to manned aircrafts in most situations. It has long been postulated that use of Unmanned Aircraft Systems (UAS) in the civil domain will enable overall improvement in effectiveness of performance in many civil applications currently performed by manned aircrafts and it will provide potential long term cost savings for the UAS operators. UAS would also give rise to whole host of new applications, which have not yet been envisaged. However the civil UAS industry has not yet started due to the restricted access of UAS in segregated areas of the national airspace and inability to routinely access national airspace alongside manned aircrafts. This paper proposes that the integration of UAS in nonsegregated airspace is a complex system-of-systems problem with a level of difficulty well beyond the technical challenges involved in the development, implementation and validation of the system. The routine operation of UAS in national airspace is as much of a political and emotional issue because the aviation regulatory authorities are swayed as much by current political environment and public perception towards the issue. Beyond public concerns, the system design problem is inherently complex. The size and lower costs are two major benefits of UAS. However to design a UAS which has high safety standards and follows same level of equivalence and transparency as manned aircrafts without compromising on two major advantages of UAS, is a big challenge. © 2011 IEEE.},
  affiliation             = {Loughborough University, Loughborough LE11 3TU, United Kingdom; Department of Systems Division, Loughborough University, Loughborough LE11 3TU, United Kingdom},
  art_number              = {5929108},
  author_keywords         = {Air Traffic Management; System of Systems; Unmanned Aircraft System},
  correspondence_address1 = {Ramalingam, K.; Loughborough University, Loughborough LE11 3TU, United Kingdom},
  document_type           = {Conference Paper},
  doi                     = {10.1109/SYSCON.2011.5929108},
  isbn                    = {9781424494927},
  journal                 = {2011 IEEE International Systems Conference, SysCon 2011 - Proceedings},
  keywords                = {Air Traffic Management; Civil applications; Cost advantages; Cost saving; High safety; Lower cost; Manned aircraft; Military domains; National air spaces; New applications; Operational capabilities; Public concern; Public perception; Regulatory authorities; System of systems; Technical challenges; Unmanned aircraft system, Air traffic control; Aircraft; Behavioral research; Systems analysis; Systems engineering, Unmanned aerial vehicles (UAV)},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960584093&doi=10.1109%2fSYSCON.2011.5929108&partnerID=40&md5=2323d8b6453fae9974f2778a22d88181},
}

@Article{Wu2011479,
  author                  = {Wu, Y. and Wang, X. and Lin, Y.},
  title                   = {An integration process model of enterprise information system families based on system of systems},
  journal                 = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year                    = {2011},
  volume                  = {6729 LNCS},
  number                  = {PART 2},
  pages                   = {479-485},
  issn                    = {03029743},
  note                    = {cited By 0},
  abbrev_source_title     = {Lect. Notes Comput. Sci.},
  abstract                = {Based on the theory of system of systems (SoS), an integration process model of an enterprise information system family is discussed. The model is stratified into two levels, the top-level sub-processes of SoS and the bottom-level sub-processes of component systems, and the mapping relations between activities in sub-processes are classified as horizontal and vertical, which all contribute to better internal consistency. To support the dynamic integration environment of an enterprise information system family, the model is also designed to be an iterative process. Finally, based on the proposed model, we present an example of an enterprise information system family integration process in an auto industry chain. © 2011 Springer-Verlag.},
  affiliation             = {School of Software Engineering, Chongqing University, Chongqing, China; School of Mechanical Engineering, Chongqing University, Chongqing, China},
  author_keywords         = {Enterprise Information System Family; Integration Process; System of Systems},
  correspondence_address1 = {Wu, Y.; School of Software Engineering, Chongqing University, Chongqing, China; email: wyb@cqu.edu.cn},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-642-21524-7_59},
  isbn                    = {9783642215230},
  keywords                = {Auto industry; Component systems; Enterprise information system; Integration Process; Internal consistency; Iterative process; Mapping relation; System of Systems, Artificial intelligence; Cellular automata; Industry; Integration; Systems engineering, Information systems},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79958224398&doi=10.1007%2f978-3-642-21524-7_59&partnerID=40&md5=c9210eb7de5fc699f8f9c2e17d93c4e3},
}

@Conference{Mane20103798,
  author                  = {Mane, M. and DeLaurentis, D.},
  title                   = {System integration and risk propagation in aeronautical systems-of-systems},
  year                    = {2010},
  volume                  = {5},
  pages                   = {3798-3807},
  note                    = {cited By 1},
  abbrev_source_title     = {Cong. Int. Counc. Aeronaut. Sci. ICAS},
  abstract                = {The capability-based acquisition approach emphasizes required operational capabilities (rather than individual system performance) and thus directly leads to the simultaneous development of systems that must eventually interact within a system-of-systems. As a result, system interdependencies in the development and acquisition processes increase complexity and risk as well as complicate the tradeoff between risk and capability. The authors' prior work has developed a Computational Exploratory Model to simulate the development processes of interdependent systems intended for a system-of-systems capability. The progress documented in this paper focuses on the impact of network topologies on the propagation of disruption and achievement of target capabilities. The enhanced model differentiates the effectiveness of alternate configurations of constituent systems and quantifies the impact of varying levels of interdependencies on the timely completion of a project that aims to achieve a target capability. A proof-of-concept application problem examining options for missile defense detection and tracking is presented, including the identification of non-dominated solutions thatoffer a balance of development time and capability level.},
  affiliation             = {Purdue University, West Lafayette, IN 47907-2023, United States},
  author_keywords         = {Delay propagation; System interdependencies},
  correspondence_address1 = {Mane, M.; Purdue University, West Lafayette, IN 47907-2023, United States},
  document_type           = {Conference Paper},
  isbn                    = {9781617820496},
  journal                 = {27th Congress of the International Council of the Aeronautical Sciences 2010, ICAS 2010},
  keywords                = {Application problems; Delay propagation; Detection and tracking; Development process; Interdependent systems; Nondominated solutions; Operational capabilities; System interdependencies, Electric network topology, Aerodynamics},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878475050&partnerID=40&md5=36085066175388750bd70f6abdc37a33},
}

@Article{AsadNaqvi2010201,
  author                  = {Asad Naqvi, S. and Chitchyan, R. and Zschaler, S. and Rashid, A. and Südholt, M.},
  title                   = {Cross-document dependency analysis for system-of-system integration},
  journal                 = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year                    = {2010},
  volume                  = {6028 LNCS},
  pages                   = {201-226},
  issn                    = {03029743},
  note                    = {cited By 2},
  abbrev_source_title     = {Lect. Notes Comput. Sci.},
  abstract                = {Systems-of-systems are formed through integration of individual complex systems, often not designed to work together. A number of factors can make this integration very challenging which often leads to catastrophic failures. In this paper, we focus on three major classes of system-of-system integration problems: managerial indeendence, interface incompatibility, and component-system complexity. We then present an aspect-oriented requirements description language (RDL) which uses natural language analysis capabilities to reason about dependencies across the documentation of the constituent systems of a system-of-systems. The aspect-oriented compositions in the RDL also facilitate specification of cross-document constraints and inconsistency resolution strategies, which can be used for deriving proof obligations and test cases for verification and validation of the emergent behaviour of a system-of-systems. We showcase the capabilities of our RDL through a case study of a real-world emergency response system. Our analysis shows that the querying and composition capabilities of the RDL provide valuable support for reasoning across documentation of multiple systems and specifying suitable integration constraints. © 2010 Springer-Verlag Berlin Heidelberg.},
  affiliation             = {Lancaster University, Lancaster, United Kingdom; DCS, École des Mines de Nantes, Nantes, France},
  correspondence_address1 = {Asad Naqvi, S.; Lancaster University, Lancaster, United Kingdom; email: naqvis@comp.lancs.ac.uk},
  document_type           = {Conference Paper},
  doi                     = {10.1007/978-3-642-12566-9_11},
  isbn                    = {3642125654; 9783642125652},
  keywords                = {Aspect-oriented; Aspect-oriented composition; Catastrophic failures; Complex systems; Dependency analysis; Description languages; Emergency response systems; Emergent behaviours; Inconsistency resolution; Multiple systems; Natural language analysis; Proof obligations; Real-world; System complexity; System integration; System-of-Systems; Systems-of-systems; Test case; Verification and validation, Security of data},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651303565&doi=10.1007%2f978-3-642-12566-9_11&partnerID=40&md5=8b1458c6fa01cf3a620eb3e45d286bb2},
}

@Conference{Bagdatli2010,
  author                  = {Bagdatli, B. and Griendling, K. and Kalpakchian, D. and Jones, E. and Ussery, S. and Ball, J. and Kallman, J. and Mavris, D.},
  title                   = {A method for examining the impact of interoperability on mission performance in a system-of-systems},
  year                    = {2010},
  note                    = {cited By 4},
  abbrev_source_title     = {IEEE Aerosp. Conf. Proc.},
  abstract                = {This research details the development of a design process and decision-making environment to support the acquisition of an air-based, interoperable, autonomous system-of-systems to support suppression of enemy air defenses missions. 12 The design is done using a three part process, which includes the concurrent development of the DoDAF products, modeling and simulation environment, and decision support environment. In particular, the research focuses on understanding how the interactions, interoperability, and autonomy level of the unmanned aircraft affect the overall mission performance. ©2010 IEEE.},
  affiliation             = {Georgia Institute of Technology, Aerospace Systems Design Laboratory, 270 Ferst Drive, Atlanta, GA 30327, United States},
  art_number              = {5446884},
  author_keywords         = {Architecture; Autonomous; Interoperable; Systems-of-systems; Unmanned},
  correspondence_address1 = {Bagdatli, B.; Georgia Institute of Technology, Aerospace Systems Design Laboratory, 270 Ferst Drive, Atlanta, GA 30327, United States; email: burak.bagdatli@asdl.gatech.edu},
  document_type           = {Conference Paper},
  doi                     = {10.1109/AERO.2010.5446884},
  isbn                    = {9781424438884},
  issn                    = {1095323X},
  journal                 = {IEEE Aerospace Conference Proceedings},
  keywords                = {Autonomous; Autonomous systems; Autonomy levels; Concurrent development; Decision supports; Design process; Interoperable systems; Mission performance; Modeling and simulation; Suppression of enemy air defense; System-of-Systems; Unmanned aircrafts, Computer simulation; Decision support systems; Interoperability, Decision making},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952811768&doi=10.1109%2fAERO.2010.5446884&partnerID=40&md5=7f46af6da99ec0890908bf0e799117b7},
}

@Article{Krüger2010725,
  author                  = {Krüger, I.H. and Meisinger, M. and Menarini, M.},
  title                   = {Interaction-based runtime verification for systems of systems integration},
  journal                 = {Journal of Logic and Computation},
  year                    = {2010},
  volume                  = {20},
  number                  = {3},
  pages                   = {725-742},
  issn                    = {0955792X},
  note                    = {cited By 13},
  abbrev_source_title     = {J Logic Comput},
  abstract                = {Complex distributed systems pose great challenges for quality assurance. Size, complexity and concurrency of these systems often render traditional verification techniques impractical. In particular, this is true for systems integration efforts, where additional challenges arise from the independent evolution of the composed systems. Runtime verification provides a systematic strategy for analytical quality assurance of such systems. Key elements of runtime verification are system models, ways to inject these models into the observed system and a framework for analysing and monitoring the runtime behaviour against the models. The approach we present in this article is based on interaction models. We specify expected system interactions using Message Sequence Charts (MSC), from which we generate distributed runtime monitors for each of the components. We use aspect-oriented programming (AOP) techniques to inject the monitors into the implementation of the components. Thereby, we verify the adherence of the distributed system interactions with the MSC model. The focus of this article is the runtime verification in the systems integration domain; here, Enterprise Service Buses (ESB) have emerged as a powerful infrastructure for integrating complex distributed systems. In the context of an ESB we leverage the Spring AOP framework to inject the runtime monitors. As a result we obtain a comprehensive, tool-supported approach for model-based runtime verification of interactions. We demonstrate our approach using the Central Locking System as running example of an integrated embedded system. © The Author, 2010. Published by Oxford University Press. All rights reserved.},
  affiliation             = {Computer Science and Engineering Department, University of California, San Diego, San Diego, CA 92093-0404, United States},
  author_keywords         = {Aspect-oriented programming; Distributed systems; Message sequence chart; Model-based testing; Runtime monitoring; Runtime verification; Systems integration},
  coden                   = {JLCOE},
  correspondence_address1 = {Krüger, I. H.; Computer Science and Engineering Department, University of California, San Diego, San Diego, CA 92093-0404, United States; email: ikrueger@ucsd.edu},
  document_type           = {Article},
  doi                     = {10.1093/logcom/exn079},
  keywords                = {Aspect-Oriented Programming; Distributed systems; Message Sequence Charts; Model based testing; Run-time verification; Runtime Monitoring, Computer software selection and evaluation; Computer systems programming; Flow patterns; Flowcharting; Integration; Model checking; Model structures; Network components; Quality assurance; Quality control; Total quality management, Mathematical models},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952931585&doi=10.1093%2flogcom%2fexn079&partnerID=40&md5=de65eb6802723ab727ed152cf113ba9b},
}

@Conference{Chang2009199,
  author                  = {Chang, C.F. and Tan, P.H. and Tam, S.K.},
  title                   = {Managing systems of systems interoperability - federated soa and reference architectures},
  year                    = {2009},
  volume                  = {1},
  pages                   = {199-212},
  note                    = {cited By 0},
  abbrev_source_title     = {Annu. Int. Symp. Int. Counc. Syst. Eng., INCOSE},
  abstract                = {New and emerging threats, technology advancements and the advent of the Knowledge Age are driving change in Armed Forces around the world. The Singapore Armed Forces is in the midst of transformation into the 3rd Generation SAF to meet these challenges. As military systems morph into increasing networked and interdependent system of systems, the Defence Science and Technology Agency (DSTA) has also adopted strategies and put in systems engineering efforts to manage the interoperability requirements and complexities of this system of systems. In 2006 DSTA adopted Enterprise Architecture (EA) to facilitate business- Information Technology (IT) alignment and subsequently established a Reference Architecture Framework to ensure interoperability across systems. In this article, we describe the Reference Architecture Framework, the linkage between EA and the Framework, and how the framework will guide the development of the solution blueprint to enable 3rd Generation SAF transformations. © 2009 by Chang Chai Fung, Tan Pong Heng and Tam Soh Khum.},
  affiliation             = {Defence Science and Technology Agency, Depot Road #22-01, Defence Technology Tower A, Singapore 109679, Singapore},
  correspondence_address1 = {Chang, C.F.; Defence Science and Technology Agency, Depot Road #22-01, Defence Technology Tower A, Singapore; email: cchaifun@dsta.gov.sg},
  document_type           = {Conference Paper},
  isbn                    = {9781615674398},
  journal                 = {19th Annual International Symposium of the International Council on Systems Engineering, INCOSE 2009},
  keywords                = {Enterprise Architecture; Interdependent systems; Interoperability requirements; Reference architecture; Science and technology agencies; Singapore Armed Force; Systems of systems; Technology advancement, Architecture; Information technology; Systems engineering, Interoperability},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878160482&partnerID=40&md5=1cc64713a5a28d48394160cf6cc4a9dd},
}

@Article{Jovel200945,
  author                  = {Jovel, J. and Jain, R.},
  title                   = {Impact of identified causal factors to "system of systems" integration complexity from a defense industry perspective},
  journal                 = {Global Journal of Flexible Systems Management},
  year                    = {2009},
  volume                  = {10},
  number                  = {4},
  pages                   = {45-54},
  issn                    = {09722696},
  note                    = {cited By 6},
  abbrev_source_title     = {Global J. Flexible Syst. Manage.},
  abstract                = {Multi-mission projects such as Missile Defense Agency's (MDA) Ballistic Missile Defense (BMD) program involve systems with unique capabilities developed by different companies to communicate together. While system integration for an independent system is a challenge in itself, integration for system of systems is a huge complex effort in part due to interoperability challenges. The focus of this paper is research, analyze, and prioritize some of the causal factors of system integration complexity, such as interoperability, for complex systems such as BMD. Complex system integration is used interchangeably with system of systems integration in this paper because currently in the defense industry, system of systems integration is the new complex system integration. From the defense industry perspective, an attempt is made to contribute in developing a cause and effect relationship model between system requirements, system architecture (specifically open system architecture), and system of systems integration process complexity. © 2009, Global Institute of Flexible Systems Management.},
  affiliation             = {Stevens Institute of Technology, United States},
  author_keywords         = {Complexity; System of systems; Systems architecture; Systems engineering; Systems integration},
  correspondence_address1 = {Jovel, J.; Stevens Institute of TechnologyUnited States; email: jjovel@stevens.edu},
  document_type           = {Article},
  doi                     = {10.1007/BF03396571},
  language                = {English},
  publisher               = {Global Institute of Flexible Systems Management},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955675853&doi=10.1007%2fBF03396571&partnerID=40&md5=3c017ca8cefd7f7d702d55b22ffc4bcf},
}

@Conference{Santiago200868,
  author                  = {Santiago, R. and Wang, G. and Chen, H. and Wang, C.},
  title                   = {Interoperability of end to end Quality of Service (QoS) management across heterogeneous platforms in system of systems},
  year                    = {2008},
  pages                   = {68-75},
  note                    = {cited By 0},
  abbrev_source_title     = {Proc IEE Int. Enterprise Distrib. Obj. Comput. Workshop EDOC},
  abstract                = {Interconnectivity, interoperability, evolution and emergent behavior are some of the key characteristics of System of Systems (SOS). Providing end to end Quality of Service (QoS) for an SOS is a major challenge today because of issues with connectivity, the independent evolution of component systems and their heterogeneity. Heterogeneity of systems is common because of the independent evolution paths and development cycles of the systems. In this paper, we describe an interoperable end to end QoS management solution including concepts, architecture, prototype, and experimental results. Our solution not only provides QoS at systems level, but also ensuring end-to-end QoS across heterogeneous systems at the SOS level. To validate our solution, we analyzed and compared architecture alternatives and developed prototype and experiments employing multiple and varied data dissemination technologies.},
  affiliation             = {Boeing Phantom Works, Seattle, WA 98124, United States},
  art_number              = {4815001},
  correspondence_address1 = {Santiago, R.; Boeing Phantom Works, Seattle, WA 98124, United States; email: rodolfo.a.santiago@boeing.com},
  document_type           = {Conference Paper},
  doi                     = {10.1109/EDOCW.2008.39},
  issn                    = {15417719},
  journal                 = {Proceedings - IEEE International Enterprise Distributed Object Computing Workshop, EDOC},
  keywords                = {Component systems; Data dissemination; Development cycle; Emergent behaviors; End-to-end QoS; End-to-end quality of service; Heterogeneous platforms; Heterogeneous systems; Interconnectivity; Key characteristics; System of systems; Systems levels, Computer science; Graph theory; Interoperability; Quality control; Technical presentations, Quality of service},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349326667&doi=10.1109%2fEDOCW.2008.39&partnerID=40&md5=f67e8dd16161398f3afcd7ca74efa562},
}

@Conference{Parisi2008,
  author                  = {Parisi, C. and Sahin, F. and Jamshidi, M.},
  title                   = {A discrete event XML based system of systems simulation for robust threat detection and integration},
  year                    = {2008},
  note                    = {cited By 16},
  abbrev_source_title     = {IEEE Int. Conf. Syst. Syst. Eng., SoSE},
  abstract                = {In a System of systems (SoS) consisting of heterogeneous independently operable systems, effective communication among the systems is essential. These independent systems need to understand each other through effective communication in or order for them to establish a SoS. Thus, there is a need for a common language which wraps the data that is sent and received from a system within a SoS. This paper presents and extends the application of Extensible Markup Language (XML) to represent data communicated among systems without underlying differences in hardware/software of the individual systems. Moreover, since the operation of each system is asynchronous in nature, the entire SoS can be considered as an event driven system. This paper extends an XML based SoS simulation framework to simulate a robust threat detection and integration problem. The DEVSJAVA software is used as the discrete event simulator. Finally, XML based encapsulation is created in the DEVSJAVA environment to create the common language for the heterogeneous systems in a SoS. © 2008 IEEE.},
  affiliation             = {EE Department Rochester, Institute of Technology, Rochester, NY, United States; ECE Department, University of Texas San Antonio, San Antonio, TX, United States},
  art_number              = {4724187},
  author_keywords         = {Discrete event simulation; Robust threat detection; System of systems simulation; XML},
  correspondence_address1 = {Parisi, C.; EE Department Rochester, Institute of Technology, Rochester, NY, United States; email: cvp5715@rit.edu},
  document_type           = {Article},
  doi                     = {10.1109/SYSOSE.2008.4724187},
  isbn                    = {9781424421732},
  journal                 = {2008 IEEE International Conference on System of Systems Engineering, SoSE 2008},
  keywords                = {Computer software; Discrete event simulation; Hypertext systems; Linguistics; Query languages; Systems engineering; XML, Common languages; Discrete events; Discrete-event simulators; Effective communications; Event-driven systems; Extensible markup languages; Hardware/software; Heterogeneous systems; Independent systems; Individual systems; Integration problems; Robust threat detection; Simulation frameworks; System of systems simulation, Markup languages},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-61449106690&doi=10.1109%2fSYSOSE.2008.4724187&partnerID=40&md5=990f7289df6e1f81afa2e5f52f5a600a},
}

@Conference{Kewley20081121,
  author                  = {Kewley, R. and Cook, J. and Goerger, N. and Henderson, D. and Teague, E.},
  title                   = {Federated simulations for systems of systems integration},
  year                    = {2008},
  pages                   = {1121-1129},
  note                    = {cited By 11},
  abbrev_source_title     = {Proc. Winter Simul. Conf.},
  abstract                = {Systems of systems integration is a difficult engineering challenge that places a particular burden on the engineers who must develop simulation models to support that integration. Developing a large scale stand-alone model to support systems integration is a time-consuming process that is often not possible. An alternative approach is to leverage existing models in a federation. This type of work requires a specialized set of engineering skills. The United States Military Academy Department of Systems Engineering SysHub research program is better defining these skills and applying them to different problem domains. This paper highlights how capabilities for information exchange, environmental representation, entity representation, model development, and data collection support the federation development process.© 2008 IEEE.},
  affiliation             = {Department of Systems Engineering, United States Military Academy, West Point, NY 10996, United States},
  art_number              = {4736181},
  coden                   = {WSCPD},
  correspondence_address1 = {Kewley, R.; Department of Systems Engineering, United States Military Academy, West Point, NY 10996, United States; email: Robert.Kewley@usma.edu},
  document_type           = {Conference Paper},
  doi                     = {10.1109/WSC.2008.4736181},
  isbn                    = {9781424427086},
  issn                    = {08917736},
  journal                 = {Proceedings - Winter Simulation Conference},
  keywords                = {Alternative approaches; Data collections; Engineering challenges; Engineering skills; Federated simulations; Federation development; Information exchanges; Model development; Problem domains; Research programs; Simulation models; Stand -alone; Support systems; Systems of systems; Time-consuming process; United states military academies, Engineering research; Systems engineering, Models},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-60749123368&doi=10.1109%2fWSC.2008.4736181&partnerID=40&md5=91807346bb588f663f113a14eb76c7fd},
}

@Conference{González200841,
  author                  = {González, A. and Piel, É. and Gross, H.-G.},
  title                   = {Architecture support for runtime integration and verification of component-based systems of systems},
  year                    = {2008},
  pages                   = {41-48},
  note                    = {cited By 18},
  abbrev_source_title     = {Aramis - Int. Workshop Autom. Eng. Auton. runtiMe Evol. Syst. conjunction ASE IEEE/ACM Int. Conf. Autom. Softw. Eng.},
  abstract                = {Systems-of-Systems (SoS) represent a novel kind of system, for which runtime evolution is a key requirement, as components join and leave during runtime. Current component integration and verification techniques are not enough in such a dynamic environment. In this paper we present ATLAS, an architectural framework that enables the runtime integration and verification of a system, based on the built-in test paradigm. ATLAS augments components with two specific interfaces to add and remove tests, and to provide adequate testability features to run these tests. To illustrate our approach, we present a case study of a dynamic reconfiguration scenario of components, in the Maritime Safety and Security domain, using our implementation of ATLAS for the Fractal component model. We demonstrate that built-in testing can be extended beyond development-time component integration testing, to support runtime reconfiguration and verification of component-based systems.},
  affiliation             = {Delft University of Technology, Software Engineering Research Group, Mekelweg 4, 2628 CD Delft, Netherlands},
  art_number              = {4686292},
  correspondence_address1 = {González, A.; Delft University of Technology, Software Engineering Research Group, Mekelweg 4, 2628 CD Delft, Netherlands; email: a.gonzalezsanchez@tudelft.nl},
  document_type           = {Conference Paper},
  doi                     = {10.1109/ASEW.2008.4686292},
  isbn                    = {9781424427765},
  journal                 = {Aramis 2008 - 1st International Workshop on Automated engineeRing of Autonomous and runtiMe evolvIng Systems, and ASE2008 the 23rd IEEE/ACM Int. Conf. Automated Software Engineering},
  keywords                = {Automation; Dynamic models; Software engineering; Technical presentations; Testing, And verifications; Architectural frameworks; Built-in tests; Case studies; Component models; Current components; Dynamic environments; Dynamic reconfigurations; Run-time reconfigurations; Runtime evolutions; Security domains; Specific interfaces; Systems of systems; Time components, Integration},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-58049142604&doi=10.1109%2fASEW.2008.4686292&partnerID=40&md5=e0fed5c7365f0a07ebdf6fe4aad87c4c},
}

@Article{Anderson200818,
  author                  = {Anderson, W.B. and Boxer, P.},
  title                   = {Modeling and analysis of interoperability risk in systems of systems environments},
  journal                 = {CrossTalk},
  year                    = {2008},
  volume                  = {21},
  number                  = {11},
  pages                   = {18-22},
  note                    = {cited By 5},
  abbrev_source_title     = {CrossTalk},
  abstract                = {This article describes the use of a set of modeling and analysis techniques in an interoperability risk probe that found gaps in the ability of a North Atlantic Treaty Organization (NATO) modernization program to react to changing demands. The modeling and analysis techniques were used to create models of the people, processes, and technologies of the program and to represent the way demands were placed on this complex socio-technical system. Analysis of the models revealed interoperability risks that were manifested in the linkages between operational requirements of functional capabilities and the way in which those capabilities were being maintained. The risks identified in this probe were typed as mission, composition, and performance risks. The structural models produced by the techniques bring a welcome engineering rigor to the process of examining interoperability.},
  affiliation             = {Software Engineering Institute; SEI, Carnegie Mellon University, 4500 Fifth AVE, Pittsburgh, PA 15213-3890, United States},
  correspondence_address1 = {Anderson, W. B.; Software Engineering InstituteUnited States; email: wba@sei.cmu.edu},
  document_type           = {Article},
  keywords                = {Functional capabilities; Modeling and analysis; Modernization programs; North Atlantic Treaty organizations; Operational requirements; Performance risks; Structural models; Systems of systems; Technical systems, Interoperability; Model structures; Models; Modernization, Risk analysis},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-55349145249&partnerID=40&md5=0a27175c5cf5ab14d5c5c300a718f919},
}

@Article{Colombi200810,
  author                  = {Colombi, J. and Cohee, B.C. and Turner, C.W.},
  title                   = {Interoperability test and evaluation: A system of systems field study},
  journal                 = {CrossTalk},
  year                    = {2008},
  volume                  = {21},
  number                  = {11},
  pages                   = {10-14},
  note                    = {cited By 5},
  abbrev_source_title     = {CrossTalk},
  abstract                = {Effective operational test and evaluation (OT&E) is an essential part of successful systems and software engineering. But increased program dependencies, network-centric operations, and growing interoperability requirements have greatly complicated test and evaluation. This article examines the policy, process, and practice of the Air force (AF) test and evaluation programs, such as Force Development Evaluations (FDEs), particularly during the sustainment of systems. Several observations are made regarding the current process and five areas are emphasized for improvement.},
  affiliation             = {Air Force Institute of Technology; Dept. of Systems and Engineering Management, AFIT/ENV, Wright-Patterson AFB, OH 45433, United States; 315Th Training Squadron, 154 Canberra ST, Goodfellow AFB, TX 76908-4002, United States; HQ CENTCOM/CCJ6-CO, 7115 S Boundary BLVD, MacDill AFB, FL 33621-5101, United States},
  correspondence_address1 = {Colombi, J.; Air Force Institute of Technologyemail: john.colombi@afit.edu},
  document_type           = {Article},
  keywords                = {Air forces; Current processes; Field studies; Interoperability tests; Operational test and evaluations; System of systems; Systems and softwares; Test and evaluations, Interoperability; Software engineering, Testing},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-55349133814&partnerID=40&md5=119f564f156575ff6aa551c78e6394db},
}

@Article{Durbha2008358,
  author                  = {Durbha, S.S. and King, R.L. and Younan, N.H.},
  title                   = {An information semantics approach for knowledge management and interoperability for the global earth observation system of systems},
  journal                 = {IEEE Systems Journal},
  year                    = {2008},
  volume                  = {2},
  number                  = {3},
  pages                   = {358-365},
  issn                    = {19328184},
  note                    = {cited By 14},
  abbrev_source_title     = {IEEE Syst. J.},
  abstract                = {The Global Earth Observation System of Systems (GEOSS) is built on current international cooperation efforts among existing distributed earth observing and processing systems. The goal is to formulate an end-to-end process that enables the collection and distribution of accurate, reliable earth observation (EO) data, information, products, and services to both suppliers and consumers worldwide. EOs are obtained from a multitude of sources and require tremendous efforts and coordination among different governments and user groups to come to a shared understanding on a set of concepts involved in a domain. Semantic metadata play a crucial role in resolving the differences in meaning, interpretation, and usage of the same or related data. Also, the knowledge about the geopolitical background of the originating datasets could be encoded in the metadata that would address the diversity on a global scale. In distributed environments like GEOSS, modularization is inevitable. In this paper, we describe the need for an information semantics-based approach for knowledge management and interoperability between heterogeneous GEOSS systems. Further, considering the magnitude of concepts involved in GEOSS, we explore the possibility of using modular ontologies for formulating smaller interconnected ontologies. © 2008 IEEE.},
  affiliation             = {Department of Electrical and Computer Engineering, GeoResources Institute, Mississippi State University, Starkville, MS 39762, United States; Bagley College of Engineering, Mississippi State University, Starkville, MS 39762, United States; Department of Electrical and Computer Engineering, Mississippi State University, Starkville, MS 39762, United States},
  author_keywords         = {Global Earth Observation System of Systems (GEOSS); Modularization; Ontology; Semantics},
  correspondence_address1 = {Durbha, S.S.; Department of Electrical and Computer Engineering, GeoResources Institute, Mississippi State University, Starkville, MS 39762, United States; email: suryad@gri.msstate.edu},
  document_type           = {Article},
  doi                     = {10.1109/JSYST.2008.925975},
  keywords                = {Administrative data processing; Data storage equipment; Information theory; International cooperation; Interoperability; Knowledge management; Management information systems; Metadata; Modular construction; Observatories; Ontology; Semantics, Data-sets; Distributed environments; Earth observation data; Earth observing; Global Earth Observation System of Systems; Global Earth Observation System of Systems (GEOSS); Global scaling; Information semantics; Modularization; ON currents; Processing systems; Semantic metadata; Shared understanding; User groups, Information management},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-54849161400&doi=10.1109%2fJSYST.2008.925975&partnerID=40&md5=bc6cc3b9c98412cf736f2aaa4161fa20},
}

@Conference{McCracken2007867,
  author                  = {McCracken, J.R. and Eggleston, R.G.},
  title                   = {AXIOM: A concept space approach suitable for achieving meaning composability levels of system of system interoperability},
  year                    = {2007},
  volume                  = {2},
  pages                   = {867-883},
  note                    = {cited By 0},
  abbrev_source_title     = {Fall Simul. Interoperability Workshop},
  abstract                = {We present a computational approach for achieving meaning composition up to level 6 of the Levels of Conceptual Interoperability Model. Our approach, known as AXIOM, extends the idea of modeling concepts as concept spaces advanced by Gardenfors and combines it with a structured use of concept maps and mereological operators to create a meaning composability process. This process transforms basic concept meaning, into contextualized situated meaning, and finally into actionable meaning relative to an agent's problem focus. We describe the meaning composability process of AXIOM and address how it achieves level 6 of the LCIM.},
  affiliation             = {Design Knowledge Company, 2661 Commons Blvd., Dayton, OH 45431-3704, United States; USAFRL/HEC, Bldg. 190, WPAFB, OH 45433, United States},
  author_keywords         = {Composability; Conceptual spaces; Human modeling; Modeling and simulation},
  correspondence_address1 = {McCracken, J.R.; Design Knowledge Company, 2661 Commons Blvd., Dayton, OH 45431-3704, United States; email: jim@tdkc.com},
  document_type           = {Conference Paper},
  isbn                    = {9781622761449},
  journal                 = {Fall Simulation Interoperability Workshop 2007},
  keywords                = {Basic concepts; Composability; Computational approach; Concept maps; Concept space; Conceptual spaces; Human modeling; Modeling and simulation; Modeling concepts; System of systems, Computer simulation; Geometry, Interoperability},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867756561&partnerID=40&md5=85ef1c24af3bf3ebbc3056f949886097},
}

@Conference{Meilich2007,
  author                  = {Meilich, A.},
  title                   = {Human systems integration - A system of systems engineering challenge},
  year                    = {2007},
  note                    = {cited By 3},
  abbrev_source_title     = {IEEE Int. Conf. Syst. Syst. Eng., SOSE},
  abstract                = {The relationships of systems to humans in the loop and the effectiveness of humans to carry out a mission in that context continue to be problematic. In the system-of-systems (SoS) context, the human is the key enabler in using SoS as opposed to the stove-piped systems of the past. Single purpose systems were performance-optimized and tightly integrated to focus on single capability or mission-specific goals, rather than agility that can accommodate changing human needs as they are challenged by new and asymmetric threats. The SoS engineering discipline must consider a broader set of skills in order to tackle the human-in-the-loop as a prime design variable. The focus will be on Human System Integration at the Cognitive and Social level of interaction within and among systems. This presentation will present some observations on where we are and where we may have to go in order to tackle these multidimensional problems using enterprise engineering as an extension of system engineering. ©2007 IEEE.},
  affiliation             = {Advanced Concepts - NetCentric Integration, Lockheed Martin Advanced Concepts, 10530 Rosehaven Street, Fairfax, VA 22020, United States},
  art_number              = {4304216},
  author_keywords         = {Cognitive domain; Human systems integration; Social domain; System of systems; Systems engineering},
  correspondence_address1 = {Meilich, A.; Advanced Concepts - NetCentric Integration, Lockheed Martin Advanced Concepts, 10530 Rosehaven Street, Fairfax, VA 22020, United States; email: abraham.w.meilichg@lmco.com},
  document_type           = {Conference Paper},
  doi                     = {10.1109/SYSOSE.2007.4304216},
  isbn                    = {1424411602; 9781424411603},
  journal                 = {2007 IEEE International Conference on System of Systems Engineering, SOSE},
  keywords                = {Engineering; Industrial engineering; Systems engineering, Engineering disciplines; Enterprise engineering; Human needs; Human system integration; Human systems integration (HSI); Human-in-the-loop (HITL); International conferences; Multi dimensional problems; System of systems (SOS); System-of-systems engineering, Cognitive systems},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-47349088845&doi=10.1109%2fSYSOSE.2007.4304216&partnerID=40&md5=bb73b5dee5556ca4ce9dedd91bff93aa},
}

@Conference{Sahin20071376,
  author                  = {Sahin, F. and Sridhar, P. and Horan, B. and Raghavan, V. and Jamshidi, M.},
  title                   = {System of systems approach to threat detection and integration of heterogeneous independently operable systems},
  year                    = {2007},
  pages                   = {1376-1381},
  note                    = {cited By 23},
  abbrev_source_title     = {Conf. Proc. IEEE Int. Conf. Syst. Man Cybern.},
  abstract                = {This paper presents a system of systems approach to threat detection through integration of heterogeneous independently operable systems. The approach is presented on a realistic situation where a human-controlled base robot, swarm robot(s), and sensors work together to obtain a decision about a possible threat in the environment. The base robot is remotely operated by a human using a haptic control system. The swarm robot(s) are autonomous and can accept directives from the base robot. Finally, sensors directly communicate with (report to) the base robot. In this scenario, heterogeneous systems and human interact in a system of systems architecture. With the inclusion of human expert and sensor verification of swarm robots, the system can successfully perform the threat detection and reduce the false alarms. Finally, a system of systems simulation framework including a base robot, a swarm robot, and two sensors is presented in addition to an experimental evaluation of the proposed SoS architecture. © 2007 IEEE.},
  affiliation             = {IEEE; Rochester Institute of Technology, Rochester, NY 14623, United States; Department of Electrical and Computer Engineering, University of Texas San Antonio, San Antonio, TX 78249, United States; University of Texas San Antonio, San Antonio, TX 78249, United States; Intelligent Systems Research Lab., Deakin University, Geelong, VIC 3217, Australia},
  art_number              = {4414157},
  coden                   = {PICYE},
  correspondence_address1 = {Sahin, F.; Department of Electrical and Computer Engineering, University of Texas San Antonio, San Antonio, TX 78249, United States; email: ferat.sahin@utsa.edu},
  document_type           = {Conference Paper},
  doi                     = {10.1109/ICSMC.2007.4414157},
  isbn                    = {1424409918; 9781424409914},
  issn                    = {1062922X},
  journal                 = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
  keywords                = {Swarm robots; Threat detection, Control systems; Integration; Intelligent robots; Verification, Intrusion detection},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-40949084338&doi=10.1109%2fICSMC.2007.4414157&partnerID=40&md5=65b3199378db834c0f8d1a8ab5fa34a3},
}

@Conference{West2007141,
  author                  = {West, P.J.},
  title                   = {Systems-of-systems integration using a net-centric organization},
  year                    = {2007},
  pages                   = {141-145},
  note                    = {cited By 1},
  abbrev_source_title     = {Proc. Annu. IEEE Syst. Conf.},
  abstract                = {This paper presents a real-world, industry perspective of the challenges associated with operating a global Live, Virtual, Constructive (LVC) environment. The LVC environment comprises an expanding network of on-demand MSA&amp;E1 capabilities which allows customers to experience the interactions of System-of-Systems (SoS) architectures and behaviors at a level not possible elsewhere. Robust Systems-of-Systems integration is a core competency for world-class LVC operations. The net-centric organizational model discussed here has shown resilience and high performance under stressing conditions. © 2007 IEEE.},
  affiliation             = {Boeing Company, 1215 S Clark St, Arlington, VA 22202},
  art_number              = {4258869},
  correspondence_address1 = {West, P.J.; Boeing Company, 1215 S Clark St, Arlington, VA 22202; email: phillip.j.west@Boeing.com},
  document_type           = {Conference Paper},
  doi                     = {10.1109/SYSTEMS.2007.374664},
  isbn                    = {142441041X; 9781424410415},
  journal                 = {Proceedings of the 1st Annual 2007 IEEE Systems Conference},
  keywords                = {Mathematical models; Robust control; Societies and institutions; Virtual reality, Live, Virtual, Constructive (LVC) environment; Resilience; Stressing conditions; System-of-Systems (SoS), Systems analysis},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34748910082&doi=10.1109%2fSYSTEMS.2007.374664&partnerID=40&md5=a447504db2a6e576c210fad3e796a256},
}

@Conference{SmithII20077130,
  author                  = {Smith II, J.D. and Meyers, B.C.},
  title                   = {Interoperability patterns and systems of systems acquisition},
  year                    = {2007},
  volume                  = {10},
  pages                   = {7130-7135},
  note                    = {cited By 0},
  abbrev_source_title     = {Collect. Tech. Pap. Aeros. Sci. Meet.},
  abstract                = {This paper explores some of the reasons that the acquisition of systems of systems is fundamentally different from that of individual systems, leading to brief overview of interoperable acquisition. Against this backdrop, the authors introduce the concept of interoperability patterns and antipatterns, and show how they can contribute to an understanding of the complex interrelationships between the various programs and systems that exist within a system of systems context.},
  affiliation             = {Carnegie Mellon Software Engineering Institute, Arlington, VA 22203, United States; Carnegie Mellon Software Engineering Institute, Pittsburgh, PA 15213, United States; Technical Staff, Dynamic Systems Program, NRECA Building, 4301 Wilson Boulevard, Arlington, VA 22203, Austria; Technical Staff, Dynamic Systems Program, Integration of Software-Intensive Systems Initiative, 4500 Fifth Avenue, Pittsburgh, PA 15213-3890, Austria},
  correspondence_address1 = {Smith II, J.D.; Carnegie Mellon Software Engineering Institute, Arlington, VA 22203, United States},
  document_type           = {Conference Paper},
  isbn                    = {1563478900; 9781563478901},
  journal                 = {Collection of Technical Papers - 45th AIAA Aerospace Sciences Meeting},
  keywords                = {Interoperability patterns; Interoperable acquisition; Systems acquisition, Interoperability; Network protocols; Wireless telecommunication systems, Systems analysis},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34250896796&partnerID=40&md5=c6c717094978c9ee15eeb2c210939179},
}

@Conference{DiMario2006236,
  author                  = {DiMario, M.J.},
  title                   = {System of systems interoperability types and characteristics in joint command and control},
  year                    = {2006},
  volume                  = {2006},
  pages                   = {236-241},
  note                    = {cited By 32},
  abbrev_source_title     = {Proc. IEEE/SMC Int. Conf. Syst. Eng.},
  abstract                = {The United States Department of Defense and their Joint Vision 2010 and 2020 articulates the necessity for multinational and interagency cooperation and interdependent command and control for a full range of capabilities. Joint Vision relies on system of systems to bridge participant systems with interoperability as a key enabler. To achieve this key enabler, this paper discusses the need for interoperability implementation at the programmatic, constructive, and operational levels. The system of systems interoperability must take into account its unbounded characteristics and engineer constituent systems for syntactic and semantic interoperability and to be system of systems enabled for an omnipresent environment. This paper demonstrates why systems must be managed and engineered as system of systems centric versus systems centric. System Readiness Levels and Integration Readiness Levels are suggested to mange the constituent systems within a system of systems. © 2006 IEEE.},
  affiliation             = {Department of Systems Engineering and Engineering Management, Stevens Institute of Technology, Hoboken, NJ, United States},
  art_number              = {1652302},
  author_keywords         = {Bounded; Command and control; Convergence; Integration readiness level; Interoperability; Joint vision; Semantic; SoS enabled; Syntactic; System of systems; System readiness level; Technology readiness level; Unbounded},
  correspondence_address1 = {DiMario, M.J.; Department of Systems Engineering and Engineering Management, Stevens Institute of Technology, Hoboken, NJ, United States; email: dimario@patmedia.net},
  document_type           = {Conference Paper},
  isbn                    = {1424401887; 9781424401888},
  journal                 = {Proceedings 2006 IEEE/SMC International Conference on System of Systems Engineering},
  keywords                = {Command and control systems; Semantics; Syntactics; Systems engineering, Integration readiness levels; Joint visions; System readiness levels; Technology readiness levels, Interoperability},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845930610&partnerID=40&md5=2681c5ae47f02acde8b8eeaeaa98b544},
}

@Conference{Wolfson2006583,
  author                  = {Wolfson, S. and Norman, R. and Bolin, J. and Sells, J. and Troupe, A.},
  title                   = {Testing the test: Distributed testing in support of system of systems integration},
  year                    = {2006},
  pages                   = {583-593},
  note                    = {cited By 0},
  abbrev_source_title     = {Simul. Interoperability Stand. Organ. - Spring Simul. Interoperability Workshop, Spring SIW},
  abstract                = {Over the years, Redstone Technical Test Center (RTTC) has developed a mature but constantly evolving distributed M&S capability in support of systems testing. However, new programs, such as Future Combat Systems (FCS) and its Experiment 1.1, have required RTTC to expand beyond support of systems testing and into support of system of systems testing in distributed environments either locally or distant in nature. System of systems testing requires organizations with different areas of expertise to come together to formulate a common test infrastructure. The Test and Training Enabling Architecture (TENA) was chosen to facilitate data sharing across the test network infrastructure. This paper describes how the use of the TENA Middleware and TENA standards can make a test infrastructure "plug and play" compatible with other components while greatly reducing the time needed to integrate test components. In order to assess the ability to perform system of systems testing, RTTC deployed several key components in support of the horizontal integration of the test infrastructure. Range-in-a-Box was used to collect and send data onto the test network infrastructure. The RTTC Camera Control was used to provide live video of any instrumented or tracked experiment participant. The SIMDIS Visualization Tool was used to provide real-time situational awareness of the entire experiment, including sensor data and tactical position information. Finally, the Reflect Suite was used to log all TENA data on the test network and 583 playback test runs as-needed. This TENA-enabled integrated test network infrastructure allowed for full situational awareness and real-time remote instrumentation command and control from any point on the test network, including from over 2,000 miles away. In addition to system of systems testing, RTTC has started to investigate the benefits of being more actively engaged in the Integration Phase of the system acquisition process. This will enable RTTC to help system developers troubleshoot and solve integration issues with their systems at a very early stage before the systems enter evaluation.},
  affiliation             = {U.S. Army Redstone Technical Test Center, Information Management Branch, Huntsville, AL, United States; CSTE-DTC-RT-F-FL, Bldg. 7884, Redstone Arsenal, AL, United States; ERC Incorporated, U.S. Army Redstone Technical Test Center (RTTC), Information Management Branch, Huntsville, AL, United States},
  author_keywords         = {FCS experiment 1.1; RIAB; RTTC camera control; SIMDIS; TENA},
  correspondence_address1 = {Wolfson, S.; U.S. Army Redstone Technical Test Center, Information Management Branch, Huntsville, AL, United States; email: scott.wolfson@us.army.mil},
  document_type           = {Conference Paper},
  isbn                    = {9781604239232},
  journal                 = {Simulation Interoperability Standards Organization - Spring Simulation Interoperability Workshop 2007, 07 Spring SIW},
  keywords                = {Camera controls; FCS experiment 1.1; RIAB; SIMDIS; TENA, Cameras; Data visualization; Experiments; Integration; Interoperability; Microwave circuits; Middleware; Systems engineering; Visualization, Ability testing},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865633388&partnerID=40&md5=0927943affe3e774f6e0594640e0bbe2},
}

@Conference{Mitchell200667,
  author                  = {Mitchell, D.K. and Samms, C. and Wojcik, T.M.},
  title                   = {System-of-systems modeling: The evolution of an approach for true human system integration},
  year                    = {2006},
  pages                   = {67-74},
  note                    = {cited By 1},
  abbrev_source_title     = {Simul. Interoperability Stand. Organ. - Conf. Behav. Represent. Model. Simul.},
  abstract                = {For many years, analysts have recognized the need to accurately represent the human in system simulations because the human is the most variable portion of the system representation (Allender, 2000). It is especially critical, but challenging to represent the multi-tasking capability of humans that has been a limitation in accurate representation of system performance (Deutsch, 1997). Within the military analytical community multitasking human performance representation, particularly as it relates to crew size has become a critical issue in military vehicle design. Motivated by the needs of organizations such as the Army Materiel Systems Analysis Activity (AMSAA), the Future Combat System Lead System Integrator Boeing-SAIC, and the recognition that traditional military simulations such as CASTFOREM and JANUS have limited capability to accurately represent multi-tasking human behavior (Henthorn, Mitchell, & McDowell, 2005), the U.S. Army Research Laboratory decided to take the initiative to improve the credible representation of human behavior in military system performance simulations. This approach has culminated in a system-of-systems modeling approach that can also be applied in the commercial marketplace. This paper describes the evolution of the ARL system-of-systems modeling approach and the development of the capabilities within the Improved Performance Research Integration Tool (IMPRINT) tool that enable it to be used to build system-of-systems models.},
  affiliation             = {U.S. Army Research Laboratory, Human Research and Engineering Directorate, Aberdeen Proving Ground, MD 21005, United States; Micro Analysis and Design, 4949 Pearl East Circle, Boulder, CO 80301, United States},
  author_keywords         = {Function allocation; IMPRINT; Multitask environment; System-of-systems; Workload},
  correspondence_address1 = {Mitchell, D.K.; U.S. Army Research Laboratory, Human Research and Engineering Directorate, Aberdeen Proving Ground, MD 21005, United States; email: diane@arl.army.mil},
  document_type           = {Conference Paper},
  isbn                    = {9781604238969},
  journal                 = {Simulation Interoperability Standards Organization - 15th Conference on Behavior Representation in Modeling and Simulation 2006},
  keywords                = {Commercial marketplace; Crew size; Critical issues; Future Combat Systems; Human behaviors; Human performance; Human system integration; IMPRINT; Integration tools; Lead system integrators; Military simulation; Military systems; Modeling approach; Multitask environment; Performance research; Performance simulation; System representation; System simulations; System-of-systems; U.S. Army; Workload, Computer simulation; Social sciences; Systems analysis, Multitasking},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865323306&partnerID=40&md5=6519de6bce7778b694b3fad94c2a0f25},
}

@Conference{Carr2006123,
  author                  = {Carr, R.G. and Eyre, R.H.},
  title                   = {Maximising coherence in the integration of systems-of-systems},
  year                    = {2006},
  volume                  = {2006},
  number                  = {11589},
  pages                   = {123-129},
  note                    = {cited By 0},
  abbrev_source_title     = {IET Semin Dig},
  abstract                = {Coherence in systems-of-systems can be achieved by specifying the desired capability and measuring progress across all Defence Lines of Development. By implementing and extending Capability Requirements Documents a rigorous approach to capability specification and validation can be achieved. This is complemented by a robust approach to measuring and developing system maturity ensuring that due rigor is applied to the structure and content of user and systems requirements, the desired readiness is attained, implicit requirements are captured and that appropriate system-of-system verification and validation is completed. By development and use of bespoke tools, this approach can deliver added value in the tangible form of financial savings, a higher quality of input from stakeholders, improved management processes and visibility and an increase in corporate knowledge. © The IET.},
  affiliation             = {Sula Systems Ltd., Old Crown House, Wotton-under-Edge, Glos, GL12 7AE, United Kingdom},
  author_keywords         = {Capability readiness integration coherence},
  correspondence_address1 = {Carr, R.G.; Sula Systems Ltd., Old Crown House, Wotton-under-Edge, Glos, GL12 7AE, United Kingdom},
  document_type           = {Conference Paper},
  doi                     = {10.1049/ic:20060288},
  isbn                    = {0863416985; 9780863416989},
  journal                 = {IET Seminar Digest},
  keywords                = {Cost effectiveness; Identification (control systems); Industrial management; Robustness (control systems), Capability readiness integration coherence; Financial savings, Systems analysis},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34250620574&doi=10.1049%2fic%3a20060288&partnerID=40&md5=4c40e1dbd7717ea429d9c6cc4b15388b},
}

@Conference{Krueger200651,
  author                  = {Krueger, I.H. and Meisinger, M. and Menarini, M. and Pasco, S.},
  title                   = {Rapid systems of systems integration - Combining an architecture-centric approach with enterprise service bus infrastructure},
  year                    = {2006},
  pages                   = {51-56},
  note                    = {cited By 13},
  abbrev_source_title     = {Proc. IEEE Int. Conf. Info. Reuse Integr.},
  abstract                = {Rapid, yet methodical, systems of systems integration is in high demand Application areas such as homeland security and disaster response add to the challenge because of a unique set of integration requirements; three examples are: (1) a high demand for flexibility with respect to the configuration and support of business processes to anticipate and cater to changing threat and mitigation scenarios, (2) high agility demands during both development and production to address legacy and emergent capabilities, processes, applications and technologies, (3) wide variety of trust relationships among and across stakeholders and their organizations. In this paper we report on an approach for balancing challenging integration requirements while rapidly delivering a high-quality, value added, integrated system architecture and service-based implementation infrastructure. In particular, we show how the choice of an Enterprise Service Bus as a deployment infrastructure helps discharge many of the obligations induced by the mentioned requirements - if it is combined with an agile, yet systematic approach for architecture discovery and design. © 2006 IEEE.},
  affiliation             = {University of California, Calit2, San Diego, United States},
  art_number              = {4018464},
  correspondence_address1 = {Krueger, I.H.; University of California, Calit2, San Diego, United States; email: ikrueger@ucsd.edu},
  document_type           = {Conference Paper},
  doi                     = {10.1109/IRI.2006.252387},
  isbn                    = {0780397886; 9780780397880},
  journal                 = {Proceedings of the 2006 IEEE International Conference on Information Reuse and Integration, IRI-2006},
  keywords                = {Business processes; Homeland security; Integrated system architecture; Stakeholders, Disaster prevention; Network architecture; Security systems, Systems analysis},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34250218027&doi=10.1109%2fIRI.2006.252387&partnerID=40&md5=6cd6b53db0e19bec73cbc771be016ecd},
}

@Conference{Battle2005809,
  author                  = {Battle, C.},
  title                   = {Integrated system analysis capability framework for system of systems integration},
  year                    = {2005},
  volume                  = {2},
  pages                   = {809-815},
  note                    = {cited By 0},
  abbrev_source_title     = {Collect. Technic. Papers Space Explor. conf. Continu. Voyage Discov.},
  abstract                = {NASA's pursuit of Space Exploration and in particular Project Constellation will challenge traditional system acquisition approaches by requiring integration of a complex System of Systems (SoS). The intent of this paper is to provide an overview of a proven Integrated System Analysis Capability (ISAC) framework that is an adaptation of an Integrated Ground Test and Simulation (IGT&S) solution. IGT&S provides a comprehensive framework in which individual systems that are interdependent on one another can be integrated to perform whole system integration analysis, testing and evaluation. The ISAC concept is to provide a framework for comprehensive SoS integration in which HWIL/SWIL emulation of the systems of the Space Exploration System are tested and evaluated as one system. The overview will encompass the fundamental approach, and application of SoS Integration in an ISAC framework. Copyright © 2005 by Teledyne Brown Engineering.},
  affiliation             = {Teledyne Brown Engineering, Huntsville, AL 35807, United States},
  correspondence_address1 = {Battle, C.; Teledyne Brown Engineering, Huntsville, AL 35807, United States},
  document_type           = {Conference Paper},
  isbn                    = {1563477270; 9781563477270},
  journal                 = {A Collection of Technical Papers - 1st Space Exploration Conference: Continuing the Voyage of Discovery},
  keywords                = {Integrated System analysis capability; Space exploration systems; System integration analysis; System of Systems (SoS), Computer simulation; Large scale systems; Systems analysis; Testing, Space research},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-28744458965&partnerID=40&md5=58fc64fc3e3e14637e61f3872d8ba77a},
}

@Conference{Sage2005,
  author                  = {Sage, A.P.},
  title                   = {Systems of systems: Architecture based systems design, and integration},
  year                    = {2005},
  volume                  = {4},
  pages                   = {v-vi},
  note                    = {cited By 8},
  abbrev_source_title     = {Conf. Proc. IEEE Int. Conf. Syst. Man Cybern.},
  abstract                = {This keynote speech discusses the engineering of a system of systems. Systems architecting and associated design and integration are highlighted as central issues in engineering a systems of systems. Several conceptual models for systems engineering and management are discussed and the essential need for systems architecting, design, and integration is highlighted. Successful systems engineering must be approached at the levels of technology, humans, and organizations. To accomplish this, it is very important to identify and use an appropriate architectural framework and contemporary work concerning architectural frameworks is discussed. Most contemporary large system issues can not be approached from a monolithic perspective. Rather, we must consider system of systems and federation of systems issues. The essential characteristics of these systems are discussed and it is observed that properties of evolution, emergence and adaptation are inherently associated with systems architecting, design, and integration. These provide daunting challenges for systems engineering and management in the 21st Century.},
  affiliation             = {George Mason University, United States},
  coden                   = {PICYE},
  correspondence_address1 = {Sage, A.P.; George Mason University, Fairfax, VA, United States},
  document_type           = {Conference Paper},
  issn                    = {1062922X},
  journal                 = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
  keywords                = {Software engineering; Systems analysis; Systems engineering; Technology transfer, Architectural framework; Conceptual models; Monolithic; System architecting, Computer architecture},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-27944501659&partnerID=40&md5=4de3288df7a7da352d95e21a73e8dade},
}

@Conference{Ehrmanntraut2003,
  author                  = {Ehrmanntraut, R.},
  title                   = {System-of-systems integration of air-ground telecommunications with the software connector},
  year                    = {2003},
  volume                  = {2},
  pages                   = {6.A.3/1-6.A.3/12},
  note                    = {cited By 2},
  abbrev_source_title     = {AIAA IEEE Dig Avionics Syst Conf Proc},
  abstract                = {Component-based software development has come up with the new paradigm for the interconnection of software components - the Connector. It would be useful to discuss whether this new software technology can be applied for the aeronautical world and which benefits would derive from it. The discussion will be held from the perspective of Air Traffic Management, and herein from the domain of air-ground integration as example. The paper gives an overview of the status of the different historical, current and future air-ground technologies. It formulates the reasons for the approach to integrate the different and co-existing technologies, and explains the integration problem. Further it shows historical effort conducted in the EEC to overcome the shortfalls mainly of ATN (Aeronautical Telecommunications Network) integration, and presents some of the early solutions for improvements. The following sections introduce to the concepts of Connector, and finally the discussion is on the applicability of the Connector concept to the aeronautical world. The discussion will structure the functions of the Connector and produce a layered architectural model for. the air-ground Connector.},
  affiliation             = {EUROCONTROL Experimental Ctr. (EEC), Brétigny sur Orge, France},
  coden                   = {ADACF},
  correspondence_address1 = {Ehrmanntraut, R.; EUROCONTROL Experimental Ctr. (EEC), Brétigny sur Orge, France; email: rudiger.ehrmanntraut@eurocontrol.int},
  document_type           = {Conference Paper},
  journal                 = {AIAA/IEEE Digital Avionics Systems Conference - Proceedings},
  keywords                = {Aerospace applications; Aerospace ground support; Air traffic control; Aviation; Information technology; Radio communication; Software engineering, Air ground integration; Air ground telecommunications; Air traffic management; Software connector, Avionics},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0344982824&partnerID=40&md5=72fd459e74f6516260d42bf3849827ba},
}

@Conference{Kelley1999215,
  author                  = {Kelley, Michael and Pei, Richard},
  title                   = {C4I2WS system of systems integration for the future army},
  year                    = {1999},
  volume                  = {3694},
  pages                   = {215-222},
  publisher               = {Society of Photo-Optical Instrumentation Engineers, Bellingham, WA, United States},
  note                    = {cited By 1},
  abbrev_source_title     = {Proc SPIE Int Soc Opt Eng},
  abstract                = {An account is given on the recent initiatives at the U.S. Army's Communication & Electronics Command (CECOM) Research and Engineering Directrorate (CERDEC) to develop and establish a System of Systems Integration (SOSI) capability, together with the infrastructure and simulation facilities required to conduct collaborative distributed prototyping and evaluation. The new capability will permit the CERDEC's various Directorates in conjunction with other stakeholders in the RDA process to accomplish its mission of developing and integrating C412WS Systems for the XXI Century Army.},
  affiliation             = {U.S. Army Communication-Electronics, Command, United States},
  coden                   = {PSISD},
  correspondence_address1 = {Kelley, Michael; U.S. Army Communication-Electronics, CommandUnited States},
  document_type           = {Conference Paper},
  issn                    = {0277786X},
  journal                 = {Proceedings of SPIE - The International Society for Optical Engineering},
  keywords                = {Command and control systems; Data acquisition; Electronic warfare; Information technology; Military applications; Military communications; Military engineering; Sensors; Systems engineering, Simulation based acquisition; System of systems integration, Computer simulation},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033320690&partnerID=40&md5=30a97ef7c1cdb71f72137f26e4aa178d},
}

@Article{LeFèvre2018101,
  author                  = {Le Fèvre, C. and Poty, L. and Noël, G.},
  title                   = {Big data, generalities and integration in radiotherapy [Les big data, généralités et intégration en radiothérapie]},
  journal                 = {Cancer/Radiotherapie},
  year                    = {2018},
  volume                  = {22},
  number                  = {1},
  pages                   = {101},
  issn                    = {12783218},
  note                    = {cited By 0},
  abbrev_source_title     = {Cancer Radiother.},
  affiliation             = {Département universitaire de radiothérapie, centre Paul-Strauss, Unicancer, 3, rue de la Porte-de-l'Hôpital, Strasbourg cedex, 67065, France; Département informatique, centre Paul-Strauss, Unicancer, 3, rue de la Porte-de-l'Hôpital, Strasbourg cedex, 67065, France; Laboratoire EA 3430, fédération de médecine translationnelle de Strasbourg (FMTS), université de Strasbourg, Strasbourg, 67000, France},
  coden                   = {CARAF},
  correspondence_address1 = {Noël, G.; Laboratoire EA 3430, fédération de médecine translationnelle de Strasbourg (FMTS), université de StrasbourgFrance; email: gnoel@strasbourg.unicancer.fr},
  document_type           = {Note},
  doi                     = {10.1016/j.canrad.2017.11.002},
  language                = {English; French},
  publisher               = {Elsevier Masson SAS},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041375585&doi=10.1016%2fj.canrad.2017.11.002&partnerID=40&md5=c38802cb5b1df271bde6d5ca1da27a51},
}

@Conference{Dong20131245,
  author                  = {Dong, X.L. and Srivastava, D.},
  title                   = {Big data integration},
  year                    = {2013},
  volume                  = {6},
  number                  = {11},
  pages                   = {1245-1248},
  publisher               = {Association for Computing Machinery},
  note                    = {cited By 103},
  abbrev_source_title     = {Proc Int Conf Data Eng},
  abstract                = {The Big Data era is upon us: data is being generated, collected and analyzed at an unprecedented scale, and data-driven decision making is sweeping through all aspects of society. Since the value of data explodes when it can be linked and fused with other data, addressing the big data integration (BDI) challenge is critical to realizing the promise of Big Data. BDI differs from traditional data integration in many dimensions: (i) the number of data sources, even for a single domain, has grown to be in the tens of thousands, (ii) many of the data sources are very dynamic, as a huge amount of newly collected data are continuously made available, (iii) the data sources are extremely heterogeneous in their structure, with considerable variety even for substantially similar entities, and (iv) the data sources are of widely differing qualities, with significant differences in the coverage, accuracy and timeliness of data provided. This seminar explores the progress that has been made by the data integration community on the topics of schema mapping, record linkage and data fusion in addressing these novel challenges faced by big data integration, and identifies a range of open problems for the community. © 2013 IEEE.},
  affiliation             = {AT and T Labs. - Research, Florham Park, NJ, United States},
  art_number              = {6544914},
  correspondence_address1 = {AT and T Labs. - Research, Florham Park, NJ, United States},
  document_type           = {Conference Paper},
  doi                     = {10.1109/ICDE.2013.6544914},
  isbn                    = {9781467349086},
  issn                    = {10844627},
  journal                 = {Proceedings - International Conference on Data Engineering},
  keywords                = {Big datum; Data-sources; Number of datum; Record linkage; Schema mappings; Significant differences; Single domains, Data fusion, Data integration},
  language                = {English},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881350480&doi=10.1109%2fICDE.2013.6544914&partnerID=40&md5=a4d1ce17824b355ea8c6ea1bd3318909},
}

@Conference{DelGreco2008,
  author                  = {Del Greco, S. and Ansari, S.},
  title                   = {Radar visualization and data exporter tools to support interoperability and the Global Earth Observation System of Systems (GEOSS), from the National Oceanographic and Atmospheric Administration's (NOAA's) National Climatic Data Center (NCDC)},
  year                    = {2008},
  volume                  = {316},
  note                    = {cited By 0},
  abbrev_source_title     = {World Environ. Water Resour. Congr.: Ahupua'a - Proc. World Environ. Water Resour. Congr.},
  abstract                = {In February 2005, 61 countries around the World agreed on a 10 year plan to build open systems for sharing geospatial data and services across different platforms worldwide. This system is known as the Global Earth Observation System of Systems (GEOSS). The objective of GEOSS focuses on easy access to environmental data and interoperability across different systems allowing participating countries to measure the "pulse" of the planet in an effort to advance society. In support of GEOSS goals, NOAA's National Climatic Data Center (NCDC) has developed radar visualization and data exporter tools using Open Source software libraries. The NCDC Interactive Radar Viewer and Data Exporter Toolkit load Weather Surveillance Radar 1988 Doppler (WSR-88D) volume scan (S-band) data, known as Level-II, and derived products, known as Level-III, into an OPEN Geographical Information System (GIS) compliant environment. The application is launched via Java Web Start and runs on the client machine while accessing these data remotely from the NCDC archive or in near real time from other NOAA servers. The Radar Interactive Viewer Toolkit provides custom data overlays, animations and basic queries. The export of images and movies is provided in multiple formats that support the "blending" of radar data with other types of data. The Data Exporter allows for data export in both vector polygon (Shapefile, Well-Known Text) and raster (GeoTIFF, ESRI Grid, VTK, NetCDF, GrADS) formats. NCDC recently decoded Sigmet C-band doppler radar data and plans to implement the functionality to read C-Band radar data into the Radar Viewer/Data Exporter Toolkit. This supports a bilateral agreement between the United States and Canada for data sharing and interoperability. In addition, the NCDC is implementing decoders to read a test bed of distributed X- band radars that are funded through the Collaborative Adaptive Sensing of the Atmosphere (CASA) project. This paper describes in further detail the NCDC Radar Visualization and Data Exporter Tools, and the NCDC hopes to establish collaboration with scientists participating in GEOSS to leverage these tools for interoperable use with other global radar networks. © 2008 ASCE.},
  affiliation             = {NOAA National Climatic Data Center, Asheville, NC, United States},
  author_keywords         = {Climatic data; Information management; Radar},
  correspondence_address1 = {Del Greco, S.; NOAA National Climatic Data Center, Asheville, NC, United States},
  document_type           = {Conference Paper},
  doi                     = {10.1061/40976(316)390},
  isbn                    = {9780784409763},
  journal                 = {World Environmental and Water Resources Congress 2008: Ahupua'a - Proceedings of the World Environmental and Water Resources Congress 2008},
  keywords                = {Adaptive sensing; Bilateral agreements; Client machine; Climatic data; Compliant environment; Data export; Data overlay; Data Sharing; Derived products; Environmental data; Geo-spatial data; Geographical information systems; Global earth observation system of systems; Java web start; National climatic data centers; National oceanographic and atmospheric administrations; Near-real time; Open Source Software; Radar data; Radar network; Weather surveillance radar-1988 Doppler; X-band Radars, Blending; Climatology; Doppler radar; Equipment testing; Geographic information systems; Information management; Interoperability; Java programming language; Observatories; Radar; Surveillance radar; Systems engineering; Visualization; Water resources; Weather satellites, Data visualization},
  language                = {English},
  page_count              = {4},
  source                  = {Scopus},
  url                     = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79251490395&doi=10.1061%2f40976%28316%29390&partnerID=40&md5=22799773d7e1339286c15f63346cb9f3},
}

@Comment{jabref-meta: databaseType:bibtex;}
